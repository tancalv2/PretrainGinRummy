{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GenerateModel.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RubzqOlEW1H2","executionInfo":{"status":"ok","timestamp":1608688964758,"user_tz":300,"elapsed":14980,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"aaa3f55e-15ed-4cb7-bdd8-375949fe0f88"},"source":["# Run this cell to mount your Google Drive.\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IKyWpxtRtB_O"},"source":["# Shared Functions"]},{"cell_type":"code","metadata":{"id":"WGgzStQ_FBXP"},"source":["pth = '/content/drive/MyDrive/Colab Notebooks/Thesis'\r\n","\r\n","# Available states-action pairs:\r\n","state_action_pair = {'all': 'all', # all actions\r\n","                    'bpbd': 'draw', # actions 2/3 \r\n","                    'apbd': ['discard', 'knock'], # actions 6-57, 58-109\r\n","                    'apad': 'knock_bin'} # binary action\r\n","\r\n","# All Possible Classes\r\n","all_classes = ['SP0','SP1','Draw','Pickup','DH','GIN',\r\n","               'AC', '2C', '3C', '4C', '5C', '6C', '7C', '8C', '9C', 'TC', 'JC', 'QC', 'KC',\r\n","               'AH', '2H', '3H', '4H', '5H', '6H', '7H', '8H', '9H', 'TH', 'JH', 'QH', 'KH',\r\n","               'AS', '2S', '3S', '4S', '5S', '6S', '7S', '8S', '9S', 'TS', 'JS', 'QS', 'KS',\r\n","               'AD', '2D', '3D', '4D', '5D', '6D', '7D', '8D', '9D', 'TD', 'JD', 'QD', 'KD',\r\n","               'AC', '2C', '3C', '4C', '5C', '6C', '7C', '8C', '9C', 'TC', 'JC', 'QC', 'KC',\r\n","               'AH', '2H', '3H', '4H', '5H', '6H', '7H', '8H', '9H', 'TH', 'JH', 'QH', 'KH',\r\n","               'AS', '2S', '3S', '4S', '5S', '6S', '7S', '8S', '9S', 'TS', 'JS', 'QS', 'KS',\r\n","               'AD', '2D', '3D', '4D', '5D', '6D', '7D', '8D', '9D', 'TD', 'JD', 'QD', 'KD']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ByjhuCunasYr"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"dAkKSNrD6wh5"},"source":["import copy\n","import numpy as np\n","import pandas as pd\n","import os\n","import time\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import torch.utils.data as data\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","np.set_printoptions(threshold=np.inf)\n","np.set_printoptions(linewidth=np.inf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eRlCpLNOxJEU"},"source":["## cardDataset Class"]},{"cell_type":"code","metadata":{"id":"1Xpwc02F7aNc"},"source":["class cardDataset(data.Dataset):\n","\n","    def __init__(self, features, labels):\n","\n","        self.features = features\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, index):\n","        return self.features[index], self.labels[index]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2yHfT_gYPVk"},"source":["## Balance"]},{"cell_type":"code","metadata":{"id":"UCx4xwJ4YQu1"},"source":["def balanceClasses(states, actions):\n","    class_count = np.sum(actions, axis=0)\n","    zero_count_ind = np.where(class_count == 0)[0]\n","    class_count[zero_count_ind] = 1e10\n","    min_count = np.min(class_count)\n","    min_count_ind = np.argmin(class_count)\n","    # Get indices of current class \n","    action_ind = np.where(actions[:,min_count_ind] == 1)[0]\n","    actions_bal = actions[action_ind]\n","    states_bal = states[action_ind]\n","    for curr_ind in range(actions.shape[1]): \n","        if curr_ind not in zero_count_ind and curr_ind != min_count_ind:\n","            action_ind = np.where(actions[:,curr_ind] == 1)[0]\n","            actions_temp = actions[action_ind]\n","            states_temp = states[action_ind]\n","\n","            random_indices = np.random.choice(actions_temp.shape[0], size=min_count, replace=False)\n","            actions_temp = actions_temp[random_indices]\n","            states_temp = states_temp[random_indices]\n","\n","            actions_bal = np.concatenate((actions_bal, actions_temp))\n","            states_bal = np.concatenate((states_bal, states_temp))\n","    return states_bal, actions_bal"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yYW7krlXGs4Z"},"source":["## Prune States/Actions\r\n"]},{"cell_type":"code","metadata":{"id":"Jyu88GZ1Gs4d"},"source":["# prunable states\n","prune_states = {'currHand': 0, 'topCard': 1,\n","                'deadCard': 2, 'oppCard': 3,\n","                'unknownCard': 4}\n","\n","def pruneStates(states, stateList=[]):\n","    ''' States '''\n","    # (0) ignore current hand\n","    # states[:,(260-52*5):(260-52*4)] = 0\n","    # (1) ignore top card feature\n","    # states[:,(260-52*4):(260-52*3)] = 0\n","    # (2) ignore dead cards feature\n","    # states[:,(260-52*3):(260-52*2)] = 0\n","    # (3) ignore opponent known cards feature\n","    # states[:,(260-52*2):(260-52*1)] = 0\n","    # (4) ignore unknown cards feature\n","    # states[:,(260-52):(260-52*0)] = 0\n","    for s in stateList:\n","        try: \n","            print('pruning state: {}'.format(s))\n","            states[:,(260-52*(5-prune_states[s])):(260-52*(4-prune_states[s]-1))] = 0\n","        except:\n","            print('{} is not a state'.format(s))\n","            pass\n","    return states\n","\n","# chooseable actions\n","prune_actions = {'all': 0,'draw_pickup': 1,'discard': 2,'knock': 3,'knock_bin': 4}\n","\n","def chooseActions(actions, classes, actionChoice):\n","    ''' Actions '''\n","    # (0) all:          actions\n","    #       (x) score_player: actions[:,0:2]\n","    # (1) draw_pickup:  actions[:,2:4]\n","    #       (x) deadHand:     actions[:,4]\n","    #       (x) gin:          actions[:,5]\n","    # (2) discard:      actions[:,6:58]\n","    # (3) knock:        actions[:,58:]\n","    # (4) knock_bin:    actions\n","\n","    if actionChoice == 'all':\n","        return actions, classes\n","    elif actionChoice == 'draw_pickup':\n","        return actions[:,2:4], classes[2:4]\n","    elif actionChoice == 'discard':\n","        return actions[:,6:58], classes[6:58]\n","    elif actionChoice == 'knock':\n","        return actions[:,58:], classes[58:]\n","    elif actionChoice == 'knock_bin':\n","        return actions, [\"No Knock\", \"Knock\"]\n","\n","    else:\n","        print('action selected not allowed')\n","        return actions, classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IPvwCAr8i7rB"},"source":["## Models"]},{"cell_type":"markdown","metadata":{"id":"WBBwvbTtrIa9"},"source":["### Model Types\r\n","\r\n","i.e. 1 Hidden Layer: input_size*2"]},{"cell_type":"code","metadata":{"id":"oyizODzR7W35"},"source":["class MLP(nn.Module):\n","\n","    def __init__(self, input_size, output_size):\n","        super(MLP, self).__init__()\n","        ''' Layer 1 '''\n","        self.l1 = nn.Linear(input_size, input_size*2)\n","\n","        ''' Layer 2 '''\n","        self.l2 = nn.Linear(input_size*2, output_size)\n","        \n","        ''' Activation Function '''\n","        self.sig = nn.Sigmoid()\n","\n","    def forward(self, features):\n","        try:\n","            x = self.l1(features.cuda())\n","        except:\n","            x = self.l1(features)\n","        # x = self.l1(features)\n","        x = self.sig(x)\n","        x = self.l2(x)\n","        return self.sig(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kMcxOddo_Ar2"},"source":["## Load Data and Model"]},{"cell_type":"code","metadata":{"id":"c25nuPlRubld"},"source":["def load_data(data, label, batch_size=1000, shuffle=False):\n","    '''\n","    Load dataset according to batch_size given\n","    '''\n","    data_set = cardDataset(data, label)\n","    data_loader = DataLoader(data_set, batch_size=batch_size, shuffle=shuffle)\n","    return data_loader\n","\n","\n","def load_test_data(numGames):\n","    '''\n","    Load test data\n","    '''\n","    states_test = np.load('{}/s_{}k.npy'.format(data_pth,numGames//1000))\n","    actions_test = np.load('{}/a_{}k.npy'.format(data_pth,numGames//1000))\n","\n","    # prune states\n","    states_test = pruneStates(states_test, pruneStatesList)\n","\n","    # choosable actions\n","    actions_test, classes = chooseActions(actions_test, all_classes, actionChoice)\n","    test_loader = load_data(states_test, actions_test)\n","    return test_loader, classes\n","\n","\n","def load_model(lr=0.001, input_size=None, output_size=None,\n","               model=None, pre_train=False, model_PT=None):\n","    loss_fnc = torch.nn.MSELoss()\n","    if model is None:\n","        try:\n","            model = MLP(input_size, output_size).cuda()\n","        except:\n","            model = MLP(input_size, output_size)\n","        # model = MLP(input_size)\n","        if pre_train:\n","            pre_train_model = torch.load(model_PT)\n","            try:\n","                pre_train_model.l1 = pre_train_model.l1.cuda()\n","                model.l1.weight = pre_train_model.l1.weight.cuda()\n","                model.l1.bias = pre_train_model.l1.bias.cuda()\n","            except:\n","                model.l1.weight = pre_train_model.l1.weight\n","                model.l1.bias = pre_train_model.l1.bias\n","        # print(model.l1.weight.device)\n","        # print(model.l1.bias.device)\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","        return model, loss_fnc, optimizer\n","    return model, loss_fnc, _"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x9xYVimV-d0y"},"source":["## Evaluate"]},{"cell_type":"code","metadata":{"id":"J6MxsF8LWvQ6"},"source":["def evaluate(model, data_loader, loss_fnc):\n","\n","    total_corr = 0\n","    accum_loss = 0\n","    for i, data in enumerate(data_loader):\n","        inputs, labels = data\n","        inputs = inputs.type(torch.FloatTensor)\n","        labels = labels.type(torch.FloatTensor)\n","        outputs = model(inputs)\n","        try:\n","            batch_loss = loss_fnc(input=outputs, target=labels.cuda())\n","        except:\n","            batch_loss = loss_fnc(input=outputs, target=labels)\n","        # batch_loss = loss_fnc(input=outputs, target=labels)\n","\n","        guess = torch.argmax(outputs, dim=1)\n","        # print(guess)\n","        try:\n","            answer = torch.argmax(labels.cuda(), dim=1)\n","        except:\n","            answer = torch.argmax(labels, dim=1)\n","        # answer = torch.argmax(labels, dim=1)\n","\n","        corr = guess == answer\n","        total_corr += int(corr.sum())\n","        accum_loss += batch_loss\n","\n","    acc = float(total_corr)/len(data_loader.dataset)\n","    loss = accum_loss/(i+1)\n","    return acc, loss.item() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uHg3uuvb-bVW"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"-oiAF2N_DR_4"},"source":["def train(train_loader, val_loader, batch_size=1000, lr=0.001, epochs=100,\n","          verbose=False, pre_train=False, model_PT=None):\n","\n","    input_size = len(train_loader.dataset.features[0])\n","    output_size = len(val_loader.dataset.labels[0])\n","    # input_size = data_train.shape[1]\n","    model, loss_fnc, optimizer = load_model(lr, input_size, output_size,\n","                                            pre_train=pre_train, model_PT=model_PT)\n","\n","    max_val_acc = 0\n","    min_val_loss = np.inf\n","    train_acc, train_loss = [], []\n","    val_acc, val_loss = [], []\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        accum_loss = 0\n","        total_corr = 0\n","        for i, data in enumerate(train_loader):\n","            inputs, labels = data\n","            inputs = inputs.type(torch.FloatTensor)\n","            labels = labels.type(torch.FloatTensor)\n","            \n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            try:\n","                batch_loss = loss_fnc(input=outputs, target=labels.cuda())\n","            except:\n","                batch_loss = loss_fnc(input=outputs, target=labels)\n","            # batch_loss = loss_fnc(input=outputs, target=labels)\n","            accum_loss += batch_loss\n","            batch_loss.backward()\n","            optimizer.step()\n","\n","            guess = torch.argmax(outputs, dim=1)\n","            # print(guess)\n","            try:\n","                answer = torch.argmax(labels.cuda(), dim=1)\n","            except:\n","                answer = torch.argmax(labels, dim=1)\n","            # answer = torch.argmax(labels, dim=1)\n","            # print(labels)\n","            corr = guess == answer\n","            total_corr += int(corr.sum())\n","\n","        # evaluate per epoch\n","        vacc, vloss = evaluate(model, val_loader, loss_fnc)\n","        val_acc.append(vacc)\n","        val_loss.append(vloss)\n","        train_loss.append(accum_loss.item()/(i+1))\n","        train_acc.append(float(total_corr)/len(train_loader.dataset))\n","        # best acc model\n","        if vacc > max_val_acc:\n","            max_val_acc = vacc\n","            epoch_acc = epoch\n","            model_acc = copy.deepcopy(model) \n","        # best loss model\n","        if vloss < min_val_loss:\n","            min_val_loss = vloss\n","            epoch_loss = epoch\n","            model_loss = copy.deepcopy(model)\n","\n","        if verbose:\n","            # print records\n","            print(\"Epoch: {} | Train Loss: {:.8f} | Train acc: {:.6f}\"\n","                .format(epoch + 1, train_loss[epoch], train_acc[epoch]))\n","            print(\"              Val Loss: {:.8f} |   Val acc: {:.6f}\"\n","                .format(val_loss[epoch], val_acc[epoch]))\n","        accum_loss = 0.0\n","        total_corr = 0\n","\n","\n","    print('Finished Training')\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(\"Total training time elapsed: {:.2f} seconds\".format(elapsed_time))\n","    plotTrain(train_acc, val_acc, epoch_acc, 'Accuracy',batch_size, lr)\n","    plotTrain(train_loss, val_loss, epoch_loss, 'Loss',batch_size, lr)\n","\n","    return model, model_acc, model_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a4RMbLGjstPP"},"source":["## Plot Functions"]},{"cell_type":"code","metadata":{"id":"YuRUncDFssjI"},"source":["def plotTrain(train, val, epoch, label, bs, lr):\n","    plt.figure()\n","    plt.title(\"{} vs. Epoch\".format(label), fontsize=14)\n","    plt.xlabel(\"Epochs\", fontsize=12)\n","    plt.ylabel(label, fontsize=12)\n","    plt.plot(train, label='Training {}'.format(label))\n","    plt.plot(val, label='Validation {}'.format(label))\n","    plt.axvline(epoch, color='red', label='Best Epoch: {}'.format(epoch+1))\n","    plt.plot(epoch, val[epoch], marker='o', color=\"red\", label=\"{}: {:.4f}\"\n","             .format(label, val[epoch]))\n","    plt.legend()\n","    plt.savefig('{}/{}_bs_{}_lr_{}.png'.format(plot_pth,label,bs,lr),\n","                bbox_inches='tight')\n","    plt.show()\n","    plt.close()\n","\n","\n","def evaluate_confusion_matrix(model, data_loader):\n","    \"\"\"\n","    Run the model on the test set and generate the confusion matrix.\n","\n","    Args:\n","        model: PyTorch neural network object\n","        data_loader: PyTorch data loader for the dataset\n","    Returns:\n","        cm: A NumPy array denoting the confusion matrix\n","    \"\"\"\n","    val_labels = np.array([], dtype=np.int64)\n","    val_preds = np.array([], dtype=np.int64)\n","\n","    for i, data in enumerate(data_loader, 0):\n","        vinputs, vlabels = data\n","        vinputs = vinputs.type(torch.FloatTensor)\n","        vlabels = vlabels.type(torch.FloatTensor)\n","        voutputs = model(vinputs)\n","        vguess = torch.argmax(voutputs.cpu(), dim=1)\n","        vlabels = torch.argmax(vlabels.cpu(), dim=1)\n","        val_labels = np.concatenate((val_labels, vlabels))\n","        val_preds = np.concatenate((val_preds, vguess))\n","    \n","    # cm = confusion_matrix(val_labels, val_preds)\n","    cm_temp = np.zeros([voutputs.shape[1],voutputs.shape[1]], dtype=np.int64)\n","    for i in range(len(val_labels)):\n","        cm_temp[val_labels[i]][val_preds[i]] += 1\n","    cm = cm_temp\n","    print('Accuracy: {:.2f}'.format(100*(val_labels == val_preds).sum() /len(val_labels)))\n","    return cm\n","\n","\n","# Function based off\n","# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n","def plot_confusion_matrix(cm, classes, mode,\n","                          normalize=True,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","\n","    Args:\n","        cm: A NumPy array denoting the confusion matrix\n","        classes: A list of strings denoting the name of the classes\n","        normalize: Boolean whether to normalize the confusion matrix or not\n","        title: String for the title of the plot\n","        cmap: Colour map for the plot\n","    \"\"\"\n","    # normalize\n","    if normalize:\n","        plot_name = 'CM_norm'\n","        cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-5)\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        plot_name = 'CM'\n","        print('Confusion matrix, without normalization')\n","\n","    # limit figure size\n","    if cm.shape[0] < 52:\n","        plt.figure(facecolor='white')\n","    else:\n","        plt.figure(figsize=cm.shape, facecolor='white')\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    # plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    if mode == 'full':\n","        plt.savefig('{}/{}_G_{}k.png'.format(plot_pth,plot_name,currGames//1000),\n","                    bbox_inches='tight')\n","    else:\n","        plt.savefig('{}/{}_G_{}k_{}.png'.format(plot_pth,plot_name,currGames//1000,mode),\n","                    bbox_inches='tight')        \n","    if cm.shape[0] < 52:\n","        plt.show()\n","    plt.close()\n","    return\n","\n","\n","def plot_cm(classes, model, data_loader, mode='full'):\n","\n","    cm = evaluate_confusion_matrix(model, data_loader)\n","    plot_confusion_matrix(cm, classes, mode,\n","                        normalize=True,\n","                        title='Confusion matrix',\n","                        cmap=plt.cm.Blues)\n","    plot_confusion_matrix(cm, classes, mode,\n","                        normalize=False,\n","                        title='Confusion matrix',\n","                        cmap=plt.cm.Blues)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1zIOKj82WfJa"},"source":["# State-Action Pair\r\n","\r\n","i.e. Before Pickup, Before Discard: Draw (bpbd_draw)"]},{"cell_type":"markdown","metadata":{"id":"SBwV5XHqsgTq"},"source":["## Model Name\r\n","\r\n","Specify the following parameters:\r\n","\r\n","- Data Selection:\r\n"," - model_name\r\n"," - state-action pair\r\n","```r\r\n","state_action_pair = {'all': 'all', # all actions\r\n","                    'bpbd': 'draw', # actions 2/3 \r\n","                    'apbd': ['discard', 'knock'], # actions 6-57, 58-109\r\n","                    'apad': 'knock_bin'}\r\n","```\r\n"," - numGames\r\n"," - pruneStatesList\r\n"," ```r\r\n"," {'currHand','topCard','deadCard','oppCard','unknownCard'}\r\n"," ```\r\n"," - actionChoice = 'all'\r\n","```r\r\n","{'all','draw_pickup','discard','knock'}\r\n","```\r\n","\r\n","- Model Parameters:\r\n","\r\n","| Parameter     | Type      |Default|\r\n","| ------------- |:---------:| -----:|\r\n","| batch_size    | int       | 1000  |\r\n","| learning_rate | float     | 0.001 |\r\n","| epoch         | int       | 100   |\r\n","| pre_train     | bool (T/F)| False |\r\n","| model_PT      | str (path)| null  |"]},{"cell_type":"code","metadata":{"id":"LzIZNusYMVsm"},"source":["# model name\r\n","model_name = 'all_states_all_actions'\r\n","\r\n","# state_action pair, and dataset selection\r\n","state = 'all'\r\n","action = 'all'\r\n","numGames = 8000\r\n","\r\n","# prunable states\r\n","# {'currHand','topCard','deadCard','oppCard','unknownCard'} or blank if None\r\n","pruneStatesList = []\r\n","\r\n","# choosable actions\r\n","# {'all','draw_pickup','discard','knock','knock_bin'}\r\n","actionChoice = 'all'\r\n","\r\n","# Balance classes\r\n","balance = False\r\n","\r\n","# Training parameters\r\n","batch_size = 1000\r\n","lr = 0.001\r\n","epochs = 100\r\n","\r\n","# Pretrain model\r\n","pre_train = False\r\n","model_PT = ''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fYEmVZjHTUlU"},"source":["### Directories"]},{"cell_type":"code","metadata":{"id":"2nXU1F_bac2E"},"source":["# create model and plot directories if do not exist\r\n","\r\n","# model directories\r\n","state_pth = '{}/models/{}'.format(pth,state)\r\n","if not os.path.exists(state_pth):\r\n","    os.mkdir(state_pth)\r\n","action_pth = '{}/{}'.format(state_pth,action)\r\n","if not os.path.exists(action_pth):\r\n","    os.mkdir(action_pth)\r\n","model_pth = '{}/{}'.format(action_pth,model_name)\r\n","if not os.path.exists(model_pth):\r\n","    os.mkdir(model_pth)\r\n","\r\n","# plot directories\r\n","state_pth = '{}/plots/{}'.format(pth,state)\r\n","if not os.path.exists(state_pth):\r\n","    os.mkdir(state_pth)\r\n","action_pth = '{}/{}'.format(state_pth,action)\r\n","if not os.path.exists(action_pth):\r\n","    os.mkdir(action_pth)\r\n","plot_pth = '{}/{}'.format(action_pth,model_name)\r\n","if not os.path.exists(plot_pth):\r\n","    os.mkdir(plot_pth)\r\n","\r\n","# data directory\r\n","data_pth = '{}/data/{}/{}'.format(pth,state,action)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-lP6-zCORtQZ"},"source":["### Load, Prune, Split Data"]},{"cell_type":"code","metadata":{"id":"QPeZSlI7sjCh"},"source":["if action in state_action_pair[state]:\n","    states = np.load('{}/s_{}k.npy'.format(data_pth,numGames//1000))\n","    actions = np.load('{}/a_{}k.npy'.format(data_pth,numGames//1000))\n","\n","    # prune states\n","    states = pruneStates(states, pruneStatesList)\n","\n","    # choosable actions\n","    actions, classes = chooseActions(actions, all_classes, actionChoice)\n","\n","    # balance classes\n","    if balance:\n","        states,actions = balanceClasses(states,actions)\n","\n","    # split train/val\n","    data_train, data_val, label_train, label_val = train_test_split(states, actions, test_size=0.3, random_state=421)\n","else:\n","    print('illegeal state-action pair')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oNX0uB6LWMvv"},"source":["train_loader = load_data(data_train, label_train, batch_size, shuffle=True)\r\n","val_loader = load_data(data_val, label_val, batch_size, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"obOqXVZghQzX"},"source":["### Train Model"]},{"cell_type":"code","metadata":{"id":"45QhmhWDWDob"},"source":["model, model_acc, model_loss = train(train_loader, val_loader, batch_size, lr, epochs, verbose=True, pre_train=pre_train, model_PT=model_PT)\r\n","torch.save(model, '{}/model.pt'.format(model_pth))\r\n","torch.save(model_acc, '{}/model_acc.pt'.format(model_pth))\r\n","torch.save(model_loss, '{}/model_loss.pt'.format(model_pth))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DW31uxR32JoZ"},"source":["#### Confusion Matrix"]},{"cell_type":"code","metadata":{"id":"M6mgQZEiQtkC"},"source":["torch.save(model, '{}/model.pt'.format(model_pth))\r\n","torch.save(model_acc, '{}/model_acc.pt'.format(model_pth))\r\n","torch.save(model_loss, '{}/model_loss.pt'.format(model_pth))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IUNBzKdGDFbn"},"source":["##### Train Set"]},{"cell_type":"code","metadata":{"id":"SLxYWYeIEHvT"},"source":["currGames = 8000\n","model, loss_fnc, _ = load_model(model=model)\n","plot_cm(classes, model, train_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k5gkIktiMyoD"},"source":["##### Validation Set"]},{"cell_type":"code","metadata":{"id":"MrkvSof6MyoR"},"source":["currGames = 8000\n","model, loss_fnc, _ = load_model(model=model)\n","plot_cm(classes, model, val_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gaIdoZAXM4SJ"},"source":["##### Test Set (6k)"]},{"cell_type":"code","metadata":{"id":"sPXiAdf-M4SL"},"source":["currGames = 8000\n","test_loader_6k, classes = load_test_data(currGames)\n","model, loss_fnc, _ = load_model(model=model)\n","plot_cm(classes, model, test_loader_6k, mode='val')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F18JCOSyNfIM"},"source":["##### Test Set (2k)\r\n","\r\n","Test on all three models generated:"]},{"cell_type":"code","metadata":{"id":"ws_iC6x3R3ag"},"source":["currGames = 2000\n","test_loader_2k, classes = load_test_data(currGames)\n","torch.save(model, '{}/model.pt'.format(model_pth))\n","torch.save(model_acc, '{}/model_acc.pt'.format(model_pth))\n","torch.save(model_loss, '{}/model_loss.pt'.format(model_pth))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q6jGgwJd0DE0"},"source":["###### all epoch"]},{"cell_type":"code","metadata":{"id":"AxRb3twZODP4"},"source":["model, loss_fnc, _ = load_model(model=model)\n","plot_cm(classes, model, test_loader_2k)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GozGjASy0JXL"},"source":["###### max validation accuracy"]},{"cell_type":"code","metadata":{"id":"UYVSIyQQOCng"},"source":["model_acc, loss_fnc, _ = load_model(model=model_acc)\n","plot_cm(classes, model_acc, test_loader_2k, mode='acc')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l8iWcRlP0J3t"},"source":["###### min validation loss"]},{"cell_type":"code","metadata":{"id":"tu1W7Lav9RNU"},"source":["model_loss, loss_fnc, _ = load_model(model=model_loss)\n","plot_cm(classes, model_loss, test_loader_2k, mode='loss')"],"execution_count":null,"outputs":[]}]}