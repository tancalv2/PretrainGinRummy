{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dqn.ipynb","provenance":[],"collapsed_sections":["hH83LalFQa0A","q-FMMNhFGts5","lriHyOBsFI7I"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RubzqOlEW1H2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608748984636,"user_tz":300,"elapsed":18561,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"09144838891693247193"}},"outputId":"377e28e3-65f5-4fe2-9a95-bf6a12af34ed"},"source":["# Run this cell to mount your Google Drive.\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o8lnqVu4Qq-8"},"source":["# DQN"]},{"cell_type":"code","metadata":{"id":"4HnoQ7YHQ7eK"},"source":["!pip install rlcard\n","!pip install rlcard[torch]\n","!pip install rlcard[tensorflow]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u2wz3Kx41J9H"},"source":["%cd /content/drive/My Drive/Colab Notebooks/Thesis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bAgTASZMJLs4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608749152679,"user_tz":300,"elapsed":2282,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"09144838891693247193"}},"outputId":"ee464334-1900-4c24-9a10-0f1e08e46808"},"source":["import torch\n","import tensorflow as tf\n","\n","print(torch.__version__)\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.7.0+cu101\n","1.15.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aJX46H9x33XX"},"source":["## DQN Customized"]},{"cell_type":"code","metadata":{"id":"pRvqQZTgy8U-"},"source":["''' DQN agent\n","The code is derived from https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/dqn.py\n","Copyright (c) 2019 Matthew Judell\n","Copyright (c) 2019 DATA Lab at Texas A&M University\n","Copyright (c) 2016 Denny Britz\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","SOFTWARE.\n","'''\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from collections import namedtuple\n","from copy import deepcopy\n","\n","from rlcard.agents.dqn_agent import Memory\n","from rlcard.utils.utils import remove_illegal\n","\n","Transition = namedtuple('Transition', ['state', 'action', 'reward', 'next_state', 'done'])\n","\n","\n","class DQNAgent(object):\n","    '''\n","    Approximate clone of rlcard.agents.dqn_agent.DQNAgent\n","    that depends on PyTorch instead of Tensorflow\n","    '''\n","    def __init__(self,\n","                 scope,\n","                 replay_memory_size=20000,\n","                 replay_memory_init_size=100,\n","                 update_target_estimator_every=1000,\n","                 discount_factor=0.99,\n","                 epsilon_start=1.0,\n","                 epsilon_end=0.1,\n","                 epsilon_decay_steps=20000,\n","                 batch_size=32,\n","                 action_num=2,\n","                 state_shape=None,\n","                 train_every=1,\n","                 mlp_layers=None,\n","                 learning_rate=0.00005,\n","                 device=None):\n","\n","        '''\n","        Q-Learning algorithm for off-policy TD control using Function Approximation.\n","        Finds the optimal greedy policy while following an epsilon-greedy policy.\n","        Args:\n","            scope (str): The name of the DQN agent\n","            replay_memory_size (int): Size of the replay memory\n","            replay_memory_init_size (int): Number of random experiences to sampel when initializing\n","              the reply memory.\n","            update_target_estimator_every (int): Copy parameters from the Q estimator to the\n","              target estimator every N steps\n","            discount_factor (float): Gamma discount factor\n","            epsilon_start (int): Chance to sample a random action when taking an action.\n","              Epsilon is decayed over time and this is the start value\n","            epsilon_end (int): The final minimum value of epsilon after decaying is done\n","            epsilon_decay_steps (int): Number of steps to decay epsilon over\n","            batch_size (int): Size of batches to sample from the replay memory\n","            evaluate_every (int): Evaluate every N steps\n","            action_num (int): The number of the actions\n","            state_space (list): The space of the state vector\n","            train_every (int): Train the network every X steps.\n","            mlp_layers (list): The layer number and the dimension of each layer in MLP\n","            learning_rate (float): The learning rate of the DQN agent.\n","            device (torch.device): whether to use the cpu or gpu\n","        '''\n","        self.use_raw = False\n","        self.scope = scope\n","        self.replay_memory_init_size = replay_memory_init_size\n","        self.update_target_estimator_every = update_target_estimator_every\n","        self.discount_factor = discount_factor\n","        self.epsilon_decay_steps = epsilon_decay_steps\n","        self.batch_size = batch_size\n","        self.action_num = action_num\n","        self.train_every = train_every\n","\n","        # Torch device\n","        if device is None:\n","            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        else:\n","            self.device = device\n","\n","        # Total timesteps\n","        self.total_t = 0\n","\n","        # Total training step\n","        self.train_t = 0\n","\n","        # The epsilon decay scheduler\n","        self.epsilons = np.linspace(epsilon_start, epsilon_end, epsilon_decay_steps)\n","\n","        # Create estimators\n","        self.q_estimator = Estimator(action_num=action_num, learning_rate=learning_rate, state_shape=state_shape, \\\n","            mlp_layers=mlp_layers, device=self.device)\n","        self.target_estimator = Estimator(action_num=action_num, learning_rate=learning_rate, state_shape=state_shape, \\\n","            mlp_layers=mlp_layers, device=self.device)\n","\n","        # Create replay memory\n","        self.memory = Memory(replay_memory_size, batch_size)\n","\n","    def feed(self, ts):\n","        ''' Store data in to replay buffer and train the agent. There are two stages.\n","            In stage 1, populate the memory without training\n","            In stage 2, train the agent every several timesteps\n","        Args:\n","            ts (list): a list of 5 elements that represent the transition\n","        '''\n","        (state, action, reward, next_state, done) = tuple(ts)\n","        self.feed_memory(state['obs'], action, reward, next_state['obs'], done)\n","        self.total_t += 1\n","        tmp = self.total_t - self.replay_memory_init_size\n","        if tmp>=0 and tmp%self.train_every == 0:\n","            self.train()\n","\n","    def step(self, state):\n","        ''' Predict the action for genrating training data but\n","            have the predictions disconnected from the computation graph\n","        Args:\n","            state (numpy.array): current state\n","        Returns:\n","            action (int): an action id\n","        '''\n","        A = self.predict(state['obs'])\n","        A = remove_illegal(A, state['legal_actions'])\n","        action = np.random.choice(np.arange(len(A)), p=A)\n","        return action\n","\n","    def eval_step(self, state):\n","        ''' Predict the action for evaluation purpose.\n","        Args:\n","            state (numpy.array): current state\n","        Returns:\n","            action (int): an action id\n","        '''\n","        q_values = self.q_estimator.predict_nograd(np.expand_dims(state['obs'], 0))[0]\n","        probs = remove_illegal(np.exp(q_values), state['legal_actions'])\n","        best_action = np.argmax(probs)\n","        return best_action, probs\n","\n","    def predict(self, state):\n","        ''' Predict the action probabilities but have them\n","            disconnected from the computation graph\n","        Args:\n","            state (numpy.array): current state\n","        Returns:\n","            q_values (numpy.array): a 1-d array where each entry represents a Q value\n","        '''\n","        epsilon = self.epsilons[min(self.total_t, self.epsilon_decay_steps-1)]\n","        A = np.ones(self.action_num, dtype=float) * epsilon / self.action_num\n","        q_values = self.q_estimator.predict_nograd(np.expand_dims(state, 0))[0]\n","        best_action = np.argmax(q_values)\n","        A[best_action] += (1.0 - epsilon)\n","        return A\n","\n","    def train(self):\n","        ''' Train the network\n","        Returns:\n","            loss (float): The loss of the current batch.\n","        '''\n","        state_batch, action_batch, reward_batch, next_state_batch, done_batch = self.memory.sample()\n","\n","        # Calculate best next actions using Q-network (Double DQN)\n","        q_values_next = self.q_estimator.predict_nograd(next_state_batch)\n","        best_actions = np.argmax(q_values_next, axis=1)\n","\n","        # Evaluate best next actions using Target-network (Double DQN)\n","        q_values_next_target = self.target_estimator.predict_nograd(next_state_batch)\n","        target_batch = reward_batch + np.invert(done_batch).astype(np.float32) * \\\n","            self.discount_factor * q_values_next_target[np.arange(self.batch_size), best_actions]\n","\n","        # Perform gradient descent update\n","        state_batch = np.array(state_batch)\n","\n","        loss = self.q_estimator.update(state_batch, action_batch, target_batch)\n","        print('\\rINFO - Agent {}, step {}, rl-loss: {}'.format(self.scope, self.total_t, loss), end='')\n","\n","        # Update the target estimator\n","        if self.train_t % self.update_target_estimator_every == 0:\n","            self.target_estimator = deepcopy(self.q_estimator)\n","            print(\"\\nINFO - Copied model parameters to target network.\")\n","\n","        self.train_t += 1\n","\n","    def feed_memory(self, state, action, reward, next_state, done):\n","        ''' Feed transition to memory\n","        Args:\n","            state (numpy.array): the current state\n","            action (int): the performed action ID\n","            reward (float): the reward received\n","            next_state (numpy.array): the next state after performing the action\n","            done (boolean): whether the episode is finished\n","        '''\n","        self.memory.save(state, action, reward, next_state, done)\n","\n","    def get_state_dict(self):\n","        ''' Get the state dict to save models\n","        Returns:\n","            (dict): A dict of model states\n","        '''\n","        q_key = self.scope + '_q_estimator'\n","        q_value = self.q_estimator.qnet.state_dict()\n","        target_key = self.scope + '_target_estimator'\n","        target_value = self.target_estimator.qnet.state_dict()\n","        return {q_key: q_value, target_key: target_value}\n","\n","    def load(self, checkpoint):\n","        ''' Load model\n","        Args:\n","            checkpoint (dict): the loaded state\n","        '''\n","        q_key = self.scope + '_q_estimator'\n","        self.q_estimator.qnet.load_state_dict(checkpoint[q_key])\n","        target_key = self.scope + '_target_estimator'\n","        self.target_estimator.qnet.load_state_dict(checkpoint[target_key])\n","\n","class Estimator(object):\n","    '''\n","    Approximate clone of rlcard.agents.dqn_agent.Estimator that\n","    uses PyTorch instead of Tensorflow.  All methods input/output np.ndarray.\n","    Q-Value Estimator neural network.\n","    This network is used for both the Q-Network and the Target Network.\n","    '''\n","\n","    def __init__(self, action_num=2, learning_rate=0.001, state_shape=None, mlp_layers=None, device=None):\n","        ''' Initilalize an Estimator object.\n","        Args:\n","            action_num (int): the number output actions\n","            state_shape (list): the shape of the state space\n","            mlp_layers (list): size of outputs of mlp layers\n","            device (torch.device): whether to use cpu or gpu\n","        '''\n","        self.action_num = action_num\n","        self.learning_rate=learning_rate\n","        self.state_shape = state_shape\n","        self.mlp_layers = mlp_layers\n","        self.device = device\n","\n","        # set up Q model and place it in eval mode\n","        qnet = EstimatorNetwork(action_num, state_shape, mlp_layers)\n","        qnet = qnet.to(self.device)\n","        self.qnet = qnet\n","        self.qnet.eval()\n","\n","        # initialize the weights using Xavier init\n","        for p in self.qnet.parameters():\n","            if len(p.data.shape) > 1:\n","                nn.init.xavier_uniform_(p.data)\n","\n","        # set up loss function\n","        self.mse_loss = nn.MSELoss(reduction='mean')\n","\n","        # set up optimizer\n","        self.optimizer =  torch.optim.Adam(self.qnet.parameters(), lr=self.learning_rate)\n","\n","    def predict_nograd(self, s):\n","        ''' Predicts action values, but prediction is not included\n","            in the computation graph.  It is used to predict optimal next\n","            actions in the Double-DQN algorithm.\n","        Args:\n","          s (np.ndarray): (batch, state_len)\n","        Returns:\n","          np.ndarray of shape (batch_size, NUM_VALID_ACTIONS) containing the estimated\n","          action values.\n","        '''\n","        with torch.no_grad():\n","            s = torch.from_numpy(s).float().to(self.device)\n","            q_as = self.qnet(s).cpu().numpy()\n","        return q_as\n","\n","    def update(self, s, a, y):\n","        ''' Updates the estimator towards the given targets.\n","            In this case y is the target-network estimated\n","            value of the Q-network optimal actions, which\n","            is labeled y in Algorithm 1 of Minh et al. (2015)\n","        Args:\n","          s (np.ndarray): (batch, state_shape) state representation\n","          a (np.ndarray): (batch,) integer sampled actions\n","          y (np.ndarray): (batch,) value of optimal actions according to Q-target\n","        Returns:\n","          The calculated loss on the batch.\n","        '''\n","        self.optimizer.zero_grad()\n","\n","        self.qnet.train()\n","\n","        s = torch.from_numpy(s).float().to(self.device)\n","        a = torch.from_numpy(a).long().to(self.device)\n","        y = torch.from_numpy(y).float().to(self.device)\n","\n","        # (batch, state_shape) -> (batch, action_num)\n","        q_as = self.qnet(s)\n","\n","        # (batch, action_num) -> (batch, )\n","        Q = torch.gather(q_as, dim=-1, index=a.unsqueeze(-1)).squeeze(-1)\n","\n","        # update model\n","        batch_loss = self.mse_loss(Q, y)\n","        batch_loss.backward()\n","        self.optimizer.step()\n","        batch_loss = batch_loss.item()\n","\n","        self.qnet.eval()\n","\n","        return batch_loss\n","\n","\n","class EstimatorNetwork(nn.Module):\n","    ''' The function approximation network for Estimator\n","        It is just a series of tanh layers. All in/out are torch.tensor\n","    '''\n","\n","    def __init__(self, action_num=2, state_shape=None, mlp_layers=None):\n","        ''' Initialize the Q network\n","        Args:\n","            action_num (int): number of legal actions\n","            state_shape (list): shape of state tensor\n","            mlp_layers (list): output size of each fc layer\n","        '''\n","        super(EstimatorNetwork, self).__init__()\n","\n","        self.action_num = action_num\n","        self.state_shape = state_shape\n","        self.mlp_layers = mlp_layers\n","\n","        # build the Q network\n","        layer_dims = [np.prod(self.state_shape)] + self.mlp_layers\n","        fc = [nn.Flatten()]\n","        fc.append(nn.BatchNorm1d(layer_dims[0]))\n","        for i in range(len(layer_dims)-1):\n","            fc.append(nn.Linear(layer_dims[i], layer_dims[i+1], bias=True))\n","            fc.append(nn.Sigmoid())\n","        fc.append(nn.Linear(layer_dims[-1], self.action_num, bias=True))\n","        self.fc_layers = nn.Sequential(*fc)\n","        # self.l1 = nn.Linear(input_size, input_size*2)\n","        # self.l2 = nn.Linear(input_size*2, 1)\n","        # self.sig = nn.Sigmoid()\n","\n","    def forward(self, s):\n","        ''' Predict action values\n","        Args:\n","            s  (Tensor): (batch, state_shape)\n","        '''\n","        return self.fc_layers(s)\n","        # x = self.l1(nn.Flatten(s))\n","        # x = self.sig(x)\n","        # x = self.l2(x)\n","        # return self.sig(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IPvwCAr8i7rB"},"source":["### Models"]},{"cell_type":"markdown","metadata":{"id":"WBBwvbTtrIa9"},"source":["#### 1 Hidden Layer: input_size*2\r\n","\r\n","i.e. 1 Hidden Layer: input_size*2"]},{"cell_type":"code","metadata":{"id":"oyizODzR7W35"},"source":["class MLP(nn.Module):\n","\n","    def __init__(self, input_size, output_size):\n","        super(MLP, self).__init__()\n","        ''' Layer 1 '''\n","        self.l1 = nn.Linear(input_size, input_size*2)\n","\n","        ''' Layer 2 '''\n","        self.l2 = nn.Linear(input_size*2, output_size)\n","        \n","        ''' Activation Function '''\n","        self.sig = nn.Sigmoid()\n","\n","    def forward(self, features):\n","        try:\n","            x = self.l1(features.cuda())\n","        except:\n","            x = self.l1(features)\n","        # x = self.l1(features)\n","        x = self.sig(x)\n","        x = self.l2(x)\n","        return self.sig(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hH83LalFQa0A"},"source":["### Experiments"]},{"cell_type":"code","metadata":{"id":"NeBLkvfs1Q4w"},"source":["model = torch.load('/content/drive/My Drive/Colab Notebooks/Thesis/models/apbd_pytorch/model_pt.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCQ4AA592t9k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606331770938,"user_tz":300,"elapsed":256,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"c3a216a1-7c7b-4758-d5a3-f901fe4255ba"},"source":["model.l1.weight.cpu()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.5348e+00, -1.3212e+00,  1.7455e+00,  ...,  4.4827e-02,\n","          4.6710e-02, -3.4218e-02],\n","        [ 2.9515e+00, -8.4011e-01,  8.9235e-01,  ..., -1.0771e-02,\n","          2.0655e-02, -5.8781e-03],\n","        [-3.3204e-01, -3.1470e-01, -3.7012e-01,  ...,  1.3609e-02,\n","          8.4998e-03,  3.6893e-02],\n","        ...,\n","        [-1.6948e+00, -1.7720e+00,  9.3538e+00,  ..., -1.2536e-02,\n","         -4.9882e-02, -5.5409e-02],\n","        [-2.5379e+00, -1.6696e+00, -2.0588e+00,  ..., -2.2529e-02,\n","         -2.2292e-02, -5.4467e-02],\n","        [-2.1017e+00, -6.5800e-01, -1.3593e+00,  ...,  2.1683e-02,\n","         -1.4672e-02, -2.4222e-02]], grad_fn=<CopyBackwards>)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"dEvdtC0E4GBT"},"source":["agent = DQNAgent(scope='dqn',\n","                 action_num=env.action_num,\n","                 replay_memory_init_size=memory_init_size,\n","                 train_every=train_every,\n","                 state_shape=env.state_shape,\n","                 mlp_layers=[520, 1],\n","                 device=torch.device('cpu'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"upTlpo-E4JAD"},"source":["agent.q_estimator.qnet.fc_layers[2].weight = model.l1.weight\n","agent.q_estimator.qnet.fc_layers[2].bias = model.l1.bias\n","agent.q_estimator.qnet.fc_layers[4].weight = model.l2.weight\n","agent.q_estimator.qnet.fc_layers[4].bias = model.l2.bias"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIxGjQu_1wJO","executionInfo":{"status":"ok","timestamp":1606332068646,"user_tz":300,"elapsed":266,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"53fbab47-4a71-4b3f-8b65-a87494db01e8"},"source":["agent.q_estimator.qnet.fc_layers[2].weight\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-1.2913e-02,  1.7555e-02, -6.8227e-02,  ..., -7.2687e-02,\n","          7.2696e-05, -8.6314e-02],\n","        [-7.4512e-02,  4.7105e-02,  6.1485e-02,  ...,  5.1628e-02,\n","          2.0472e-02, -8.7519e-02],\n","        [-2.8611e-02, -2.6829e-02, -4.9708e-02,  ...,  8.7605e-02,\n","          1.5988e-02,  4.0572e-03],\n","        ...,\n","        [ 4.5356e-02,  2.4573e-02, -5.1773e-02,  ...,  3.2959e-02,\n","          2.4060e-03, -4.8993e-03],\n","        [-4.9848e-02, -2.1334e-03, -3.2256e-02,  ...,  1.4862e-02,\n","          7.3959e-02, -6.6445e-02],\n","        [-1.6038e-02, -1.8058e-02, -4.7224e-02,  ...,  1.3438e-02,\n","          6.3478e-02,  9.8711e-03]], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQ63cOIH1_yi","executionInfo":{"status":"ok","timestamp":1606332064290,"user_tz":300,"elapsed":263,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"8fa91ead-73f1-49dd-af57-e8ef1b75720e"},"source":["torch.nn.Parameter(model.l1.weight.cpu())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-1.5348e+00, -1.3212e+00,  1.7455e+00,  ...,  4.4827e-02,\n","          4.6710e-02, -3.4218e-02],\n","        [ 2.9515e+00, -8.4011e-01,  8.9235e-01,  ..., -1.0771e-02,\n","          2.0655e-02, -5.8781e-03],\n","        [-3.3204e-01, -3.1470e-01, -3.7012e-01,  ...,  1.3609e-02,\n","          8.4998e-03,  3.6893e-02],\n","        ...,\n","        [-1.6948e+00, -1.7720e+00,  9.3538e+00,  ..., -1.2536e-02,\n","         -4.9882e-02, -5.5409e-02],\n","        [-2.5379e+00, -1.6696e+00, -2.0588e+00,  ..., -2.2529e-02,\n","         -2.2292e-02, -5.4467e-02],\n","        [-2.1017e+00, -6.5800e-01, -1.3593e+00,  ...,  2.1683e-02,\n","         -1.4672e-02, -2.4222e-02]], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"q-FMMNhFGts5"},"source":["### Experiments"]},{"cell_type":"code","metadata":{"id":"2RFHnK5JGts5"},"source":["model = torch.load('/content/drive/My Drive/Colab Notebooks/Thesis/models/apbd_pytorch/all_actions/all_states_pt/model_pt.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KiADnJGWGts6","executionInfo":{"status":"ok","timestamp":1606839698861,"user_tz":300,"elapsed":680,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"87ec7d1a-ea82-4847-cd88-96b7b3a92215"},"source":["model.l1.weight"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[ 0.6614,  2.1479, -1.6525,  ..., -0.4112, -1.0874,  0.0352],\n","        [-4.8278, -2.2176, -1.6181,  ..., -0.9454,  0.8455, -1.8266],\n","        [-0.3782, -1.3687, -0.5236,  ..., -0.7101,  0.6055, -0.2169],\n","        ...,\n","        [ 0.5531,  1.3833,  6.1786,  ..., -0.3115,  2.3554,  0.5696],\n","        [ 0.3756,  1.5449, -4.1381,  ..., -0.1857, -0.2171,  0.0489],\n","        [-3.6795,  0.9895, -3.0810,  ...,  0.9654, -0.0851, -1.4277]],\n","       device='cuda:0', requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"APqoggjfGts8"},"source":["agent = DQNAgent(scope='dqn',\n","                 action_num=env.action_num,\n","                 replay_memory_init_size=memory_init_size,\n","                 train_every=train_every,\n","                 state_shape=env.state_shape,\n","                 mlp_layers=[520, 1],\n","                 device=torch.device('cuda:0'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_cRD2qfGGts8"},"source":["agent.q_estimator.qnet.fc_layers[2].weight = model.l1.weight\n","agent.q_estimator.qnet.fc_layers[2].bias = model.l1.bias\n","agent.q_estimator.qnet.fc_layers[4].weight = model.l2.weight\n","agent.q_estimator.qnet.fc_layers[4].bias = model.l2.bias"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_eiA5mzGts8","executionInfo":{"status":"ok","timestamp":1606332068646,"user_tz":300,"elapsed":266,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"53fbab47-4a71-4b3f-8b65-a87494db01e8"},"source":["agent.q_estimator.qnet.fc_layers[2].weight\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-1.2913e-02,  1.7555e-02, -6.8227e-02,  ..., -7.2687e-02,\n","          7.2696e-05, -8.6314e-02],\n","        [-7.4512e-02,  4.7105e-02,  6.1485e-02,  ...,  5.1628e-02,\n","          2.0472e-02, -8.7519e-02],\n","        [-2.8611e-02, -2.6829e-02, -4.9708e-02,  ...,  8.7605e-02,\n","          1.5988e-02,  4.0572e-03],\n","        ...,\n","        [ 4.5356e-02,  2.4573e-02, -5.1773e-02,  ...,  3.2959e-02,\n","          2.4060e-03, -4.8993e-03],\n","        [-4.9848e-02, -2.1334e-03, -3.2256e-02,  ...,  1.4862e-02,\n","          7.3959e-02, -6.6445e-02],\n","        [-1.6038e-02, -1.8058e-02, -4.7224e-02,  ...,  1.3438e-02,\n","          6.3478e-02,  9.8711e-03]], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FfL0gB05Gts8","executionInfo":{"status":"ok","timestamp":1606332064290,"user_tz":300,"elapsed":263,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"8fa91ead-73f1-49dd-af57-e8ef1b75720e"},"source":["torch.nn.Parameter(model.l1.weight.cpu())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-1.5348e+00, -1.3212e+00,  1.7455e+00,  ...,  4.4827e-02,\n","          4.6710e-02, -3.4218e-02],\n","        [ 2.9515e+00, -8.4011e-01,  8.9235e-01,  ..., -1.0771e-02,\n","          2.0655e-02, -5.8781e-03],\n","        [-3.3204e-01, -3.1470e-01, -3.7012e-01,  ...,  1.3609e-02,\n","          8.4998e-03,  3.6893e-02],\n","        ...,\n","        [-1.6948e+00, -1.7720e+00,  9.3538e+00,  ..., -1.2536e-02,\n","         -4.9882e-02, -5.5409e-02],\n","        [-2.5379e+00, -1.6696e+00, -2.0588e+00,  ..., -2.2529e-02,\n","         -2.2292e-02, -5.4467e-02],\n","        [-2.1017e+00, -6.5800e-01, -1.3593e+00,  ...,  2.1683e-02,\n","         -1.4672e-02, -2.4222e-02]], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"oSz3nMo_3_5W"},"source":["## Run"]},{"cell_type":"markdown","metadata":{"id":"lriHyOBsFI7I"},"source":["### Pretrained"]},{"cell_type":"code","metadata":{"id":"RW5bbvnvP9zN"},"source":["import copy\n","import numpy as np\n","import pandas as pd\n","import time\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import torch.utils.data as data\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import itertools"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eH218HedWWED"},"source":["from tensorflow.keras.backend import clear_session\n","clear_session()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVjmyHtJRHAp","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1606337459237,"user_tz":300,"elapsed":1168441,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"12434e10-d13b-4411-b088-55748d08e6f9"},"source":["import torch\n","import tensorflow\n","import os\n","\n","import rlcard\n","# from rlcard.agents import DQNAgentPytorch as DQNAgent\n","from rlcard.agents import RandomAgent\n","from rlcard.utils import set_global_seed, tournament\n","from rlcard.utils import Logger\n","\n","# Make environment\n","env = rlcard.make('gin-rummy', config={'seed': 0})\n","eval_env = rlcard.make('gin-rummy', config={'seed': 0})\n","env.game.settings.print_settings()\n","\n","# Set the iterations numbers and how frequently we evaluate/save plot\n","evaluate_every = 100\n","evaluate_num = 100  # mahjong_dqn has 1000\n","episode_num = 1000  # mahjong_dqn has 100000\n","\n","# The initial memory size\n","memory_init_size = 1000\n","\n","# Train the agent every X steps\n","train_every = 1\n","\n","# The paths for saving the logs and learning curves\n","log_dir = './experiments/gin_rummy_dqn_result/apbd'\n","\n","# Set a global seed\n","set_global_seed(0)\n","\n","agent = DQNAgent(scope='dqn',\n","                 action_num=env.action_num,\n","                 replay_memory_init_size=memory_init_size,\n","                 train_every=train_every,\n","                 state_shape=env.state_shape,\n","                 mlp_layers=[520, 52],\n","                 device=torch.device('cpu'))\n","\n","model = torch.load('/content/drive/My Drive/Colab Notebooks/Thesis/models/apbd_pytorch/model_pt.pt')\n","# load pretrained weights\n","agent.q_estimator.qnet.fc_layers[2].weight = torch.nn.Parameter(model.l1.weight.cpu())\n","agent.q_estimator.qnet.fc_layers[2].bias = torch.nn.Parameter(model.l1.bias.cpu())\n","agent.q_estimator.qnet.fc_layers[4].weight = torch.nn.Parameter(model.l2.weight.cpu())\n","agent.q_estimator.qnet.fc_layers[4].bias = torch.nn.Parameter(model.l2.bias.cpu())\n","\n","# agent.target_estimator.qnet.fc_layers[2].weight = torch.nn.Parameter(model.l1.weight.cpu())\n","# agent.target_estimator.qnet.fc_layers[2].bias = torch.nn.Parameter(model.l1.bias.cpu())\n","# agent.target_estimator.qnet.fc_layers[4].weight = torch.nn.Parameter(model.l2.weight.cpu())\n","# agent.target_estimator.qnet.fc_layers[4].bias = torch.nn.Parameter(model.l2.bias.cpu())\n","\n","random_agent = RandomAgent(action_num=eval_env.action_num)\n","env.set_agents([agent, random_agent])\n","eval_env.set_agents([agent, random_agent])\n","\n","# Init a Logger to plot the learning curve\n","logger = Logger(log_dir)\n","\n","for episode in range(episode_num):\n","\n","    # Generate data from the environment\n","    trajectories, _ = env.run(is_training=True)\n","\n","    # Feed transitions into agent memory, and train the agent\n","    for ts in trajectories[0]:\n","        agent.feed(ts)\n","\n","    # Evaluate the performance. Play with random agents.\n","    if episode % evaluate_every == 0:\n","        logger.log_performance(env.timestep, tournament(eval_env, evaluate_num)[0])\n","\n","# Close files in the logger\n","logger.close_files()\n","\n","# Plot the learning curve\n","logger.plot('DQN')\n","\n","# Save model\n","save_dir = 'models/gin_rummy_dqn_pytorch/apbd'\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","state_dict = agent.get_state_dict()\n","print(state_dict. keys())\n","torch.save(state_dict, os.path.join(save_dir, 'model.pth'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["========== Settings ==========\n","scorer_name=GinRummyScorer\n","dealer_for_round=DealerForRound.Random\n","stockpile_dead_card_count=2\n","going_out_deadwood_count=10\n","max_drawn_card_count=52\n","is_allowed_knock=True\n","is_allowed_gin=True\n","is_allowed_pick_up_discard=True\n","is_allowed_to_discard_picked_up_card=False\n","is_always_knock=False\n","is_south_never_knocks=False\n","==============================\n","\n","----------------------------------------\n","  timestep     |  136\n","  reward       |  -0.5181\n","----------------------------------------\n","INFO - Agent dqn, step 1000, rl-loss: 0.1182563379406929\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 2000, rl-loss: 0.04826102405786514\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 3000, rl-loss: 0.030353372916579247\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 4000, rl-loss: 0.011231296695768833\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 5000, rl-loss: 0.011672429740428925\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 5999, rl-loss: 0.0033710268326103687\n","----------------------------------------\n","  timestep     |  11997\n","  reward       |  -0.5047\n","----------------------------------------\n","INFO - Agent dqn, step 6000, rl-loss: 0.0040258001536130905\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 7000, rl-loss: 0.0021210319828242064\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 8000, rl-loss: 0.013961332850158215\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 9000, rl-loss: 0.0010915930615738034\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 10000, rl-loss: 0.0045121535658836365\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 11000, rl-loss: 4.517463457887061e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 12000, rl-loss: 3.159351763315499e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 12145, rl-loss: 0.0017541615525260568\n","----------------------------------------\n","  timestep     |  24288\n","  reward       |  -0.5728\n","----------------------------------------\n","INFO - Agent dqn, step 13000, rl-loss: 0.0019221206894144416\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 14000, rl-loss: 9.879098570308997e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 15000, rl-loss: 5.07323250076297e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 16000, rl-loss: 0.0010077523766085505\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 17000, rl-loss: 1.7429162824100786e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 18000, rl-loss: 2.704106520923233e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 18041, rl-loss: 1.2372532864901586e-07\n","----------------------------------------\n","  timestep     |  36080\n","  reward       |  -0.5477000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 19000, rl-loss: 0.0008490577456541359\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 20000, rl-loss: 7.564556767647446e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 21000, rl-loss: 2.834347583302588e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 22000, rl-loss: 0.00146940303966403\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 23000, rl-loss: 0.0009923761244863272\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 23962, rl-loss: 0.0007365308119915426\n","----------------------------------------\n","  timestep     |  47920\n","  reward       |  -0.6722000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 24000, rl-loss: 3.119868051726371e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 25000, rl-loss: 1.4778856893826742e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 26000, rl-loss: 3.942838020520867e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 27000, rl-loss: 2.7367472284822725e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 28000, rl-loss: 4.424072983510996e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 29000, rl-loss: 0.0011505032889544964\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 29801, rl-loss: 0.0003931579121854156\n","----------------------------------------\n","  timestep     |  59600\n","  reward       |  -0.5046\n","----------------------------------------\n","INFO - Agent dqn, step 30000, rl-loss: 1.8493797426799574e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 31000, rl-loss: 0.0009087240323424339\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 32000, rl-loss: 1.8057195916298951e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 33000, rl-loss: 3.9956614727998385e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 34000, rl-loss: 0.0007055453606881201\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 35000, rl-loss: 0.0020820689387619495\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 35909, rl-loss: 4.5215244881546823e-07\n","----------------------------------------\n","  timestep     |  71814\n","  reward       |  -0.5792999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 36000, rl-loss: 1.7431580090487842e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 37000, rl-loss: 0.0009160472545772791\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 38000, rl-loss: 1.277941663602178e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 39000, rl-loss: 0.0011086987797170877\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 40000, rl-loss: 1.1968651847382716e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 41000, rl-loss: 0.01722598634660244\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 41979, rl-loss: 2.1825123042162886e-08\n","----------------------------------------\n","  timestep     |  83953\n","  reward       |  -0.611\n","----------------------------------------\n","INFO - Agent dqn, step 42000, rl-loss: 0.0003490132512524724\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 43000, rl-loss: 0.01716618984937668\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 44000, rl-loss: 1.1322990900453078e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 45000, rl-loss: 0.00010026321979239583\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 46000, rl-loss: 1.0889453960771789e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 47000, rl-loss: 0.00014275748981162906\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 47916, rl-loss: 1.6054883644756046e-06\n","----------------------------------------\n","  timestep     |  95827\n","  reward       |  -0.5231999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 48000, rl-loss: 1.08661570266122e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 49000, rl-loss: 5.172502426376013e-08\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 50000, rl-loss: 8.823496244758644e-08\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 51000, rl-loss: 5.111098744237097e-08\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 52000, rl-loss: 1.1499420082827783e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 53000, rl-loss: 2.7752205369324656e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 53929, rl-loss: 6.517535098282679e-07\n","----------------------------------------\n","  timestep     |  107856\n","  reward       |  -0.48209999999999986\n","----------------------------------------\n","INFO - Agent dqn, step 54000, rl-loss: 1.794236413843464e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 55000, rl-loss: 0.00021254128660075366\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 56000, rl-loss: 1.3101049489705474e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 57000, rl-loss: 0.001017310656607151\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 58000, rl-loss: 2.7996447826694748e-08\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 59000, rl-loss: 0.001115881372243166\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 59968, rl-loss: 4.658596139961446e-07./experiments/gin_rummy_dqn_result/apbd/performance.csv\n","dict_keys(['dqn_q_estimator', 'dqn_target_estimator'])\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"huWWevd_Hxqe"},"source":["### Pretrained All States"]},{"cell_type":"code","metadata":{"id":"0OclTTHRHxqe"},"source":["import copy\n","import numpy as np\n","import pandas as pd\n","import time\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import torch.utils.data as data\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import itertools"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ilBx3V-THxqe"},"source":["from tensorflow.keras.backend import clear_session\n","clear_session()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0eeM3GH5Hxqe","executionInfo":{"status":"ok","timestamp":1608751563679,"user_tz":300,"elapsed":1546331,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"09144838891693247193"}},"outputId":"028ed222-1d4f-412b-b185-5213a1c2ae6d"},"source":["import torch\n","import tensorflow\n","import os\n","\n","import rlcard\n","# from rlcard.agents import DQNAgentPytorch as DQNAgent\n","from rlcard.agents import RandomAgent\n","from rlcard.utils import set_global_seed, tournament\n","from rlcard.utils import Logger\n","\n","# Make environment\n","env = rlcard.make('gin-rummy', config={'seed': 0})\n","eval_env = rlcard.make('gin-rummy', config={'seed': 0})\n","env.game.settings.print_settings()\n","\n","# Set the iterations numbers and how frequently we evaluate/save plot\n","evaluate_every = 100\n","evaluate_num = 100  # mahjong_dqn has 1000\n","episode_num = 5000  # mahjong_dqn has 100000\n","# episode_num = 1000  # mahjong_dqn has 100000\n","\n","# The initial memory size\n","memory_init_size = 1000\n","\n","# Train the agent every X steps\n","train_every = 1\n","\n","# The paths for saving the logs and learning curves\n","log_dir = './experiments/gin_rummy_dqn_result/all/all'\n","\n","# Set a global seed\n","set_global_seed(0)\n","\n","agent = DQNAgent(scope='dqn',\n","                 action_num=env.action_num,\n","                 replay_memory_init_size=memory_init_size,\n","                 train_every=train_every,\n","                 state_shape=env.state_shape,\n","                 mlp_layers=[520, 110],\n","                 device=torch.device('cuda:0'))\n","\n","model = torch.load('/content/drive/My Drive/Colab Notebooks/Thesis/models/all/all/all_states_all_actions/model.pt')\n","# load pretrained weights\n","agent.q_estimator.qnet.fc_layers[2].weight = torch.nn.Parameter(model.l1.weight)\n","agent.q_estimator.qnet.fc_layers[2].bias = torch.nn.Parameter(model.l1.bias)\n","agent.q_estimator.qnet.fc_layers[4].weight = torch.nn.Parameter(model.l2.weight)\n","agent.q_estimator.qnet.fc_layers[4].bias = torch.nn.Parameter(model.l2.bias)\n","\n","agent.target_estimator.qnet.fc_layers[2].weight = torch.nn.Parameter(model.l1.weight)\n","agent.target_estimator.qnet.fc_layers[2].bias = torch.nn.Parameter(model.l1.bias)\n","agent.target_estimator.qnet.fc_layers[4].weight = torch.nn.Parameter(model.l2.weight)\n","agent.target_estimator.qnet.fc_layers[4].bias = torch.nn.Parameter(model.l2.bias)\n","\n","random_agent = RandomAgent(action_num=eval_env.action_num)\n","env.set_agents([agent, random_agent])\n","eval_env.set_agents([agent, random_agent])\n","\n","# Init a Logger to plot the learning curve\n","logger = Logger(log_dir)\n","\n","for episode in range(episode_num):\n","\n","    # Generate data from the environment\n","    trajectories, _ = env.run(is_training=True)\n","\n","    # Feed transitions into agent memory, and train the agent\n","    for ts in trajectories[0]:\n","        agent.feed(ts)\n","\n","    # Evaluate the performance. Play with random agents.\n","    if episode % evaluate_every == 0:\n","        logger.log_performance(env.timestep, tournament(eval_env, evaluate_num)[0])\n","\n","# Close files in the logger\n","logger.close_files()\n","\n","# Plot the learning curve\n","logger.plot('DQN')\n","\n","# Save model\n","save_dir = 'models/gin_rummy_dqn_pytorch/all/all'\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","state_dict = agent.get_state_dict()\n","print(state_dict. keys())\n","torch.save(state_dict, os.path.join(save_dir, 'model.pth'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["========== Settings ==========\n","scorer_name=GinRummyScorer\n","dealer_for_round=DealerForRound.Random\n","stockpile_dead_card_count=2\n","going_out_deadwood_count=10\n","max_drawn_card_count=52\n","is_allowed_knock=True\n","is_allowed_gin=True\n","is_allowed_pick_up_discard=True\n","is_allowed_to_discard_picked_up_card=False\n","is_always_knock=False\n","is_south_never_knocks=False\n","==============================\n","\n","----------------------------------------\n","  timestep     |  136\n","  reward       |  -0.5909000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 1000, rl-loss: 0.032099902629852295\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 2000, rl-loss: 0.0527745857834816\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 3000, rl-loss: 0.06917478144168854\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 4000, rl-loss: 0.026052217930555344\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 5000, rl-loss: 0.026429984718561172\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 5949, rl-loss: 0.03115980513393879\n","----------------------------------------\n","  timestep     |  11897\n","  reward       |  -0.46070000000000005\n","----------------------------------------\n","INFO - Agent dqn, step 6000, rl-loss: 0.02975451573729515\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 7000, rl-loss: 0.015216227620840073\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 8000, rl-loss: 0.012261766940355301\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 9000, rl-loss: 0.004525021184235811\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 10000, rl-loss: 0.006025578826665878\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 11000, rl-loss: 0.008032558485865593\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 12000, rl-loss: 0.004875085782259703\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 12209, rl-loss: 0.002579289022833109\n","----------------------------------------\n","  timestep     |  24419\n","  reward       |  -0.4491999999999998\n","----------------------------------------\n","INFO - Agent dqn, step 13000, rl-loss: 0.0015203491784632206\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 14000, rl-loss: 0.005960938520729542\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 15000, rl-loss: 0.001430405187420547\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 16000, rl-loss: 0.00029374868609011173\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 17000, rl-loss: 0.0014035303611308336\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 18000, rl-loss: 0.0002408337313681841\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 18566, rl-loss: 0.0012416605604812503\n","----------------------------------------\n","  timestep     |  37133\n","  reward       |  -0.6474999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 19000, rl-loss: 0.002175954869017005\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 20000, rl-loss: 0.00028029322857037187\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 21000, rl-loss: 0.0010801688767969608\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 22000, rl-loss: 0.0020870156586170197\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 23000, rl-loss: 0.002718784147873521\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 24000, rl-loss: 0.0019253529608249664\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 24697, rl-loss: 0.0005306982202455401\n","----------------------------------------\n","  timestep     |  49397\n","  reward       |  -0.5403999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 25000, rl-loss: 0.00046108633978292346\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 26000, rl-loss: 5.354225868359208e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 27000, rl-loss: 0.0012284156400710344\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 28000, rl-loss: 0.0009683818789198995\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 29000, rl-loss: 0.00030392565531656146\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 30000, rl-loss: 0.0011091011110693216\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 30835, rl-loss: 4.358398655313067e-05\n","----------------------------------------\n","  timestep     |  61671\n","  reward       |  -0.5468999999999998\n","----------------------------------------\n","INFO - Agent dqn, step 31000, rl-loss: 0.0795825719833374\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 32000, rl-loss: 1.5684474419686012e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 33000, rl-loss: 3.426774492254481e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 34000, rl-loss: 0.0009292380418628454\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 35000, rl-loss: 0.0012301072711125016\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 36000, rl-loss: 0.0002505265292711556\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 36985, rl-loss: 0.0006249909056350589\n","----------------------------------------\n","  timestep     |  73968\n","  reward       |  -0.48799999999999977\n","----------------------------------------\n","INFO - Agent dqn, step 37000, rl-loss: 0.0001017496979329735\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 38000, rl-loss: 9.044227044796571e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 39000, rl-loss: 1.2416576282703318e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 40000, rl-loss: 4.832085323869251e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 41000, rl-loss: 7.020066550467163e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 42000, rl-loss: 0.00019965908722952008\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 43000, rl-loss: 9.503308683633804e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 43045, rl-loss: 0.00015756263746879995\n","----------------------------------------\n","  timestep     |  86087\n","  reward       |  -0.5654999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 44000, rl-loss: 0.00012022427836200222\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 45000, rl-loss: 6.548789315274917e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 46000, rl-loss: 0.0005857898504473269\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 47000, rl-loss: 2.811390686474624e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 48000, rl-loss: 0.0015010398346930742\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 49000, rl-loss: 6.183247751323506e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 49203, rl-loss: 0.0013352599926292896\n","----------------------------------------\n","  timestep     |  98404\n","  reward       |  -0.679\n","----------------------------------------\n","INFO - Agent dqn, step 50000, rl-loss: 1.6979669453576207e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 51000, rl-loss: 3.444131289143115e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 52000, rl-loss: 0.00016117779887281358\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 53000, rl-loss: 0.0005270889960229397\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 54000, rl-loss: 0.0004949367721565068\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 55000, rl-loss: 9.986838449549396e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 55135, rl-loss: 3.202389052603394e-05\n","----------------------------------------\n","  timestep     |  110266\n","  reward       |  -0.49939999999999984\n","----------------------------------------\n","INFO - Agent dqn, step 56000, rl-loss: 1.7542222394695273e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 57000, rl-loss: 6.567218520103779e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 58000, rl-loss: 2.614719414850697e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 59000, rl-loss: 3.5661614674609154e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 60000, rl-loss: 1.7508955352241173e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 61000, rl-loss: 1.067667085408175e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 61173, rl-loss: 0.0015345406718552113\n","----------------------------------------\n","  timestep     |  122340\n","  reward       |  -0.5153\n","----------------------------------------\n","INFO - Agent dqn, step 62000, rl-loss: 2.482303898432292e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 63000, rl-loss: 0.000807599164545536\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 64000, rl-loss: 0.00022974076273385435\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 65000, rl-loss: 1.6577549786234158e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 66000, rl-loss: 4.187187005300075e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 67000, rl-loss: 9.739469533087686e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 67239, rl-loss: 0.0017716882284730673\n","----------------------------------------\n","  timestep     |  134473\n","  reward       |  -0.5773\n","----------------------------------------\n","INFO - Agent dqn, step 68000, rl-loss: 0.0011988055193796754\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 69000, rl-loss: 1.6262357576124487e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 70000, rl-loss: 1.337581807092647e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 71000, rl-loss: 7.333769076467433e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 72000, rl-loss: 6.817260782554513e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 73000, rl-loss: 0.0017456432105973363\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 73315, rl-loss: 0.0011580351274460554\n","----------------------------------------\n","  timestep     |  146627\n","  reward       |  -0.6029000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 74000, rl-loss: 4.728930491637584e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 75000, rl-loss: 1.4637015510743367e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 76000, rl-loss: 7.154085324145854e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 77000, rl-loss: 6.902798486407846e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 78000, rl-loss: 0.0007973528117872775\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 79000, rl-loss: 0.00022516056196764112\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 79372, rl-loss: 0.0011489110765978694\n","----------------------------------------\n","  timestep     |  158741\n","  reward       |  -0.5186\n","----------------------------------------\n","INFO - Agent dqn, step 80000, rl-loss: 0.001117543550208211\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 81000, rl-loss: 7.3814835559460334e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 82000, rl-loss: 1.2234411769895814e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 83000, rl-loss: 7.718714186921716e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 84000, rl-loss: 0.001545222825370729\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 85000, rl-loss: 0.0005535723175853491\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 85260, rl-loss: 2.898560524045024e-05\n","----------------------------------------\n","  timestep     |  170513\n","  reward       |  -0.669\n","----------------------------------------\n","INFO - Agent dqn, step 86000, rl-loss: 0.0003632427251432091\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 87000, rl-loss: 7.643858407391235e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 88000, rl-loss: 0.0001996248756768182\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 89000, rl-loss: 1.1335631825204473e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 90000, rl-loss: 0.002011601347476244\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 91000, rl-loss: 0.0012938834261149168\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 91246, rl-loss: 1.0356816346757114e-05\n","----------------------------------------\n","  timestep     |  182486\n","  reward       |  -0.6226000000000002\n","----------------------------------------\n","INFO - Agent dqn, step 92000, rl-loss: 0.001400099485181272\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 93000, rl-loss: 0.0018965823110193014\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 94000, rl-loss: 0.0010222512064501643\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 95000, rl-loss: 0.0003329927858430892\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 96000, rl-loss: 0.000950885470956564\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 97000, rl-loss: 0.0005638067959807813\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 97241, rl-loss: 0.0010177793446928263\n","----------------------------------------\n","  timestep     |  194474\n","  reward       |  -0.6063000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 98000, rl-loss: 0.0007255567470565438\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 99000, rl-loss: 0.00011480330431368202\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 100000, rl-loss: 0.0017131227068603039\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 101000, rl-loss: 0.0007249317714013159\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 102000, rl-loss: 0.0005060682888142765\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 103000, rl-loss: 2.565006525401259e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 103206, rl-loss: 0.00042523961747065187\n","----------------------------------------\n","  timestep     |  206404\n","  reward       |  -0.5564000000000003\n","----------------------------------------\n","INFO - Agent dqn, step 104000, rl-loss: 0.0018377683591097593\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 105000, rl-loss: 0.001915037864819169\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 106000, rl-loss: 2.2861788693262497e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 107000, rl-loss: 1.995197635551449e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 108000, rl-loss: 2.2086555873102043e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 109000, rl-loss: 0.0004998520016670227\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 109251, rl-loss: 3.907407517544925e-06\n","----------------------------------------\n","  timestep     |  218493\n","  reward       |  -0.43060000000000004\n","----------------------------------------\n","INFO - Agent dqn, step 110000, rl-loss: 0.0008031983161345124\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 111000, rl-loss: 0.0015328156296163797\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 112000, rl-loss: 0.0013663350837305188\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 113000, rl-loss: 0.0010295381071045995\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 114000, rl-loss: 3.464931796770543e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 115000, rl-loss: 0.0005243702908046544\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 115210, rl-loss: 5.9722104197135195e-05\n","----------------------------------------\n","  timestep     |  230411\n","  reward       |  -0.6531999999999997\n","----------------------------------------\n","INFO - Agent dqn, step 116000, rl-loss: 8.29162854643073e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 117000, rl-loss: 0.0011273955460637808\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 118000, rl-loss: 2.651722024893388e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 119000, rl-loss: 0.0003054533735848963\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 120000, rl-loss: 0.0003832121437881142\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 121000, rl-loss: 0.00024289160501211882\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 121241, rl-loss: 0.0006050656083971262\n","----------------------------------------\n","  timestep     |  242471\n","  reward       |  -0.6062000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 122000, rl-loss: 0.000695742026437074\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 123000, rl-loss: 0.0009042163728736341\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 124000, rl-loss: 2.1646297682309523e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 125000, rl-loss: 9.756535291671753e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 126000, rl-loss: 0.00028072981513105333\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 127000, rl-loss: 5.890549800824374e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 127057, rl-loss: 4.369373527879361e-06\n","----------------------------------------\n","  timestep     |  254104\n","  reward       |  -0.5187999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 128000, rl-loss: 0.0012203322257846594\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 129000, rl-loss: 1.8654576706467196e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 130000, rl-loss: 0.0005042859702371061\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 131000, rl-loss: 1.824760329327546e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 132000, rl-loss: 0.00020532608323264867\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 132986, rl-loss: 1.2214421985845547e-05\n","----------------------------------------\n","  timestep     |  265965\n","  reward       |  -0.4841\n","----------------------------------------\n","INFO - Agent dqn, step 133000, rl-loss: 1.1062213161494583e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 134000, rl-loss: 0.0004328992508817464\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 135000, rl-loss: 8.24430571810808e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 136000, rl-loss: 1.0752797606983222e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 137000, rl-loss: 0.00025020536850206554\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 138000, rl-loss: 8.920551408664323e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 138799, rl-loss: 3.6293763514549937e-06\n","----------------------------------------\n","  timestep     |  277588\n","  reward       |  -0.7214000000000002\n","----------------------------------------\n","INFO - Agent dqn, step 139000, rl-loss: 1.3015047670705826e-06\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 140000, rl-loss: 2.750329883838276e-07\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 141000, rl-loss: 0.0009619612828828394\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 142000, rl-loss: 0.0012903539463877678\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 143000, rl-loss: 0.0004938277998007834\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 144000, rl-loss: 0.00033866168814711273\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 144705, rl-loss: 1.3240867701824754e-05\n","----------------------------------------\n","  timestep     |  289401\n","  reward       |  -0.5420999999999998\n","----------------------------------------\n","INFO - Agent dqn, step 145000, rl-loss: 0.000103390084404964\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 146000, rl-loss: 0.0021965703926980495\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 147000, rl-loss: 1.004532714432571e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 148000, rl-loss: 0.0003362942370586097\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 149000, rl-loss: 1.2487678759498522e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 150000, rl-loss: 0.00031416595447808504\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 150639, rl-loss: 0.0001211254348163493\n","----------------------------------------\n","  timestep     |  301268\n","  reward       |  -0.47059999999999996\n","----------------------------------------\n","INFO - Agent dqn, step 151000, rl-loss: 1.5015763892733958e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 152000, rl-loss: 1.2546015568659641e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 153000, rl-loss: 0.001026919111609459\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 154000, rl-loss: 2.0122221030760556e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 155000, rl-loss: 0.0001556656206957996\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 156000, rl-loss: 0.0003145962837152183\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 156542, rl-loss: 0.000640055921394378\n","----------------------------------------\n","  timestep     |  313071\n","  reward       |  -0.6016999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 157000, rl-loss: 7.415521395159885e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 158000, rl-loss: 0.0005395271582528949\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 159000, rl-loss: 0.0003354747605044395\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 160000, rl-loss: 4.515681939665228e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 161000, rl-loss: 0.0001250850036740303\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 162000, rl-loss: 0.019603867083787918\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 162560, rl-loss: 9.857811164692976e-06\n","----------------------------------------\n","  timestep     |  325108\n","  reward       |  -0.5456\n","----------------------------------------\n","INFO - Agent dqn, step 163000, rl-loss: 6.758861854905263e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 164000, rl-loss: 5.229261296335608e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 165000, rl-loss: 0.0003020204312633723\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 166000, rl-loss: 1.69283666764386e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 167000, rl-loss: 1.6586907804594375e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 168000, rl-loss: 0.00013885856606066227\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 168439, rl-loss: 0.0004617493541445583\n","----------------------------------------\n","  timestep     |  336869\n","  reward       |  -0.5912999999999998\n","----------------------------------------\n","INFO - Agent dqn, step 169000, rl-loss: 0.0025870581157505512\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 170000, rl-loss: 0.0002390241133980453\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 171000, rl-loss: 1.3176686479710042e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 172000, rl-loss: 0.0008717916207388043\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 173000, rl-loss: 0.0017749059479683638\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 174000, rl-loss: 0.00034014153061434627\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 174682, rl-loss: 0.0014976148959249258\n","----------------------------------------\n","  timestep     |  349353\n","  reward       |  -0.6539999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 175000, rl-loss: 1.4577523870684672e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 176000, rl-loss: 0.0003377253015059978\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 177000, rl-loss: 0.00012102961773052812\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 178000, rl-loss: 3.0150489692459814e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 179000, rl-loss: 0.00242222030647099\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 180000, rl-loss: 5.7489047321723774e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 180925, rl-loss: 2.849343763955403e-05\n","----------------------------------------\n","  timestep     |  361838\n","  reward       |  -0.5818999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 181000, rl-loss: 0.00014435431512538344\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 182000, rl-loss: 0.0033430648036301136\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 183000, rl-loss: 3.6284938687458634e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 184000, rl-loss: 0.0010143248364329338\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 185000, rl-loss: 0.00042198109440505505\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 186000, rl-loss: 0.0007620244869031012\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 186979, rl-loss: 0.00011123034346383065\n","----------------------------------------\n","  timestep     |  373946\n","  reward       |  -0.5518\n","----------------------------------------\n","INFO - Agent dqn, step 187000, rl-loss: 0.0006252357270568609\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 188000, rl-loss: 0.00045163961476646364\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 189000, rl-loss: 0.001348466845229268\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 190000, rl-loss: 4.998285658075474e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 191000, rl-loss: 0.0007540545193478465\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 192000, rl-loss: 3.823571023531258e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 193000, rl-loss: 7.763708708807826e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 193320, rl-loss: 0.0009272666648030281\n","----------------------------------------\n","  timestep     |  386631\n","  reward       |  -0.6987999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 194000, rl-loss: 6.135473086033016e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 195000, rl-loss: 0.001871500164270401\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 196000, rl-loss: 6.144399230834097e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 197000, rl-loss: 0.0007420326583087444\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 198000, rl-loss: 0.00021348960581235588\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 199000, rl-loss: 0.0003419402928557247\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 199591, rl-loss: 0.0190404262393713\n","----------------------------------------\n","  timestep     |  399172\n","  reward       |  -0.5938\n","----------------------------------------\n","INFO - Agent dqn, step 200000, rl-loss: 0.0010742135345935822\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 201000, rl-loss: 2.6876386982621625e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 202000, rl-loss: 0.00035090497112832963\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 203000, rl-loss: 5.877237344975583e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 204000, rl-loss: 4.075230754096992e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 205000, rl-loss: 0.0004392716218717396\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 205323, rl-loss: 5.6973374739754945e-05\n","----------------------------------------\n","  timestep     |  410638\n","  reward       |  -0.5293999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 206000, rl-loss: 8.67307826410979e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 207000, rl-loss: 0.0005503842257894576\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 208000, rl-loss: 0.01547800563275814\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 209000, rl-loss: 1.7822905647335574e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 210000, rl-loss: 0.000298125873086974\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 211000, rl-loss: 0.00046934018610045314\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 211374, rl-loss: 0.0005964926676824689\n","----------------------------------------\n","  timestep     |  422739\n","  reward       |  -0.6265\n","----------------------------------------\n","INFO - Agent dqn, step 212000, rl-loss: 0.0024130474776029587\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 213000, rl-loss: 0.0009659426286816597\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 214000, rl-loss: 0.0012136620935052633\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 215000, rl-loss: 3.510995156830177e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 216000, rl-loss: 0.0011060378747060895\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 217000, rl-loss: 0.0001000686752377078\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 217830, rl-loss: 0.0012041470035910606\n","----------------------------------------\n","  timestep     |  435650\n","  reward       |  -0.4915000000000002\n","----------------------------------------\n","INFO - Agent dqn, step 218000, rl-loss: 0.0033326130360364914\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 219000, rl-loss: 0.00043505325447767973\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 220000, rl-loss: 0.0007619807729497552\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 221000, rl-loss: 0.0015077099669724703\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 222000, rl-loss: 0.00042644745553843677\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 223000, rl-loss: 0.0004888954572379589\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 224000, rl-loss: 0.001432268531061709\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 224021, rl-loss: 0.00023129711917135864\n","----------------------------------------\n","  timestep     |  448028\n","  reward       |  -0.5582000000000003\n","----------------------------------------\n","INFO - Agent dqn, step 225000, rl-loss: 0.0013420787872746587\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 226000, rl-loss: 0.0010392926633358002\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 227000, rl-loss: 0.000265985174337402\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 228000, rl-loss: 0.0007110199658200145\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 229000, rl-loss: 0.001376856816932559\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 230000, rl-loss: 0.0010872958227992058\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 230020, rl-loss: 0.00012780986435245723\n","----------------------------------------\n","  timestep     |  460026\n","  reward       |  -0.6374999999999998\n","----------------------------------------\n","INFO - Agent dqn, step 231000, rl-loss: 2.9245898986118846e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 232000, rl-loss: 5.421514651970938e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 233000, rl-loss: 0.001191415823996067\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 234000, rl-loss: 3.2251205993816257e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 235000, rl-loss: 4.797369911102578e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 235838, rl-loss: 0.002654572483152151\n","----------------------------------------\n","  timestep     |  471658\n","  reward       |  -0.6140000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 236000, rl-loss: 2.7560563466977328e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 237000, rl-loss: 3.550959809217602e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 238000, rl-loss: 3.075041968259029e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 239000, rl-loss: 0.0007237442187033594\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 240000, rl-loss: 0.00011666480713756755\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 241000, rl-loss: 3.4108983527403325e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 242000, rl-loss: 3.0075087124714628e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 242294, rl-loss: 0.0001521971425972879\n","----------------------------------------\n","  timestep     |  484568\n","  reward       |  -0.4704\n","----------------------------------------\n","INFO - Agent dqn, step 243000, rl-loss: 0.0005348737468011677\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 244000, rl-loss: 0.00022373147658072412\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 245000, rl-loss: 2.5865097995847464e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 246000, rl-loss: 5.719540058635175e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 247000, rl-loss: 0.0024711855221539736\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 248000, rl-loss: 0.00013174726336728781\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 248558, rl-loss: 0.0002901691768784076\n","----------------------------------------\n","  timestep     |  497096\n","  reward       |  -0.6502\n","----------------------------------------\n","INFO - Agent dqn, step 249000, rl-loss: 2.5364286557305604e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 250000, rl-loss: 0.0014143276493996382\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 251000, rl-loss: 2.120258068316616e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 252000, rl-loss: 1.8107093637809157e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 253000, rl-loss: 3.148367250105366e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 254000, rl-loss: 0.002140878699719906\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 254756, rl-loss: 7.434211147483438e-05\n","----------------------------------------\n","  timestep     |  509492\n","  reward       |  -0.5501000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 255000, rl-loss: 3.576184099074453e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 256000, rl-loss: 3.5929770092479885e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 257000, rl-loss: 0.00015921791782602668\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 258000, rl-loss: 2.2068150428822264e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 259000, rl-loss: 2.9122867999831215e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 260000, rl-loss: 4.050857751281001e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 260730, rl-loss: 0.000731444510165602\n","----------------------------------------\n","  timestep     |  521442\n","  reward       |  -0.5744000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 261000, rl-loss: 0.00019738898845389485\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 262000, rl-loss: 0.0015283559914678335\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 263000, rl-loss: 3.2861658837646246e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 264000, rl-loss: 0.0010627269512042403\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 265000, rl-loss: 3.3148840884678066e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 266000, rl-loss: 0.0019337930716574192\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 266697, rl-loss: 8.699898899067193e-05\n","----------------------------------------\n","  timestep     |  533373\n","  reward       |  -0.6145000000000003\n","----------------------------------------\n","INFO - Agent dqn, step 267000, rl-loss: 3.19819082506001e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 268000, rl-loss: 4.3754942453233525e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 269000, rl-loss: 4.433023423189297e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 270000, rl-loss: 0.003036201000213623\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 271000, rl-loss: 3.0331590096466243e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 272000, rl-loss: 0.0009117244626395404\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 272682, rl-loss: 0.0009739614906720817\n","----------------------------------------\n","  timestep     |  545343\n","  reward       |  -0.5073999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 273000, rl-loss: 4.607447044691071e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 274000, rl-loss: 0.0009251454030163586\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 275000, rl-loss: 2.8214628400746733e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 276000, rl-loss: 0.0015403940342366695\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 277000, rl-loss: 8.803729724604636e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 278000, rl-loss: 0.001426301314495504\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 278838, rl-loss: 7.533837924711406e-05\n","----------------------------------------\n","  timestep     |  557653\n","  reward       |  -0.5987999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 279000, rl-loss: 0.0007139737717807293\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 280000, rl-loss: 9.599963232176378e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 281000, rl-loss: 0.07000095397233963\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 282000, rl-loss: 6.255459447856992e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 283000, rl-loss: 9.691073501016945e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 284000, rl-loss: 0.008156996220350266\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 285000, rl-loss: 0.00011965810699621215\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 285130, rl-loss: 0.00018227414693683386\n","----------------------------------------\n","  timestep     |  570239\n","  reward       |  -0.5243000000000001\n","----------------------------------------\n","INFO - Agent dqn, step 286000, rl-loss: 3.3202992199221626e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 287000, rl-loss: 0.000792709703091532\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 288000, rl-loss: 0.0002984959864988923\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 289000, rl-loss: 0.00023940205574035645\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 290000, rl-loss: 0.0001460760977352038\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 291000, rl-loss: 0.0020161124411970377\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 291102, rl-loss: 0.00016545278776902705\n","----------------------------------------\n","  timestep     |  582181\n","  reward       |  -0.6543000000000002\n","----------------------------------------\n","INFO - Agent dqn, step 292000, rl-loss: 2.129934546246659e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 293000, rl-loss: 3.088418816332705e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 294000, rl-loss: 0.00024213717551901937\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 295000, rl-loss: 0.0017971418565139174\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 296000, rl-loss: 1.5314886695705354e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 297000, rl-loss: 2.7373884222470224e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 297119, rl-loss: 0.0002833915641531348\n","----------------------------------------\n","  timestep     |  594212\n","  reward       |  -0.5331999999999999\n","----------------------------------------\n","INFO - Agent dqn, step 298000, rl-loss: 1.7108624888351187e-05\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 299000, rl-loss: 0.002043894026428461\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 300000, rl-loss: 0.000631310511380434\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 301000, rl-loss: 0.00012969553063157946\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 302000, rl-loss: 0.0006311542820185423\n","INFO - Copied model parameters to target network.\n","INFO - Agent dqn, step 302915, rl-loss: 0.0012090629898011684./experiments/gin_rummy_dqn_result/all/all/performance.csv\n","dict_keys(['dqn_q_estimator', 'dqn_target_estimator'])\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}