{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"testAgents.ipynb","provenance":[],"collapsed_sections":["Ssj566eQMxKZ","qfjPoV0kM1NH","o1K0a747bja2","Bh93Ni3UszBL","u-hik2PLM6C2","11qEEpVcXSun","JIhyFRnjM_b-","kvykr4ZNvJZo","xjPYLr9oQ0SF","hBud_g_iQ5mn","t8siavYqRA6-","mK_BCGBJRGVh","zLTh_vClL43-","chfSSIbcRf1O","yER8W1H6Tmrv","2jccNspv8TIU","3tJtalCWmSWg","Obh8tO1ACToR","xD_LPqg2Tmr8","__YaixA_-ptV","yfapetWbXYeK","6RteokMRTmr9","Tdlo_RBV_0My","ek7y1eUesdB_","zPCsf4xtLb2Y","fXMEVRAYaWxh","exdOodaMbM19","v6hZ20SyawMN","wSP0-kJJmJQx","vCw-aVV5mJQy","Fr7DkNeDPK92","qsoopxWKPK9-","XbeIWmq4PK-C","pw3LUwmACPTV","b78NCgV9khFx","KOqJvPwqkhF1","dYf7ekELkhF3","QPE2Zfxu_OLV","ih9xBPKv_OLb","_AJXErL2_OLe","fuyMPmFTbOOV","6stI04TLem_6","Z5rFgVueBlg1","BV3biIINBlg4","GuovHRq5tiF5","fvrT3Vb3tiF6","OpUrywYQtiF9","BwJOoFwd5WHo","gYo1esHTSJY2","pGCl6K26TBt6","aqTsIwHbqpin","oxy_G_tqE8L3","SYymyUOz5WH0","GcgNJXp05WH1","ke-DQfbpsMdc","BTV4Ge0BsMdm","zNUWKThSsMdp","kuPiD3xxaLH7","tS7qXlDjaLH8","m_RHwnW9aLH9","Y6looxhFsJa-","T0dmaiblsJbO","I-mOrFNVsJbP","ijh7E63Pruf_","daKKvjiprugR","NEEKt1strugU","21PObgbOD75E","1cSADqo6yWtQ","lyLf9qIaD75L","5x2D901HD75O","L1KuXQusqQmX","NuvJtnWK0x8p","BuSCKeFsqQmc","Mf3ym5UPqQmf","0XBq4MHG6ugb","7_Wawx4v6ugt","SB9LW0BW6ugv","D3TEziyNZ2Bh","MBNA7FOd46W8","qvDjo4AqZ2Bl","ZR4ZEGIZZ2Bn","FICJzP2Qyflk","Wi8TR_UmrE23","VF0f6rRyyfl2","gnhbtFfXT5tU","jRDlFr6BrtD7","hm0ghfYvVKjZ","qN33bkHlsWJh","1dDypQcrsTlD","_TzQ2YoZly8b","LSGRQrlB8NUn"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RubzqOlEW1H2","executionInfo":{"status":"ok","timestamp":1616976470483,"user_tz":240,"elapsed":19824,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"8919ff90-3b24-4ca5-f9a4-bbf19a13aa99"},"source":["# Run this cell to mount your Google Drive.\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ssj566eQMxKZ"},"source":["# Gin Rummy"]},{"cell_type":"code","metadata":{"id":"KPCni-gdFFeE"},"source":["pth = '/content/drive/MyDrive/Colab Notebooks/Thesis'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6Hs2guSyLy_"},"source":["all_classes = ['SP0','SP1','Draw','Pickup','DH','GIN',\n","               'AS', '2S', '3S', '4S', '5S', '6S', '7S', '8S', '9S', 'TS', 'JS', 'QS', 'KS',\n","               'AH', '2H', '3H', '4H', '5H', '6H', '7H', '8H', '9H', 'TH', 'JH', 'QH', 'KH',\n","               'AD', '2D', '3D', '4D', '5D', '6D', '7D', '8D', '9D', 'TD', 'JD', 'QD', 'KD',\n","               'AC', '2C', '3C', '4C', '5C', '6C', '7C', '8C', '9C', 'TC', 'JC', 'QC', 'KC',\n","               'AS', '2S', '3S', '4S', '5S', '6S', '7S', '8S', '9S', 'TS', 'JS', 'QS', 'KS',\n","               'AH', '2H', '3H', '4H', '5H', '6H', '7H', '8H', '9H', 'TH', 'JH', 'QH', 'KH',\n","               'AD', '2D', '3D', '4D', '5D', '6D', '7D', '8D', '9D', 'TD', 'JD', 'QD', 'KD',\n","               'AC', '2C', '3C', '4C', '5C', '6C', '7C', '8C', '9C', 'TC', 'JC', 'QC', 'KC']\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qfjPoV0kM1NH"},"source":["## Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZZ3FbZfWmdn","executionInfo":{"status":"ok","timestamp":1616976616868,"user_tz":240,"elapsed":5601,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"502a181c-e9bc-41fb-f156-52c3bffb881a"},"source":["#-------------------------------------------------------------------------------\n","# The following code was originally written by Todd Neller in Java.\n","# It was translated into Python by Anthony Hein.\n","#-------------------------------------------------------------------------------\n","\n","#-------------------------------------------------------------------------------\n","# A class for modeling a game of Gin Rummy\n","# @author Todd W. Neller\n","# @version 1.0\n","#-------------------------------------------------------------------------------\n","\n","#-------------------------------------------------------------------------------\n","# Copyright (C) 2020 Todd Neller\n","#\n","# This program is free software; you can redistribute it and/or\n","# modify it under the terms of the GNU General Public License\n","# as published by the Free Software Foundation; either version 2\n","# of the License, or (at your option) any later version.\n","#\n","# This program is distributed in the hope that it will be useful,\n","# but WITHOUT ANY WARRANTY; without even the implied warranty of\n","# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","# GNU General Public License for more details.\n","#\n","# Information about the GNU General Public License is available online at:\n","#   http://www.gnu.org/licenses/\n","# To receive a copy of the GNU General Public License, write to the Free\n","# Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n","# 02111-1307, USA.\n","#-------------------------------------------------------------------------------\n","\n","import random\n","import time\n","import numpy as np\n","import os\n","import torch\n","\n","%cd /content/drive/My Drive/Colab Notebooks/Thesis/GinRummy\n","\n","from Deck import Deck\n","from GinRummyUtil import GinRummyUtil\n","from SimpleGinRummyPlayer import SimpleGinRummyPlayer\n","\n","%cd /content/drive/My Drive/Colab Notebooks/Thesis/SupervisedLearning\n","\n","from models import *\n","\n","%cd /content/drive/My Drive/Colab Notebooks/Thesis\n","#-------------------------------------------------------------------------------\n","\n","# TRACKING\n","# Plane (5x52)      Feature\n","# 0\t currHand       the cards in current player's hand\n","# 1\t topCard        the top card of the discard pile\n","# 2\t deadCard       the dead cards: cards in discard pile (excluding the top card)\n","# 3\t oppCard        opponent known cards: cards picked up from discard pile, but not discarded\n","# 4\t unknownCard    the unknown cards: cards in stockpile or in opponent hand (but not known)\n","\n","# Action ID         Action\n","# 0\t                score_player_0_action\n","# 1\t                score_player_1_action\n","# 2\t                draw_card_action\n","# 3\t                pick_up_discard_action\n","# 4\t                declare_dead_hand_action\n","# 5\t                gin_action\n","# 6 - 57\t        discard_action\n","# 58 - 109\t        knock_action\n","\n","# Knock_bin\n","# Action ID         Action\n","# 0\t                No Knock\n","# 1\t                Knock\n","\n","def one_hot(cards):\n","    ret = np.zeros(52)\n","    for card in cards:\n","        ret[card.getId()] = 1\n","    return ret\n","\n","def un_one_hot(arr):\n","    rankNames = [\"A\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"T\", \"J\", \"Q\", \"K\"]\n","    suitNames = ['S', 'H', 'D', 'C']\n","    ret = []\n","    for i in range(len(arr)):\n","        if arr[i] != 0:\n","            ret.append(rankNames[i%13] + suitNames[i//13])\n","    return ret\n","\n","#-------------------------------------------------------------------------------"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Thesis/GinRummy\n","/content/drive/My Drive/Colab Notebooks/Thesis/SupervisedLearning\n","/content/drive/My Drive/Colab Notebooks/Thesis\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o1K0a747bja2"},"source":["## MLPGinRummyPlayer"]},{"cell_type":"code","metadata":{"id":"cxJaArOfbmUM"},"source":["# -------------------------------------------------------------------------------\n","#  MLPGinRummyPlayer\n","#\n","#  This estimation will be calculated using a Multilayer Percepton trained on the\n","#  SimpleGinRummyPlayer written\n","#  by Calvin Tan.\n","#\n","#  @author Calvin Tan\n","#  @version 1.0\n","# -------------------------------------------------------------------------------\n","\n","# -------------------------------------------------------------------------------\n","# The following code was originally written by Todd Neller in Java.\n","# It was translated into Python by May Jiang.\n","# -------------------------------------------------------------------------------\n","\n","# -------------------------------------------------------------------------------\n","# Copyright (C) 2020 Todd Neller\n","# This program is free software; you can redistribute it and/or\n","# modify it under the terms of the GNU General Public License\n","# as published by the Free Software Foundation; either version 2\n","# of the License, or (at your option) any later version.\n","# This program is distributed in the hope that it will be useful,\n","# but WITHOUT ANY WARRANTY; without even the implied warranty of\n","# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","# GNU General Public License for more details.\n","# Information about the GNU General Public License is available online at:\n","#   http://www.gnu.org/licenses/\n","# To receive a copy of the GNU General Public License, write to the Free\n","# Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n","# 02111-1307, USA.\n","# -------------------------------------------------------------------------------\n","\n","from typing import List, TypeVar\n","from random import randint\n","from GinRummyUtil import GinRummyUtil\n","from GinRummyPlayer import GinRummyPlayer\n","\n","# Import MLP Models\n","# from SupervisedLearning.models import *\n","\n","Card = TypeVar('Card')\n","\n","class MLPGinRummyPlayer(GinRummyPlayer):\n","\n","    def loadModel(self, model_pt):\n","        print('Load Model')\n","        self.model = model_pt\n","\n","    def setVerbose(self, verbose):\n","        self.playVerbose = verbose\n","\n","    def updateStates(self, states):\n","        if self.playVerbose:\n","            print('Update States')\n","        self.state = states\n","\n","    def knockAction(self) -> bool:\n","        return self.knock\n","\n","    # Inform player of 0-based player number (0/1), starting player number (0/1), and dealt cards\n","    def startGame(self, playerNum: int, startingPlayerNum: int, cards: List[Card]) -> None:\n","        self.playerNum = playerNum\n","        self.startingPlayerNum = startingPlayerNum\n","        self.cards = list(cards)\n","        self.opponentKnocked = False\n","        self.drawDiscardBitstrings = [] # long[], or List[int]\n","        self.faceUpCard = None\n","        self.faceUpCardBool = False\n","        self.drawnCard = None\n","        self.state = None\n","        self.knock = False\n","        self.playVerbose = False\n","\n","    # Return whether or not player will draw the given face-up card on the draw pile.\n","    def willDrawFaceUpCard(self, card: Card) -> bool:\n","        self.faceUpCard = card\n","        # BPBD, either draw(2)->False or pickup(3)->True\n","        state = np.expand_dims(self.state, axis=0)\n","        state = torch.from_numpy(state).type(torch.FloatTensor).to(device)\n","        action = self.model(state)\n","        action = action.detach().numpy().reshape(-1)\n","        if self.playVerbose:\n","            print('Draw new card:', action[2])\n","            print('Pickup from discard:', action[3])\n","        if action[3] > action[2]:\n","            # print('Pickup Discard Action')\n","            self.faceUpCardBool = True\n","            return True\n","        # print('Draw from Deck Action')\n","        self.faceUpCardBool = False\n","        return False\n","\n","    # Report that the given player has drawn a given card and, if known, what the card is.\n","    # If the card is unknown because it is drawn from the face-down draw pile, the drawnCard is null.\n","    # Note that a player that returns false for willDrawFaceUpCard will learn of their face-down draw from this method.\n","    def reportDraw(self, playerNum: int, drawnCard: Card) -> None:\n","        # Ignore other player draws.  Add to cards if playerNum is this player.\n","        if playerNum == self.playerNum:\n","            self.cards.append(drawnCard)\n","            self.drawnCard = drawnCard\n","\n","\n","\n","\n","\n","\n","    # def getDiscard(self) -> Card:\n","    #     # Discard a random card (not just drawn face up) leaving minimal deadwood points.\n","    #     minDeadwood = float('inf')\n","    #     candidateCards = []\n","    #     for card in self.cards:\n","    #         # Cannot draw and discard face up card.\n","    #         if card == self.drawnCard and self.drawnCard == self.faceUpCard:\n","    #         # if card == self.drawnCard and self.faceUpCard:\n","    #             continue\n","    #         # Disallow repeat of draw and discard.\n","    #         drawDiscard = [self.drawnCard, card]\n","    #         if GinRummyUtil.cardsToBitstring(drawDiscard) in self.drawDiscardBitstrings:\n","    #             continue\n","\n","    #         remainingCards = list(self.cards)\n","    #         remainingCards.remove(card)\n","    #         bestMeldSets = GinRummyUtil.cardsToBestMeldSets(remainingCards)\n","    #         deadwood = GinRummyUtil.getDeadwoodPoints3(remainingCards) if len(bestMeldSets) == 0 \\\n","    #             else GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], remainingCards)\n","    #         if deadwood <= minDeadwood:\n","    #             if deadwood < minDeadwood:\n","    #                 minDeadwood = deadwood\n","    #                 candidateCards.clear()\n","    #             candidateCards.append(card)\n","    #     # Prevent future repeat of draw, discard pair.\n","    #     discard = candidateCards[randint(0, len(candidateCards)-1)]\n","    #     drawDiscard = [self.drawnCard, discard]\n","    #     self.drawDiscardBitstrings.append(GinRummyUtil.cardsToBitstring(drawDiscard))\n","    #     return discard\n","\n","    # Get the player's discarded card.  If you took the top card from the discard pile,\n","    # you must discard a different card.\n","    # If this is not a card in the player's possession, the player forfeits the game.\n","    # @return the player's chosen card for discarding\n","    def getDiscard(self) -> Card:\n","        # APBD, either either discard or knock...\n","        # determine the allowable actions (which cards can be discarded/knocked on)\n","        currHand = np.array(self.state[0:52])\n","        knockCards = np.array(self.state[0:52])\n","        # if self.playVerbose:\n","        #     print('Current Hand:', un_one_hot(currHand))\n","        # disallow discarding PickUp FaceUp/Discarded Card\n","        if self.faceUpCardBool:\n","        # if self.drawnCard == self.faceUpCard:\n","            currHand[self.drawnCard.getId()] = 0\n","            knockCards[self.drawnCard.getId()] = 0\n","        \n","        # prune illegal knock actions\n","        cardIndex = np.where(knockCards == 1)[0]\n","        for c in cardIndex:\n","            remainingCards = list(self.cards)\n","            remainingCards.remove(Deck.getCard(c))\n","            bestMeldSets = GinRummyUtil.cardsToBestMeldSets(remainingCards)\n","            deadwood = GinRummyUtil.getDeadwoodPoints3(remainingCards) if len(bestMeldSets) == 0 \\\n","                else GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], remainingCards)\n","            if deadwood > 10:\n","                knockCards[c] = 0\n","\n","        state = np.expand_dims(self.state, axis=0)\n","        state = torch.from_numpy(state).type(torch.FloatTensor).to(device)\n","        action = self.model(state)\n","        action = action.detach().numpy().reshape(-1)\n","\n","        discardMax = max(currHand * action[6:58])\n","        # knockMax = max(currHand * action[58:110])\n","        knockMax = max(knockCards * action[58:110])\n","\n","        if self.playVerbose:\n","            unmeldedCards = self.cards.copy()\n","            bestMelds = GinRummyUtil.cardsToBestMeldSets(unmeldedCards)\n","            if len(bestMelds) > 0:\n","                melds = bestMelds[0]\n","                for meld in melds:\n","                    for card in meld:\n","                        unmeldedCards.remove(card)\n","                melds.extend(unmeldedCards)\n","            else:\n","                melds = unmeldedCards\n","            print('Current Hand:', melds)\n","            if np.argmax(action) > 58:\n","                # print('Knock', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(currHand * action[58:])), '|', np.argmax(action))\n","                print('Knock', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(knockCards * action[58:])), '|', np.argmax(action))\n","            else:\n","                # print('Discard', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(currHand * action[58:])), '|', np.argmax(action))\n","                print('Discard', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(knockCards * action[58:])), '|', np.argmax(action))\n","            print('MAX:{:.4f}, {:.4f}'.format(discardMax, knockMax))\n","\n","        if discardMax > knockMax or int(sum(knockCards) == 0):\n","            if self.playVerbose:\n","                print('Discard Action')\n","            self.knock = False\n","            return Deck.getCard(np.argmax(currHand * action[6:58]))\n","        else:\n","            if self.playVerbose:\n","                print('Knock Action')\n","            self.knock = True\n","            # return Deck.getCard(np.argmax(currHand * action[58:]))\n","            return Deck.getCard(np.argmax(knockCards * action[58:]))\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    # Report that the given player has discarded a given card.\n","    def reportDiscard(self, playerNum: int, discardedCard: Card) -> None:\n","        # Ignore other player discards.  Remove from cards if playerNum is this player.\n","        if playerNum == self.playerNum:\n","            self.cards.remove(discardedCard)\n","\n","    # At the end of each turn, this method is called and the player that cannot (or will not) end the round will return a null value.\n","    # However, the first player to \"knock\" (that is, end the round), and then their opponent, will return an ArrayList of ArrayLists of melded cards.\n","    # All other cards are counted as \"deadwood\", unless they can be laid off (added to) the knocking player's melds.\n","    # When final melds have been reported for the other player, a player should return their final melds for the round.\n","    # @return null if continuing play and opponent hasn't melded, or an ArrayList of ArrayLists of melded cards.\n","    def getFinalMelds(self) -> List[List[Card]]:\n","        # Check if deadwood of maximal meld is low enough to go out.\n","        bestMeldSets = GinRummyUtil.cardsToBestMeldSets(self.cards) # List[List[List[Card]]]\n","        if not self.opponentKnocked and (len(bestMeldSets) == 0 or \\\n","            GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], self.cards) > \\\n","            GinRummyUtil.MAX_DEADWOOD):\n","            return None\n","        if len(bestMeldSets) == 0:\n","            return []\n","        return bestMeldSets[randint(0, len(bestMeldSets)-1)]\n","\n","    # When an player has ended play and formed melds, the melds (and deadwood) are reported to both players.\n","    def reportFinalMelds(self, playerNum: int, melds: List[List[Card]]) -> None:\n","        # Melds ignored by simple player, but could affect which melds to make for complex player.\n","        if playerNum != self.playerNum:\n","            self.opponentKnocked = True\n","\n","    # Report current player scores, indexed by 0-based player number.\n","    def reportScores(self, scores: List[int]) -> None:\n","        # Ignored by simple player, but could affect strategy of more complex player.\n","        return\n","\n","    # Report layoff actions.\n","    def reportLayoff(self, playerNum: int, layoffCard: Card, opponentMeld: List[Card]) -> None:\n","        # Ignored by simple player, but could affect strategy of more complex player.\n","        return\n","\n","    # Report the final hands of players.\n","    def reportFinalHand(self, playerNum: int, hand: List[Card]) -> None:\n","        # Ignored by simple player, but could affect strategy of more complex player.\n","        return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WswUyFq7MzBj"},"source":["### Estimator Network & load checkpoint"]},{"cell_type":"code","metadata":{"id":"DVSCfSTL9KAL"},"source":["class EstimatorNetwork(nn.Module):\n","    ''' The function approximation network for Estimator\n","        It is just a series of sigmoid layers. All in/out are torch.tensor\n","        (OLD) It is just a series of tanh layers. All in/out are torch.tensor\n","    '''\n","\n","    def __init__(self, mlp_layers=None, batch_norm=False, knock_layer=False, top_layer=True):\n","        ''' Initialize the Q network\n","        Args:\n","            action_num (int): number of legal actions\n","            state_shape (list): shape of state tensor\n","            mlp_layers (list): output size of each fc layer\n","        '''\n","        super(EstimatorNetwork, self).__init__()\n","\n","        self.action_num = 110\n","        self.state_shape = 260\n","        self.mlp_layers = mlp_layers\n","        self.batch_norm = batch_norm\n","        self.knock_layer = knock_layer\n","        self.top_layer = top_layer\n","\n","        # build the Q network\n","        layer_dims = [np.prod(self.state_shape)] + self.mlp_layers\n","        fc = [nn.Flatten()]\n","        if batch_norm:\n","            fc.append(nn.BatchNorm1d(layer_dims[0]))\n","        for i in range(len(layer_dims)-1):\n","            fc.append(nn.Linear(layer_dims[i], layer_dims[i+1], bias=True))\n","            fc.append(nn.Sigmoid())\n","        # add top layer onto Q-network\n","        if self.top_layer:\n","            fc.append(nn.Linear(layer_dims[-1], self.action_num, bias=True))\n","            fc.append(nn.Softmax(dim=1))\n","        else:\n","            # remove last sigmoid layer and append softmax layer\n","            fc.pop()\n","            fc.append(nn.Softmax(dim=1))\n","\n","        # add knock layer to be an additional layer, which will manually be set identity\n","        # with bias on the knock actions (58-110)\n","        # required to be frozen!!!\n","        if self.knock_layer:\n","            fc.append(nn.Linear(self.action_num, self.action_num, bias=True))\n","            fc.append(nn.Softmax(dim=1))\n","        self.fc_layers = nn.Sequential(*fc)\n","        \n","    def forward(self, s):\n","        ''' Predict action values\n","        Args:\n","            s  (Tensor): (batch, state_shape)\n","        '''\n","        return self.fc_layers(s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bUFsqPpeD1xq"},"source":["def load_checkpoint(checkpoint):\n","    pretrained_dict = {}\n","    if knock_layer:\n","        pretrained_dict = checkpoint\n","    else:\n","        model_dict = checkpoint\n","        # check if there is batch norm layer\n","        if batch_norm:\n","            b_layer = 1 \n","            pretrained_dict['fc_layers.1.weight'] = model_dict['fc_layers.1.weight']\n","            pretrained_dict['fc_layers.1.bias'] = model_dict['fc_layers.1.bias']\n","            pretrained_dict['fc_layers.1.running_mean'] = model_dict['fc_layers.1.running_mean']\n","            pretrained_dict['fc_layers.1.running_var'] = model_dict['fc_layers.1.running_var']\n","            pretrained_dict['fc_layers.1.num_batches_tracked'] = model_dict['fc_layers.1.num_batches_tracked']\n","        else:\n","            b_layer = 0\n","        curr_layer = 1 + b_layer\n","        for i in range(len(mlp_layers)):\n","            pretrained_dict['fc_layers.{}.weight'.format(curr_layer)] = model_dict['fc_layers.{}.weight'.format(curr_layer)]\n","            pretrained_dict['fc_layers.{}.bias'.format(curr_layer)] = model_dict['fc_layers.{}.bias'.format(curr_layer)]\n","            curr_layer += 2\n","        if top_layer:\n","            pretrained_dict['fc_layers.{}.weight'.format(curr_layer)] = model_dict['fc_layers.{}.weight'.format(curr_layer)]\n","            pretrained_dict['fc_layers.{}.bias'.format(curr_layer)] = model_dict['fc_layers.{}.bias'.format(curr_layer)]\n","    return pretrained_dict"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bh93Ni3UszBL"},"source":["## RandGinRummyPlayer"]},{"cell_type":"code","metadata":{"id":"wNu79KMoszBN"},"source":["# -------------------------------------------------------------------------------\n","#  RandGinRummyPlayer\n","#\n","#  This estimation will be calculated using a Multilayer Percepton trained on the\n","#  SimpleGinRummyPlayer written\n","#  by Calvin Tan.\n","#\n","#  @author Calvin Tan\n","#  @version 1.0\n","# -------------------------------------------------------------------------------\n","\n","# -------------------------------------------------------------------------------\n","# The following code was originally written by Todd Neller in Java.\n","# It was translated into Python by May Jiang.\n","# -------------------------------------------------------------------------------\n","\n","# -------------------------------------------------------------------------------\n","# Copyright (C) 2020 Todd Neller\n","# This program is free software; you can redistribute it and/or\n","# modify it under the terms of the GNU General Public License\n","# as published by the Free Software Foundation; either version 2\n","# of the License, or (at your option) any later version.\n","# This program is distributed in the hope that it will be useful,\n","# but WITHOUT ANY WARRANTY; without even the implied warranty of\n","# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","# GNU General Public License for more details.\n","# Information about the GNU General Public License is available online at:\n","#   http://www.gnu.org/licenses/\n","# To receive a copy of the GNU General Public License, write to the Free\n","# Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n","# 02111-1307, USA.\n","# -------------------------------------------------------------------------------\n","\n","from typing import List, TypeVar\n","from random import randint\n","from GinRummyUtil import GinRummyUtil\n","from GinRummyPlayer import GinRummyPlayer\n","import random\n","\n","# Import MLP Models\n","# from SupervisedLearning.models import *\n","\n","Card = TypeVar('Card')\n","\n","class RandGinRummyPlayer(GinRummyPlayer):\n","\n","    # Inform player of 0-based player number (0/1), starting player number (0/1), and dealt cards\n","    def startGame(self, playerNum: int, startingPlayerNum: int, cards: List[Card]) -> None:\n","        self.playerNum = playerNum\n","        self.startingPlayerNum = startingPlayerNum\n","        self.cards = list(cards)\n","        self.opponentKnocked = False\n","        self.drawDiscardBitstrings = [] # long[], or List[int]\n","        self.faceUpCard = None\n","        self.drawnCard = None\n","        self.state = None\n","\n","    def willDrawFaceUpCard(self, card: Card) -> bool:\n","        # Return random choice\n","        self.faceUpCard = card\n","        newCards = list(self.cards)\n","        newCards.append(card)\n","        choice = random.randint(0, 1)\n","        if choice == 0:\n","            return True\n","        return False\n","\n","\n","    # Report that the given player has drawn a given card and, if known, what the card is.\n","    # If the card is unknown because it is drawn from the face-down draw pile, the drawnCard is null.\n","    # Note that a player that returns false for willDrawFaceUpCard will learn of their face-down draw from this method.\n","    def reportDraw(self, playerNum: int, drawnCard: Card) -> None:\n","        # Ignore other player draws.  Add to cards if playerNum is this player.\n","        if playerNum == self.playerNum:\n","            self.cards.append(drawnCard)\n","            self.drawnCard = drawnCard\n","\n","    # Get the player's discarded card.  If you took the top card from the discard pile,\n","    # you must discard a different card.\n","    # If this is not a card in the player's possession, the player forfeits the game.\n","    # @return the player's chosen card for discarding\n","    def getDiscard(self) -> Card:\n","\n","        choice = random.randint(0, len(self.cards)-1)\n","        discCard = self.cards[choice]\n","        while discCard == self.faceUpCard:\n","            choice = random.randint(0, len(self.cards)-1)\n","            discCard = self.cards[choice]\n","        return discCard\n","\n","\n","    # Report that the given player has discarded a given card.\n","    def reportDiscard(self, playerNum: int, discardedCard: Card) -> None:\n","        # Ignore other player discards.  Remove from cards if playerNum is this player.\n","        if playerNum == self.playerNum:\n","            self.cards.remove(discardedCard)\n","\n","    # At the end of each turn, this method is called and the player that cannot (or will not) end the round will return a null value.\n","    # However, the first player to \"knock\" (that is, end the round), and then their opponent, will return an ArrayList of ArrayLists of melded cards.\n","    # All other cards are counted as \"deadwood\", unless they can be laid off (added to) the knocking player's melds.\n","    # When final melds have been reported for the other player, a player should return their final melds for the round.\n","    # @return null if continuing play and opponent hasn't melded, or an ArrayList of ArrayLists of melded cards.\n","    def getFinalMelds(self) -> List[List[Card]]:\n","        # Check if deadwood of maximal meld is low enough to go out.\n","        bestMeldSets = GinRummyUtil.cardsToBestMeldSets(self.cards) # List[List[List[Card]]]\n","        if not self.opponentKnocked and (len(bestMeldSets) == 0 or \\\n","            GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], self.cards) > \\\n","            GinRummyUtil.MAX_DEADWOOD):\n","            return None\n","        if len(bestMeldSets) == 0:\n","            return []\n","        return bestMeldSets[randint(0, len(bestMeldSets)-1)]\n","\n","    # When an player has ended play and formed melds, the melds (and deadwood) are reported to both players.\n","    def reportFinalMelds(self, playerNum: int, melds: List[List[Card]]) -> None:\n","        # Melds ignored by simple player, but could affect which melds to make for complex player.\n","        if playerNum != self.playerNum:\n","            self.opponentKnocked = True\n","\n","    # Report current player scores, indexed by 0-based player number.\n","    def reportScores(self, scores: List[int]) -> None:\n","        # Ignored by simple player, but could affect strategy of more complex player.\n","        return\n","\n","    # Report layoff actions.\n","    def reportLayoff(self, playerNum: int, layoffCard: Card, opponentMeld: List[Card]) -> None:\n","        # Ignored by simple player, but could affect strategy of more complex player.\n","        return\n","\n","    # Report the final hands of players.\n","    def reportFinalHand(self, playerNum: int, hand: List[Card]) -> None:\n","        # Ignored by simple player, but could affect strategy of more complex player.\n","        return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u-hik2PLM6C2"},"source":["## Game Definition"]},{"cell_type":"code","metadata":{"id":"gDVKIcsgWJwe"},"source":["class GinRummyGame:\n","\n","    # Hand size (before and after turn). After draw and before discard there is one extra card.\n","    HAND_SIZE = 10;\n","\n","    # Whether or not to print information during game play\n","    playVerbose = False;\n","\n","    # Two Gin Rummy players numbered according to their array index.\n","    players = [];\n","\n","    # Set whether or not there is to be printed output during gameplay.\n","    def setPlayVerbose(self, playVerbose):\n","        self.playVerbose = playVerbose\n","    \n","    #-------------------------------- updateState --------------------------------#\n","    # 2020-12-20: Define a method to append states\n","    # 2021-01-16: modified append state to work for either player (0 or 1)\n","    def updateState(self, currentPlayer, discards, oppCard):\n","        currHand = one_hot(self.players[currentPlayer].cards)\n","        topCard = np.zeros(52)\n","        if len(discards) > 0:\n","            topCard[discards[-1].getId()] = 1\n","        deadCard = np.zeros(52)\n","        for d in range(len(discards) - 1):\n","            deadCard[discards[d].getId()] = 1\n","        unknownCard = np.ones(52) - currHand - topCard - deadCard - oppCard\n","        self.states = np.array([currHand, topCard, deadCard, oppCard, unknownCard]).flatten()\n","    #------------------------------------------------------------------------------#\n","\n","    # Create a self with two given players\n","    def __init__(self, player0, player1):\n","        self.players = []\n","        self.players.extend([player0, player1])\n","\n","    # Play a game of Gin Rummy and return the winning player number 0 or 1.\n","    # @return the winning player number 0 or 1\n","\n","    def play(self):\n","        scores = [0, 0]\n","        hands = []\n","        hands.extend([[], []])\n","        startingPlayer = random.randrange(2);\n","\n","        # while game not over\n","        while scores[0] < GinRummyUtil.GOAL_SCORE and scores[1] < GinRummyUtil.GOAL_SCORE:\n","            \n","            num_turns = 0\n","            currentPlayer = startingPlayer\n","            opponent = (1 if currentPlayer == 0 else 0)\n","            \n","            # get shuffled deck and deal cards\n","            deck = Deck.getShuffle(random.randrange(10 ** 8))\n","            hands[0] = []\n","            hands[1] = []\n","            for i in range(2 * self.HAND_SIZE):\n","                hands[i % 2] += [deck.pop()]\n","            for i in range(2):\n","                self.players[i].startGame(i, startingPlayer, hands[i]);\n","                if self.playVerbose:\n","                    print(\"Player %d is dealt %s.\\n\" % (i, hands[i]))\n","            if self.playVerbose:\n","                print(\"Player %d starts.\\n\" % (startingPlayer))\n","            discards = []\n","            discards.append(deck.pop())\n","            if self.playVerbose:\n","                print(\"The initial face up card is %s.\\n\" % (discards[len(discards) - 1]))\n","            firstFaceUpCard = discards[len(discards) - 1]\n","            turnsTaken = 0\n","            knockMelds = None\n","\n","            # 11/25 - Initial state, prior to any cards\n","            # 1/16 - Initialize oppCard to be two dimensional to track both players as opponents\n","            oppCard = []\n","            oppCard.extend([np.zeros(52), np.zeros(52)])\n","\n","            for i in range(2):\n","                if isinstance(self.players[i], MLPGinRummyPlayer):\n","                    self.players[i].setVerbose(self.playVerbose)\n","\n","            # while the deck has more than two cards remaining, play round\n","            while len(deck) > 2:\n","                if num_turns > 300:\n","                    print(\"Max Turns exceeded, restart\")\n","                    break\n","                else:\n","                    num_turns += 1\n","#-------------------------------------------------------------- BPBD --------------------------------------------------------------#\n","                drawFaceUp = False\n","                faceUpCard = discards[len(discards) - 1]\n","\n","                # offer draw face-up iff not 3rd turn with first face up card (decline automatically in that case)\n","                if not (turnsTaken == 2 and faceUpCard == firstFaceUpCard):\n","\n","                    #------------------------------------ DRAW ------------------------------------#\n","                    # 2020-12-01  -  Track states BEFORE the player PICKUP BEFORE player DISCARDS (track_bpbd)\n","                    # 2021-01-16  -  Track for both players instead of just player 0\n","                    # Action      -  PickUp from Discard(FaceUp) or Deck (Unknown)\n","                    # State       -  BPBD -> APBD\n","\n","                    self.updateState(currentPlayer,discards,oppCard[currentPlayer])\n","\n","                    #------------------------------------------------------------------------------#\n","\n","                    # 2021-01-16  -  Update player with current states\n","                    if isinstance(self.players[currentPlayer], MLPGinRummyPlayer):\n","                        self.players[currentPlayer].updateStates(self.states)\n","\n","                    # both players declined and 1st player must draw face down\n","                    drawFaceUp = self.players[currentPlayer].willDrawFaceUpCard(faceUpCard)\n","                    \n","                    if self.playVerbose and not drawFaceUp and faceUpCard == firstFaceUpCard and turnsTaken < 2:\n","                        print(\"Player %d declines %s.\\n\" % (currentPlayer, firstFaceUpCard))\n","\n","                if not (not drawFaceUp and turnsTaken < 2 and faceUpCard == firstFaceUpCard):\n","\n","                    # continue with turn if not initial declined option\n","                    if self.playVerbose:\n","                        if drawFaceUp:\n","                            print('drawFaceUp (Pickup discarded card)')\n","                        else:\n","                            print('Draw from deck')\n","                    drawCard = discards.pop() if drawFaceUp else deck.pop()\n","                    for i in range(2):\n","                        to_report = drawCard if i == currentPlayer or drawFaceUp else None\n","                        self.players[i].reportDraw(currentPlayer, to_report)\n","\n","                    if self.playVerbose:\n","                        print(\"Player %d draws %s.\\n\" % (currentPlayer, drawCard))\n","                    hands[currentPlayer].append(drawCard)\n","#-------------------------------------------------------------- APBD --------------------------------------------------------------#\n","                    \n","                    self.updateState(currentPlayer,discards,oppCard[currentPlayer])\n","                    \n","                    # 2021-01-16  -  Update player with current states\n","                    if isinstance(self.players[currentPlayer], MLPGinRummyPlayer):\n","                    # if type(self.players[currentPlayer]) == type(MLPGinRummyPlayer()):\n","                        self.players[currentPlayer].updateStates(self.states)\n","\n","                    discardCard = self.players[currentPlayer].getDiscard()\n","\n","                    # 2021-01-16  -  Track for both players instead of just player 0\n","                    # Track opponent pickup and discard after each discard \n","\n","                    # Set discarded card to 0 (in case discarded card was seen)\n","                    oppCard[1 - currentPlayer][discardCard.getId()] = 0\n","                    if drawFaceUp: # if opponent draws TopCard from discard\n","                        oppCard[1 - currentPlayer][drawCard.getId()] = 1\n","\n","                    if not discardCard in hands[currentPlayer] or discardCard == faceUpCard:\n","                        print(\"Player %d discards %s illegally and forfeits.\\n\" % (currentPlayer, discardCard))\n","                        return opponent;\n","                    hands[currentPlayer].remove(discardCard)\n","                    for i in range(2):\n","                        self.players[i].reportDiscard(currentPlayer, discardCard)                    \n","                    if self.playVerbose:\n","                        print(\"Player %d discards %s.\\n\" % (currentPlayer, discardCard))\n","                    discards.append(discardCard)\n","\n","                    if self.playVerbose:\n","                        unmeldedCards = hands[currentPlayer].copy()\n","                        bestMelds = GinRummyUtil.cardsToBestMeldSets(unmeldedCards)\n","                        if len(bestMelds) == 0:\n","                            print(\"Player %d has %s with %d deadwood.\\n\" % (currentPlayer, unmeldedCards, GinRummyUtil.getDeadwoodPoints3(unmeldedCards)))\n","                        else:\n","                            melds = bestMelds[0]\n","                            for meld in melds:\n","                                for card in meld:\n","                                    unmeldedCards.remove(card)\n","                            melds.extend(unmeldedCards)\n","                            print(\"Player %d has %s with %d deadwood.\\n\" % (currentPlayer, melds, GinRummyUtil.getDeadwoodPoints3(unmeldedCards)))\n","\n","#-------------------------------------------------------------- KNOCK --------------------------------------------------------------#\n","                    # CHECK FOR KNOCK\n","                    knockMelds = self.players[currentPlayer].getFinalMelds()\n","                    if knockMelds != None:\n","                        # print('Current Player:', currentPlayer)\n","                        # print(knockMelds)\n","                        # break\n","                        # 2021-01-16  -  Check if MLPGinRummyPlayer knocks\n","                        if isinstance(self.players[currentPlayer], MLPGinRummyPlayer):\n","                            knock = self.players[currentPlayer].knockAction()\n","                            if self.playVerbose:\n","                                print(knock)\n","                            if knock:\n","                                break\n","                        else:\n","                            break\n","                    \n","                turnsTaken += 1\n","                # currentPlayer = 1 if currentPlayer == 0 else 0\n","                # opponent = 1 if currentPlayer == 0 else 0\n","                if len(deck) > 2:\n","                    currentPlayer = 1 if currentPlayer == 0 else 0\n","                    opponent = 1 if currentPlayer == 0 else 0\n","\n","            # if knockMelds != None and len(deck) > 2:\n","            if knockMelds != None:\n","                # round didn't end due to non-knocking and 2 cards remaining in draw pile\n","                # check legality of knocking meld\n","                handBitstring = GinRummyUtil.cardsToBitstring(hands[currentPlayer])\n","                unmelded = handBitstring\n","                for meld in knockMelds:\n","                    meldBitstring = GinRummyUtil.cardsToBitstring(meld)\n","                    if (not meldBitstring in GinRummyUtil.getAllMeldBitstrings()) or ((meldBitstring & unmelded) != meldBitstring):\n","                        # non-meld or meld not in hand\n","                        # print(len(deck))\n","                        # print(meld)\n","                        # print(knockMelds)\n","                        # print(currentPlayer, hands[currentPlayer])\n","                        # print(1- currentPlayer, hands[1-currentPlayer])\n","                        # print(GinRummyUtil.getDeadwoodPoints1(knockMelds, hands[1-currentPlayer]))\n","                        print(\"Player %d melds %s illegally and forfeits.\\n\" % (currentPlayer, knockMelds))\n","                        return opponent\n","                    unmelded &= ~meldBitstring # remove successfully melded cards from\n","\n","                # compute knocking deadwood\n","                knockingDeadwood = GinRummyUtil.getDeadwoodPoints1(knockMelds, hands[currentPlayer])\n","                if knockingDeadwood > GinRummyUtil.MAX_DEADWOOD:\n","                    print(\"Player %d melds %s with greater than %d deadwood and forfeits.\\n\" % (currentPlayer, knockMelds, knockingDeadwood))\n","                    return opponent\n","\n","                meldsCopy = []\n","                for meld in knockMelds:\n","                    meldsCopy.append(meld.copy())\n","                for i in range(2):\n","                    self.players[i].reportFinalMelds(currentPlayer, meldsCopy)\n","                if self.playVerbose:\n","                    if knockingDeadwood > 0:\n","                        print(\"Player %d melds %s with %d deadwood from %s.\\n\" % (currentPlayer, knockMelds, knockingDeadwood, GinRummyUtil.bitstringToCards(unmelded)))\n","                    else:\n","                        print(\"Player %d goes gin with melds %s.\\n\" % (currentPlayer, knockMelds))\n","\n","                # get opponent meld\n","                opponentMelds = self.players[opponent].getFinalMelds();\n","                meldsCopy = []\n","                for meld in opponentMelds:\n","                    meldsCopy.append(meld.copy())\n","                for i in range(2):\n","                    self.players[i].reportFinalMelds(opponent, meldsCopy)\n","\n","                # check legality of opponent meld\n","                opponentHandBitstring = GinRummyUtil.cardsToBitstring(hands[opponent])\n","                opponentUnmelded = opponentHandBitstring\n","                for meld in opponentMelds:\n","                    meldBitstring = GinRummyUtil.cardsToBitstring(meld)\n","                    if (meldBitstring not in GinRummyUtil.getAllMeldBitstrings()) or ((meldBitstring & opponentUnmelded) != meldBitstring):\n","                        # non-meld or meld not in hand\n","                        print(\"Player %d melds %s illegally and forfeits.\\n\" % (opponent, opponentMelds))\n","                        return currentPlayer\n","                    opponentUnmelded &= ~meldBitstring # remove successfully melded cards from\n","\n","                if self.playVerbose:\n","                    print(\"Player %d melds %s.\\n\" % (opponent, opponentMelds))\n","\n","                # lay off on knocking meld (if not gin)\n","                unmeldedCards = GinRummyUtil.bitstringToCards(opponentUnmelded)\n","                if knockingDeadwood > 0:\n","                    # knocking player didn't go gin\n","                    cardWasLaidOff = False\n","                    while True:\n","                        # attempt to lay each card off\n","                        cardWasLaidOff = False\n","                        layOffCard = None\n","                        layOffMeld = None\n","                        for card in unmeldedCards:\n","                            for meld in knockMelds:\n","                                newMeld = meld.copy()\n","                                newMeld.append(card)\n","                                newMeldBitstring = GinRummyUtil.cardsToBitstring(newMeld)\n","                                if newMeldBitstring in GinRummyUtil.getAllMeldBitstrings():\n","                                    layOffCard = card\n","                                    layOffMeld = meld\n","                                    break\n","                            if layOffCard != None:\n","                                if self.playVerbose:\n","                                    print(\"Player %d lays off %s on %s.\\n\" % (opponent, layOffCard, layOffMeld))\n","                                for i in range(2):\n","                                    self.players[i].reportLayoff(opponent, layOffCard, layOffMeld.copy())\n","                                unmeldedCards.remove(layOffCard)\n","                                layOffMeld.append(layOffCard)\n","                                cardWasLaidOff = True\n","                                break\n","                        if not cardWasLaidOff:\n","                            break\n","\n","                opponentDeadwood = 0\n","                for card in unmeldedCards:\n","                    opponentDeadwood += GinRummyUtil.getDeadwoodPoints2(card)\n","                if self.playVerbose:\n","                    print(\"Player %d has %d deadwood with %s\\n\" % (opponent, opponentDeadwood, unmeldedCards))\n","                # compare deadwood and compute new scores\n","                if knockingDeadwood == 0:\n","                    # gin round win\n","                    scores[currentPlayer] += GinRummyUtil.GIN_BONUS + opponentDeadwood\n","                    if self.playVerbose:\n","                        print(\"Player %d scores the gin bonus of %d plus opponent deadwood %d for %d total points.\\n\" % \\\n","                        (currentPlayer, GinRummyUtil.GIN_BONUS, opponentDeadwood, GinRummyUtil.GIN_BONUS + opponentDeadwood))\n","\n","                elif knockingDeadwood < opponentDeadwood:\n","                    # non-gin round win:\n","                    scores[currentPlayer] += opponentDeadwood - knockingDeadwood;\n","                    if self.playVerbose:\n","                        print(\"Player %d scores the deadwood difference of %d.\\n\" % (currentPlayer, opponentDeadwood - knockingDeadwood))\n","\n","                else:\n","                    # undercut win for opponent\n","                    scores[opponent] += GinRummyUtil.UNDERCUT_BONUS + knockingDeadwood - opponentDeadwood;\n","                    if self.playVerbose:\n","                        print(\"Player %d undercuts and scores the undercut bonus of %d plus deadwood difference of %d for %d total points.\\n\" % \\\n","                        (opponent, GinRummyUtil.UNDERCUT_BONUS, knockingDeadwood - opponentDeadwood, GinRummyUtil.UNDERCUT_BONUS + knockingDeadwood - opponentDeadwood))\n","\n","                startingPlayer = 1 if startingPlayer == 0 else 0 # starting player alternates\n","\n","            # If the round ends due to a two card draw pile with no knocking, the round is cancelled.\n","            else:\n","                if self.playVerbose:\n","                    print(\"The draw pile was reduced to two cards without knocking, so the hand is cancelled.\")\n","\n","            # report final hands\n","            for i in range(2):\n","                for j in range(2):\n","                    self.players[i].reportFinalHand(j, hands[j].copy())\n","\n","            # score reporting\n","            if self.playVerbose:\n","                print(\"Player\\tScore\\n0\\t%d\\n1\\t%d\\n\" % (scores[0], scores[1]))\n","            for i in range(2):\n","                self.players[i].reportScores(scores.copy())\n","\n","        if self.playVerbose:\n","            print(\"Player %s wins.\\n\" % (0 if scores[0] > scores[1] else 1))\n","        return 0 if scores[0] >= GinRummyUtil.GOAL_SCORE else 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"11qEEpVcXSun"},"source":["## Shared"]},{"cell_type":"code","metadata":{"id":"faqGzLQVWQZD"},"source":["def testAgents(agent0,agent1,numGames,verbose):\n","    numP1Wins = 0\n","    game = GinRummyGame(agent0, agent1)\n","    # Multiple non-verbose games\n","    game.setPlayVerbose(verbose)\n","    # for i in range(2):\n","    #     if isinstance(game.players[i], MLPGinRummyPlayer):\n","    #         print(game.players[i].model)\n","    for i in range(numGames):\n","        if i % 250 == 0:\n","        # if i % 100 == 0:\n","            print(\"Game ... \", i)\n","        # set random seed to make testing consistent\n","        random.seed(i)\n","        numP1Wins += game.play()\n","    print(\"Games Won: P0:%d, P1:%d.\\n\" % (numGames - numP1Wins, numP1Wins))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgmlCQKmVfj3"},"source":["state = 'all'\n","action = 'all'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JIhyFRnjM_b-"},"source":["# Test Agents"]},{"cell_type":"markdown","metadata":{"id":"kvykr4ZNvJZo"},"source":["## MLP Models vs. RandomAgent"]},{"cell_type":"markdown","metadata":{"id":"xjPYLr9oQ0SF"},"source":["### No DQN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBXnwRS8vJZs","executionInfo":{"elapsed":76139,"status":"ok","timestamp":1611078170086,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"36688875-ddbe-40b3-f551-01beea8b28b0"},"source":["numGames = 2000\n","agent0 = MLPGinRummyPlayer()\n","model_name = 'all_states_all_actions'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\n","agent0.loadModel(model)\n","print(model_name)\n","agent1 = RandGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:2000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YapcvAtcvJZt","executionInfo":{"elapsed":65497,"status":"ok","timestamp":1611078236140,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"de2824f2-969f-4fc9-bf4a-43cc4fd6a3b3"},"source":["numGames = 2000\n","agent0 = MLPGinRummyPlayer()\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\n","agent0.loadModel(model)\n","print(model_name)\n","agent1 = RandGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_MLP_base_extra_knock_data_40K\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:2000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgdEDtNVvJZu","executionInfo":{"elapsed":126837,"status":"ok","timestamp":1611078297494,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"4634d00e-2e54-45bc-b105-d655d1481d17"},"source":["numGames = 2000\n","agent0 = MLPGinRummyPlayer()\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\n","agent0.loadModel(model)\n","print(model_name)\n","agent1 = RandGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_2hl_extra_knock_data_40K\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:2000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1ANIs_Lqlpw","executionInfo":{"elapsed":66836,"status":"ok","timestamp":1611462833850,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"6d836a0f-aa12-45b4-dd81-fbe630a2a328"},"source":["numGames = 2000\n","agent0 = MLPGinRummyPlayer()\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_80K'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\n","agent0.loadModel(model)\n","print(model_name)\n","agent1 = RandGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_2hl_extra_knock_data_80K\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:2000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hBud_g_iQ5mn"},"source":["### DQN - Random Agent"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHfKDylOwDNM","executionInfo":{"elapsed":1096908,"status":"ok","timestamp":1611079422546,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"3c5a9883-eb89-4aff-81f6-54406153909c"},"source":["numGames = 2000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST5/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 110]\n","# mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = RandGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=110, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=110, out_features=110, bias=True)\n","    (6): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:1996, P1:4.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t8siavYqRA6-"},"source":["### DQN - Selfplay"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SNnjtXbQsWr","executionInfo":{"elapsed":192219,"status":"ok","timestamp":1612764809037,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"792b4a9c-56f0-4ef5-9eea-3335a2eb1256"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/selfplay/TEST1/model_posttrain.pth', map_location=device)\n","# mlp_layers=[520, 110]\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = RandGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mK_BCGBJRGVh"},"source":["### DQN - SGRAgent"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5P7xKWLRJG4","executionInfo":{"elapsed":449029,"status":"ok","timestamp":1613538142624,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"3f0a922c-abca-4706-efd8-0d1e4b52e603"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST2/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = RandGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zLTh_vClL43-"},"source":["## MLP Models vs. SimpleGinRummyAgent"]},{"cell_type":"markdown","metadata":{"id":"chfSSIbcRf1O"},"source":["### No DQN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0uRlIiYTPP6Y","executionInfo":{"elapsed":93797,"status":"ok","timestamp":1611463310192,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"cd10de95-55c6-43f1-bca4-f968bf949fbe"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","model_name = 'all_states_all_actions'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\n","agent0.loadModel(model)\n","print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:130, P1:870.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdoXXbBfTs9j","executionInfo":{"elapsed":187010,"status":"ok","timestamp":1611463403416,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"76dcbfe4-92f4-428e-8127-a453b8e8e9ac"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\n","agent0.loadModel(model)\n","print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_MLP_base_extra_knock_data_40K\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:197, P1:803.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aL_OZ4BdHoe7","executionInfo":{"elapsed":295280,"status":"ok","timestamp":1611463511694,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"b6a57274-4a04-4629-b1ef-e4b1833bff85"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\n","agent0.loadModel(model)\n","print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_2hl_extra_knock_data_40K\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:246, P1:754.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wICCyA6kqqPd","executionInfo":{"elapsed":402973,"status":"ok","timestamp":1611463619397,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"cb72a737-b1b2-4cc9-ca59-5e3b1d306fe6"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_80K'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\n","agent0.loadModel(model)\n","print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_2hl_extra_knock_data_80K\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:273, P1:727.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JF1NBigsmq8g","executionInfo":{"elapsed":114849,"status":"ok","timestamp":1613928147118,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"3be03ec3-6b92-45b6-df48-df9ed4b60b67"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_80K_2K_base'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\n","agent0.loadModel(model)\n","print(model_name)\n","\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_2hl_extra_knock_data_80K_2K_base\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:226, P1:774.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yER8W1H6Tmrv"},"source":["### DQN - Random Agent (80K PT Model + Hardcoded Top layer weights)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kio3W9IwTmr7","executionInfo":{"elapsed":86846,"status":"ok","timestamp":1613419981130,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"19119b6a-6d10-4d62-de78-6e2aec7af4ad"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST9/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2jccNspv8TIU"},"source":["### DQN - Random Agent (TEST18 - larger training batches, smaller LR)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F848z2l49A1M","executionInfo":{"elapsed":106822,"status":"ok","timestamp":1613883624604,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"8a2ef7c2-ed79-4343-808e-ddb8e9e04b80"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST18/model_pretrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:69, P1:931.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z9sPxWvq8TIX","executionInfo":{"elapsed":71734,"status":"ok","timestamp":1613883696356,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"bef5567d-3347-41c8-93b8-61d7e1c820dd"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST18/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3tJtalCWmSWg"},"source":["### DQN - Random Agent (TEST19 - 80K PT Model, 2K Base)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUYeZ_zonZZN","executionInfo":{"elapsed":111363,"status":"ok","timestamp":1613928288040,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"2878b4aa-dc9b-4348-c827-8ae3758d1cd8"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/random/TEST19/model_pretrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:68, P1:932.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jBr5WYAmSWx","executionInfo":{"elapsed":72469,"status":"ok","timestamp":1613953260109,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"09144838891693247193"},"user_tz":300},"outputId":"e6b4dee1-95b7-460d-c82b-c5d271513769"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/random/TEST19/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8uk0hA4G2VJ","executionInfo":{"elapsed":72749,"status":"ok","timestamp":1613953333410,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"09144838891693247193"},"user_tz":300},"outputId":"29356cdb-7362-4422-d38a-17d22edb803e"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/random/TEST20/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAazhIdnG2hx","executionInfo":{"elapsed":62236,"status":"ok","timestamp":1613953745058,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"09144838891693247193"},"user_tz":300},"outputId":"d34c126d-b503-4fa2-f992-33fd4c8ce2d0"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/random/TEST21/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:5, P1:995.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Obh8tO1ACToR"},"source":["### DQN - Random Agent (TEST11-16)\n","\n","- 11: 0.4 knock reward\n","- 12: 1.0 knock reward\n","- 13: 1.0 knock reward, tiny LR\n","- 14: 1.0 knock reward, tiny LR, train every 10\n","- 15: train every 10\n","- 16: train every 100, tiny LR"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBNVFdhnCToe","executionInfo":{"elapsed":100632,"status":"ok","timestamp":1613885006447,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"06ec0159-75c6-4b3d-9cd7-29dcab0b2d14"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST11/model_pretrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:59, P1:941.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tMFL8sRCTof","executionInfo":{"elapsed":75949,"status":"ok","timestamp":1613885167507,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"ee866e7c-36c3-4fce-d575-06aec671db7b"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST11/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1E4PjDMEsut","executionInfo":{"elapsed":78027,"status":"ok","timestamp":1613885606634,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"a93677dd-0867-40cd-82aa-ffb78c9d1b72"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST12/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:4, P1:996.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gf3zUd-FEt7m","executionInfo":{"elapsed":62751,"status":"ok","timestamp":1613885669657,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"dd651770-7532-4d0a-d0e7-72513c477aa0"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST13/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJFRathYEvZr","executionInfo":{"elapsed":124196,"status":"ok","timestamp":1613885731111,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"f92a5b99-bd8c-4988-cb41-ec0bfbe36858"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST14/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etVbiHPIEwnv","executionInfo":{"elapsed":52911,"status":"ok","timestamp":1613885784054,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"298c8f95-8f61-46ed-dbf9-a007200e6925"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST15/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPd6c5WsExrJ","executionInfo":{"elapsed":104127,"status":"ok","timestamp":1613885835285,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"db38dac4-1d40-4a60-cd43-165cfd4270cd"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/random/TEST16/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xD_LPqg2Tmr8"},"source":["### DQN - (Pure) Selfplay"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suScDBUITmr8","executionInfo":{"elapsed":86605,"status":"ok","timestamp":1613420501932,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"c9afdc0a-a4ce-48a1-8efd-8843e417b0db"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/selfplay/TEST2/model_posttrain.pth', map_location=device)\n","# mlp_layers=[520, 110]\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:3, P1:997.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"__YaixA_-ptV"},"source":["### DQN - (Pure) Selfplay (TEST9 - larger training steps, smaller LR) "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DNcZzS93-pta","executionInfo":{"elapsed":104910,"status":"ok","timestamp":1613884093011,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"4282410e-fd8b-4539-eb5a-dc0900cc6eee"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/selfplay/TEST9/model_pretrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:61, P1:939.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2fUD3cS-0Oc","executionInfo":{"elapsed":71278,"status":"ok","timestamp":1613884164306,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"d3c16b86-5132-498b-e29c-b2e8e0ba7b73"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/selfplay/TEST9/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yfapetWbXYeK"},"source":["### DQN - Selfplay after Random"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cG1L57fYjmp","executionInfo":{"elapsed":96705,"status":"ok","timestamp":1613421066221,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"c6414bff-e557-4c8b-aa5b-36d28ec353c4"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/selfplay/TEST3/model_posttrain.pth', map_location=device)\n","# mlp_layers=[520, 110]\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:11, P1:989.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtTCq2R7XeUt","executionInfo":{"elapsed":78171,"status":"ok","timestamp":1613421304107,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"102e12c6-5cab-4b06-dd44-0c20ceee8bba"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/selfplay/TEST4/model_posttrain.pth', map_location=device)\n","# mlp_layers=[520, 110]\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6RteokMRTmr9"},"source":["### DQN - SGRAgent"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l593PSP2Tmr9","executionInfo":{"elapsed":105014,"status":"ok","timestamp":1613538248870,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"0035a2f3-93e9-4dcc-e601-7e6c2e248b89"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST2/model_pretrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:53, P1:947.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1w8XksO30eqS","executionInfo":{"elapsed":172584,"status":"ok","timestamp":1613538316462,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"986987c1-29f8-4d25-dafd-ed4c47ec72fe"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST2/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tdlo_RBV_0My"},"source":["### DQN - SGRAgent after random/TEST18"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRCACoer_0M2","executionInfo":{"elapsed":66969,"status":"ok","timestamp":1613884331203,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"2504d41b-b69e-489e-fae0-242aef24bf50"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST5/model_pretrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oUjcg4Nc_0M3","executionInfo":{"elapsed":132781,"status":"ok","timestamp":1613884399209,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"ec9c3d3f-58fe-4645-bbf4-b42481b7dcc9"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST5/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ek7y1eUesdB_"},"source":["### DQN - Selfplay after SGRAgent"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0O3WdMUz6tC","executionInfo":{"elapsed":241880,"status":"ok","timestamp":1613538385779,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"9787a503-a31b-4ee9-eaae-44e0d6bde44a"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/selfplay/TEST8/model_pretrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uE8qd2r-sdCE","executionInfo":{"elapsed":304671,"status":"ok","timestamp":1613538448585,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"c7a5e398-0cb8-4da5-e710-4c96e97bcb01"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/selfplay/TEST8/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zPCsf4xtLb2Y"},"source":["### DQN - Random Agent (TESTS)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sn3qKij6adwl","executionInfo":{"elapsed":104668,"status":"ok","timestamp":1614578759897,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"30caaa0d-a4dd-4c1c-8835-283c74a1182b"},"source":["# BEST RESULTS SO FAR, better than beginning\n","\n","model = 'models/dqn/random/TEST93'\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","agent1 = SimpleGinRummyPlayer()\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:89, P1:911.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fXMEVRAYaWxh"},"source":["#### TEST93 reward_sgr best so far..."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zlfo5ZrwOZ2y","executionInfo":{"elapsed":104759,"status":"ok","timestamp":1614579205247,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"19ebb10f-bc9c-41b2-ff3c-c0fedc72581b"},"source":["# BEST RESULTS SO FAR, better than beginning\n","\n","model = 'models/dqn/random/TEST93'\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","agent1 = SimpleGinRummyPlayer()\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:76, P1:924.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MEkkoB9EYWtT","executionInfo":{"elapsed":207457,"status":"ok","timestamp":1614579307954,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"3d1148c9-99c6-45d9-9ca2-c749b3d93bd9"},"source":["# BEST RESULTS SO FAR, better than beginning\n","\n","model = 'models/dqn/random/TEST93'\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","agent1 = SimpleGinRummyPlayer()\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:74, P1:926.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tEhOX6Reqhwn"},"source":["model_dqn_pre = torch.load('{}/model_pretrain.pth'.format(model), map_location='cpu')\n","model_dqn_post = torch.load('{}/model_sgr.pth'.format(model), map_location='cpu')\n","model_q_estim_pre = model_dqn_pre['dqn_q_estimator']\n","model_target_estim_pre = model_dqn_pre['dqn_target_estimator']\n","model_q_estim_post = model_dqn_post['dqn_q_estimator']\n","model_target_estim_post = model_dqn_post['dqn_target_estimator']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOxxMwgbqhwn"},"source":["weights_q_estim_pre = model_q_estim_pre['fc_layers.5.weight'].flatten().tolist()\n","weights_target_estim_pre = model_target_estim_pre['fc_layers.5.weight'].flatten().tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jl5w0sviqhwn"},"source":["weights_q_estim_post = model_q_estim_post['fc_layers.5.weight'].flatten().tolist()\n","weights_target_estim_post = model_target_estim_post['fc_layers.5.weight'].flatten().tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aLEUprsOqhwo"},"source":["import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CbD5J_FOqhwo"},"source":["dqn_model = 'Q Estimator'\n","weights_pre = weights_q_estim_pre\n","weights_post = weights_q_estim_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZxuNi7m2qhwo"},"source":["dqn_model = 'Target Estimator'\n","weights_pre = weights_target_estim_pre\n","weights_post = weights_target_estim_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"gNttDaLOqhwp","executionInfo":{"elapsed":421,"status":"ok","timestamp":1614579440452,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"b0de2a67-0a99-45c7-a1fc-29522e5d3337"},"source":["# s = np.subtract(weights_post, weights_pre) + 1\n","fig = plt.figure()\n","plt.scatter(weights_pre, weights_post, s=1)\n","plt.xlabel('Pretrained Weights')\n","plt.ylabel('{} Weights'.format(dqn_model))\n","x = np.linspace(-5,5,100)\n","plt.plot(x, x, '-r')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"exdOodaMbM19"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"Vk0jWS9cPhA9"},"source":["# Wins: pre/rand/self/sgr/post\n","\n","# 80K_knock (270~ Wins)\n","# model = 'models/dqn/random/TEST36'\n","# Wins: 70/12/24/30/17\n","# model = 'models/dqn/random/TEST98'\n","# Wins: 70/22/25/18/13\n","# model = 'models/dqn/random/TEST97'\n","# Wins: 70/34/31/30/10\n","# model = 'models/dqn/random/TEST96'\n","# Wins: 70/25/21/21/8\n","\n","# 80K_knock_2K_base (226 Wins)\n","# model = 'models/dqn/random/TEST95'\n","# Wins: 72/51/45/43/46\n","# model = 'models/dqn/random/TEST94'\n","# Wins: 72/40/28/55/30\n","# model = 'models/dqn/random/TEST93'\n","# Wins: 65/5/8/83/0\n","# model = 'models/dqn/random/TEST92'\n","# Wins: 77/9/25/40/18\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins2: 42/21/18\n","model = 'models/dqn/random/TEST92'\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_texybi2Lb2c","executionInfo":{"elapsed":104501,"status":"ok","timestamp":1614577959406,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"709595e0-dd38-4cfe-d0a1-5574c450c01b"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:77, P1:923.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZkYith8mPCqr"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"id":"BygcpvKwLiyS"},"source":["# Wins: pre/rand/self/sgr/post\n","\n","# 80K_knock (270~ Wins)\n","# model = 'models/dqn/random/TEST36'\n","# Wins: 70/12/24/30/17\n","# model = 'models/dqn/random/TEST98'\n","# Wins: 70/22/25/18/13\n","# model = 'models/dqn/random/TEST97'\n","# Wins: 70/34/31/30/10\n","# model = 'models/dqn/random/TEST96'\n","# Wins: 70/25/21/21/8\n","\n","# 80K_knock_2K_base (226 Wins)\n","# model = 'models/dqn/random/TEST95'\n","# Wins: 72/51/45/43/46\n","# model = 'models/dqn/random/TEST94'\n","# Wins: 72/40/28/55/30\n","# model = 'models/dqn/random/TEST93'\n","# Wins: 65/5/8/83/0\n","# model = 'models/dqn/random/TEST92'\n","# Wins: 77/9/25/40/18\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins2: 42/21/18\n","model = 'models/dqn/random/TEST92'\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4akxriA8N0LN","executionInfo":{"elapsed":172751,"status":"ok","timestamp":1614578028252,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"a2218c87-3f89-4f6c-824d-ca0318356513"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:9, P1:991.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3K0ig6wOZtI","executionInfo":{"elapsed":254423,"status":"ok","timestamp":1614578109930,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"fd4ea4ac-be91-409f-c9ec-db4248be9e9d"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:25, P1:975.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2VEtiP5T7H5","executionInfo":{"elapsed":348303,"status":"ok","timestamp":1614578203820,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"411bc874-e82e-464f-e761-919263312c77"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:40, P1:960.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UN-AVXBrOesY","executionInfo":{"elapsed":409620,"status":"ok","timestamp":1614578265144,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"a9c9d6b1-90b9-479d-ba80-eeb4d9ffbf5f"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:18, P1:982.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uvpD0ESS3-R","executionInfo":{"elapsed":503988,"status":"ok","timestamp":1614578359517,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"249f4fbd-6da7-41ee-8917-59ce4148d231"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:42, P1:958.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wu46MkKjS3-V","executionInfo":{"elapsed":590088,"status":"ok","timestamp":1614578445619,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"f703b122-0d2b-4441-a3a1-74885bcd9bfe"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:21, P1:979.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Up8hk_leS3-W","executionInfo":{"elapsed":666027,"status":"ok","timestamp":1614578521561,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"3ac21c70-2646-48d9-969d-f741c55dd064"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:18, P1:982.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v6hZ20SyawMN"},"source":["## MLP Models vs. SimpleGinRummyAgent (Group Testing)"]},{"cell_type":"markdown","metadata":{"id":"Yc9Urd5mmJQn"},"source":["### DQN - iterate"]},{"cell_type":"markdown","metadata":{"id":"wSP0-kJJmJQx"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"K-3Oc6I9mJQx"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# model = 'models/dqn/random/TEST92'\n","# Wins: 73/7/18/44/7\n","# Wins2: 38/30/14\n","# model = 'models/dqn/iterate/1_selfplay'\n","# Wins: 34/1/39/26/0\n","# Wins2: 26/34/20\n","# model = 'models/dqn/iterate/2_random'\n","# Wins: 5/0/0/1/1\n","# Wins2: 1/3/2\n","# model = 'models/dqn/iterate/3_selfplay'\n","# Wins: 0/0/0/1/0\n","# Wins2: 1/1/1\n","\n","# model = 'models/dqn/random/TEST92'\n","# model = 'models/dqn/iterate/1_selfplay'\n","# model = 'models/dqn/iterate/2_random'\n","model = 'models/dqn/iterate/3_selfplay'\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfz7AY3pmJQy","executionInfo":{"elapsed":53324,"status":"ok","timestamp":1614704364356,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"03d1ba98-f9b2-487a-f8e3-22f7b8c70d08"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vCw-aVV5mJQy"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rBOS9LDmJQz","executionInfo":{"elapsed":105670,"status":"ok","timestamp":1614704416709,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"4563da71-23e3-482a-fcfc-de4dc3310fe8"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXKPcrsCmJQz","executionInfo":{"elapsed":158341,"status":"ok","timestamp":1614704469386,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"f63401d2-ceea-40cc-e944-3318ea10c064"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Op0WMdJsmJQz","executionInfo":{"elapsed":211369,"status":"ok","timestamp":1614704522421,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"4ea84156-1b5c-4168-d83b-b957a3ee5dcd"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0OffLySmJQ0","executionInfo":{"elapsed":260696,"status":"ok","timestamp":1614704571753,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"ad7aed40-4b1f-4626-f709-0c72c023efbd"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKCuEQNtmJQ0","executionInfo":{"elapsed":314204,"status":"ok","timestamp":1614704625269,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"f24e4458-23a5-4410-d203-220455e5b223"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqQd8IWemJQ0","executionInfo":{"elapsed":366679,"status":"ok","timestamp":1614704677754,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"cae9721d-3764-48f3-a3b4-f500f8bc3178"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IgMqEVYMmJQ0","executionInfo":{"elapsed":420560,"status":"ok","timestamp":1614704731643,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"47bb4ea2-a6ac-470d-cb2e-0a6bec98121b"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Fr7DkNeDPK92"},"source":["### DQN - rewards"]},{"cell_type":"markdown","metadata":{"id":"qsoopxWKPK9-"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"C1MF9WK0PK9_"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","# model = 'models/dqn/rewards/payoff_v6'\n","# Wins: 78/1/60/72/1\n","# Wins2: 69/79/69\n","# model = 'models/dqn/rewards/payoff_v7'\n","# Wins: 68/71/73/73/0\n","# Wins2: 74/52/61\n","model = 'models/dqn/rewards/payoff_v8'\n","# Wins: 66/0/60/57/1\n","# Wins2: 66/70/79\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-JY3-98oPK-A","executionInfo":{"elapsed":109327,"status":"ok","timestamp":1614966482464,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"03b96eda-8a6f-44e7-d428-b250df890f79"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:66, P1:934.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XbeIWmq4PK-C"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TmkUUfFPK-C","executionInfo":{"elapsed":207316,"status":"ok","timestamp":1614965726706,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"c2d8b539-0a22-41c2-dda4-0478bbd94b95"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xyk5_xePK-D","executionInfo":{"elapsed":321153,"status":"ok","timestamp":1614965840551,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"65a706e1-2867-4a42-c069-53e139146cfd"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:60, P1:940.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bCRSkSzPK-D","executionInfo":{"elapsed":433005,"status":"ok","timestamp":1614965952410,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"18523885-5e04-48c5-e5c2-9eb5ff862cfe"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:57, P1:943.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXd7iW6APK-E","executionInfo":{"elapsed":509532,"status":"ok","timestamp":1614966028944,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"40371178-a6a7-45d2-c48e-d11908367325"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4JrO0WI2PK-G","executionInfo":{"elapsed":619191,"status":"ok","timestamp":1614966138611,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"a26c45cf-1e70-493f-c7de-2a4cb75d404c"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:66, P1:934.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTW0hZjRPK-G","executionInfo":{"elapsed":729388,"status":"ok","timestamp":1614966248824,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"0dfb40fb-be19-45b6-8d4b-5aabb31fc7de"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:70, P1:930.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJ_iiVAXPK-H","executionInfo":{"elapsed":842354,"status":"ok","timestamp":1614966361799,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"261a3a4d-8dec-41f5-d33f-31a361c59332"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:79, P1:921.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pw3LUwmACPTV"},"source":["## MLP Models vs. SimpleGinRummyAgent (Knock Layer)"]},{"cell_type":"markdown","metadata":{"id":"b78NCgV9khFx"},"source":["### DQN - knock layer (left in)"]},{"cell_type":"markdown","metadata":{"id":"KOqJvPwqkhF1"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"AVlhDxMOkhF2"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","# model = 'models/dqn/knockLayer/knock_point2'\n","# Wins: 12/1/9/10/10\n","# Wins2: 15/15/14\n","# model = 'models/dqn/knockLayer/knock_point02'\n","# Wins: 18/18/3/14/20\n","# Wins2: 17/16/17\n","model = 'models/dqn/knockLayer/knock_point002'\n","# Wins: 29/15/14/20/13\n","# Wins2: 20/14/11\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","knock_layer = True\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwgSaG6dkhF2","executionInfo":{"elapsed":128066,"status":"ok","timestamp":1615314746612,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"80ea243f-063c-46e8-d647-8ca8990fa8eb"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:40, P1:960.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dYf7ekELkhF3"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g3_YwA6ckhF4","executionInfo":{"elapsed":190847,"status":"ok","timestamp":1614972497335,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"bf39956b-c3fb-4f0d-bd55-f06b7612e8f7"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:15, P1:985.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IgTak_oHkhF4","executionInfo":{"elapsed":280297,"status":"ok","timestamp":1614972586793,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"cd4faf95-47dd-464a-d7db-66fbef8c78f4"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:14, P1:986.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRjv97hakhF5","executionInfo":{"elapsed":372181,"status":"ok","timestamp":1614972678684,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"bf273bb8-8bad-49ff-fc72-2d92e521e9cc"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:20, P1:980.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFluqfDdkhF5","executionInfo":{"elapsed":460212,"status":"ok","timestamp":1614972766722,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"b53cc2d8-ec25-4e65-e95f-8786f69144c5"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:13, P1:987.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QkyXbGsPkhF5","executionInfo":{"elapsed":550889,"status":"ok","timestamp":1614972857409,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"a8ca479e-478d-45ec-fe82-9476e7b6e1a5"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:20, P1:980.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1Xv1uqekhF6","executionInfo":{"elapsed":645364,"status":"ok","timestamp":1614972951895,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"3aba8282-16d0-4d52-e716-3775638b89b1"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:14, P1:986.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_vwmVx9khF6","executionInfo":{"elapsed":735985,"status":"ok","timestamp":1614973042523,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"af85b43a-30ea-47df-df88-29b6d809db1d"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:11, P1:989.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QPE2Zfxu_OLV"},"source":["### DQN - knock layer (removed)"]},{"cell_type":"markdown","metadata":{"id":"ih9xBPKv_OLb"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"aMPnS6fV_OLc"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","# model = 'models/dqn/knockLayer/knock_point2'\n","# Wins: 62/0/1/2/0\n","# Wins2: 59/56/61\n","model = 'models/dqn/knockLayer/knock_point02'\n","# Wins: 60/0/0/3/0\n","# Wins2: 70/77/74\n","# model = 'models/dqn/knockLayer/knock_point002'\n","# Wins: 3/7/5/4/3\n","# Wins2: 3/3/2\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","knock_layer = False\n","top_layer = True\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXuTqpKk_OLd"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_AJXErL2_OLe"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwdC29_w_OLf","executionInfo":{"elapsed":197239,"status":"ok","timestamp":1614988364997,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"94a4dec1-e2f3-48f7-ad93-b7c6dfd9ece2"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:3, P1:997.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EKr6baC5_OLf","executionInfo":{"elapsed":281264,"status":"ok","timestamp":1614988449030,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"e6ba1c68-f227-4a85-bfbd-c04acb2d53c7"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:7, P1:993.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GY9EztSP_OLf","executionInfo":{"elapsed":365857,"status":"ok","timestamp":1614988533634,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"8fbf75cc-966c-473e-ee10-f5e8b7a00cbc"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:5, P1:995.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vP3wdly1_OLg","executionInfo":{"elapsed":449412,"status":"ok","timestamp":1614988617197,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"168ab3d9-bbd6-436c-90f9-e293f5a685e3"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:4, P1:996.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9YnVE5Mj_OLg","executionInfo":{"elapsed":533088,"status":"ok","timestamp":1614988700880,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"4e76e1f5-3ab8-4630-ae7a-57b15e54b71b"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:3, P1:997.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhdnY8id_OLh","executionInfo":{"elapsed":619723,"status":"ok","timestamp":1614988787528,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"9918aa56-fe85-4f02-b5a7-147fb6017bf3"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:3, P1:997.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJXgMpLf_OLh","executionInfo":{"elapsed":703862,"status":"ok","timestamp":1614988871676,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"85fb14a5-d986-40cf-d69e-6dc5ac6b3a85"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:2, P1:998.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fuyMPmFTbOOV"},"source":["## MLP Models vs. SimpleGinRummyAgent (Top Layer [removed])"]},{"cell_type":"markdown","metadata":{"id":"6stI04TLem_6"},"source":["### DQN - top layer (Random)"]},{"cell_type":"markdown","metadata":{"id":"Z5rFgVueBlg1"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"XSajPLBDBlg1"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","# model = 'models/dqn/topLayer/base'\n","# Wins: 269/256/280/262/281\n","# Wins2: 281/275/269\n","# model = 'models/dqn/topLayer/base_unfrozen'\n","# Wins: 273/218/191/263/206\n","# Wins2: 266/260/258\n","\n","# top_layer = True\n","# model = 'models/dqn/topLayer/topLayer_copy'\n","# Wins: 62/0/0/88/0\n","# Wins2: 76/60/53\n","\n","# knock_layer = True\n","# top_layer = False\n","# model = 'models/dqn/topLayer/base_knock_point002'\n","# Wins: 266/290/264/277/267\n","# Wins2: 277/264/274\n","# model = 'models/dqn/topLayer/base_knock_point02'\n","# Wins: 277/286/284/291/300\n","# Wins2: 275/251/293\n","# model = 'models/dqn/topLayer/base_knock_point2'\n","# Wins: 243/265/287/281/283\n","# Wins2: 282/271/257\n","# model = 'models/dqn/topLayer/base_knock_2'\n","# Wins: 13/8/11/13/10\n","# Wins2: 14/12/17\n","\n","knock_layer = False\n","top_layer = False\n","# model = 'models/dqn/topLayer/base_payoffv2'\n","# Wins: 278/266/291/283/288\n","# Wins2: 307/260/272\n","# model = 'models/dqn/topLayer/base_payoffv3'\n","# Wins: 302/240/266/283/287\n","# Wins2: 270/250/272\n","model = 'models/dqn/topLayer/base_payoffv4'\n","# Wins: 271/271/277/277/301\n","# Wins2: 298/287/264\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6YVgqBcBlg2","executionInfo":{"elapsed":116340,"status":"ok","timestamp":1615185375559,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"8b4c85f6-40c9-4920-f921-90556415dd6a"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:271, P1:729.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BV3biIINBlg4"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRW-NQk-Blg4","executionInfo":{"elapsed":234184,"status":"ok","timestamp":1615185493409,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"4322602f-f9b0-4bb0-8932-ee55bacd0470"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:271, P1:729.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crZ4KDGCBlg5","executionInfo":{"elapsed":355429,"status":"ok","timestamp":1615185614662,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"43671117-6962-4bad-897d-9d987f492f2d"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:277, P1:723.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MH7JFSLBlg6","executionInfo":{"elapsed":476844,"status":"ok","timestamp":1615185736089,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"0283519f-cc80-4f9c-c44c-80c6aadae73b"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:277, P1:723.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"repNQJubBlg6","executionInfo":{"elapsed":595648,"status":"ok","timestamp":1615185854905,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"6c0e6609-4795-49fd-e57b-779ef1e185e3"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:301, P1:699.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFJv2W8dBlg7","executionInfo":{"elapsed":710954,"status":"ok","timestamp":1615185970218,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"df422abb-ee66-4473-daac-ecbb8ffdc38d"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:298, P1:702.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuxu-RfBBlg8","executionInfo":{"elapsed":827565,"status":"ok","timestamp":1615186086836,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"c9c0b40d-239f-493e-bb3a-bf41e5272dfd"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:287, P1:713.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVj4b_RtBlg8","executionInfo":{"elapsed":946589,"status":"ok","timestamp":1615186205866,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"6af748ab-5171-4c84-98bd-4fed58c9f8b1"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:264, P1:736.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GuovHRq5tiF5"},"source":["### DQN - top layer (Selfplay)"]},{"cell_type":"markdown","metadata":{"id":"fvrT3Vb3tiF6"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"72jjtCattiF7"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","# model = 'models/dqn/topLayer_self/base'\n","# Wins: 270/294/258/286/288\n","# Wins2: 269/265/288\n","# model = 'models/dqn/topLayer_self/base_unfrozen'\n","# Wins:  276/258/289/258/273\n","# Wins2: 285/295/258\n","\n","# knock_layer = True\n","# top_layer = False\n","# model = 'models/dqn/topLayer_self/base_knock_point002'\n","# Wins: 284/285/279/260/273\n","# Wins2: 273/285/263\n","# model = 'models/dqn/topLayer_self/base_knock_point02'\n","# Wins:  269/279/281/285/278\n","# Wins2: 274/260/265\n","# model = 'models/dqn/topLayer_self/base_knock_point2'\n","# Wins: 273/290/291/272/239\n","# Wins2: 274/275/272\n","# model = 'models/dqn/topLayer_self/base_knock_2'\n","# Wins: 13/10/14/16/6\n","# Wins2: 13/11/12\n","\n","knock_layer = False\n","top_layer = False\n","# model = 'models/dqn/topLayer_self/base_payoffv2'\n","# Wins: 284/276/270/277/268\n","# Wins2: 293/286/287\n","# model = 'models/dqn/topLayer_self/base_payoffv3'\n","# Wins: 281/285/257/242/277\n","# Wins2: 280/251/285\n","model = 'models/dqn/topLayer_self/base_payoffv4'\n","# Wins: 292/277/269/281/292\n","# Wins2: 287/240/277\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJ1PQrZ2tiF8","executionInfo":{"elapsed":115083,"status":"ok","timestamp":1615189154202,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"b2d46cfc-83c9-4877-8a76-6b8d660ba716"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:292, P1:708.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OpUrywYQtiF9"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7O3gsmdctiF9","executionInfo":{"elapsed":232976,"status":"ok","timestamp":1615189272103,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"fc83f8ac-5412-4400-f825-7e05195258d0"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:277, P1:723.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxePnblMtiF9","executionInfo":{"elapsed":352931,"status":"ok","timestamp":1615189392065,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"c1bceac7-a0ce-4e1e-8f0c-2e7fa20e222f"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:269, P1:731.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LoOZMZNItiF-","executionInfo":{"elapsed":470214,"status":"ok","timestamp":1615189509354,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"10412c62-5a05-41c1-8052-dea72de9c58b"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:281, P1:719.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmC1XYYqtiF-","executionInfo":{"elapsed":589062,"status":"ok","timestamp":1615189628209,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"f8ab7e84-eb7f-45c3-8957-d53df148b532"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:292, P1:708.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kQmQ6yrktiGA","executionInfo":{"elapsed":718013,"status":"ok","timestamp":1615189757167,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"59186b27-a403-4c9b-eff6-6a85a8d48224"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:287, P1:713.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6mHRh_stiGE","executionInfo":{"elapsed":824349,"status":"ok","timestamp":1615189863509,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"3614d637-ec9e-48e3-c662-31597b57afec"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:240, P1:760.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJAiecHbtiGF","executionInfo":{"elapsed":942409,"status":"ok","timestamp":1615189981576,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"819cf2ea-6063-4e02-94f1-8de40851ffc1"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:277, P1:723.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BwJOoFwd5WHo"},"source":["### DQN - top layer (BEST 308W - SGRAgent: base_knock_point002)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zw8BSO1SHlFi","executionInfo":{"elapsed":122808,"status":"ok","timestamp":1615060670797,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"1dcbf62a-2bc5-488b-89b6-a1b1600add60"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:308, P1:692.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"odvLlYDXDqK8","executionInfo":{"elapsed":123980,"status":"ok","timestamp":1615194001586,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"0e25fc9a-f8a0-4797-9bdc-8f41f90b3a40"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:295, P1:705.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3040vwGIzZ1","executionInfo":{"elapsed":175352,"status":"ok","timestamp":1615061242135,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"b9acdb93-1ba4-4155-c5f2-cc6c77675ac3"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:538, P1:462.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NKJUcqPKmve","executionInfo":{"elapsed":178273,"status":"ok","timestamp":1615194197193,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"e309da21-5349-488f-c1d4-bb20953878dd"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:494, P1:506.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wtcH2KKdLXAp","executionInfo":{"elapsed":181545,"status":"ok","timestamp":1615062184534,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"ce3a464b-edab-4ec8-997d-a3c5229e005c"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:525, P1:475.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMx_SNm2NVA7","executionInfo":{"elapsed":174819,"status":"ok","timestamp":1615062807306,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"3c8a7a48-c427-4f17-e646-278a824d3caa"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:482, P1:518.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"prsoopnGJz4S","executionInfo":{"elapsed":181370,"status":"ok","timestamp":1615061462083,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"0f993aa6-9814-41a6-8846-3db1bbecbacd"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:505, P1:495.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4i5AzthwNWKh","executionInfo":{"elapsed":341754,"status":"ok","timestamp":1615062978121,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"b75f3aaa-e54a-4ffc-b046-0fbbe5f331ca"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:487, P1:513.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gYo1esHTSJY2"},"source":["### DQN - top layer (BEST 315W - SGRAgent: base_knock_point02)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qjXHSnI_SIx9","executionInfo":{"elapsed":358466,"status":"ok","timestamp":1615063366939,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"5965bfa8-c0c6-4fb2-8570-e8e744cd63b9"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:315, P1:685.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pGCl6K26TBt6"},"source":["#### run testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yy55mSYFMTuo","executionInfo":{"elapsed":165245,"status":"ok","timestamp":1615313754356,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"6d0400cd-e3ba-4c5f-af87-aeae3ffc17cd"},"source":["batch_norm = False\n","knock_layer = False\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","# testAgents(agent0,agent1,1,verbose=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:310, P1:690.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jNAAEX7prWy","executionInfo":{"elapsed":171328,"status":"ok","timestamp":1615313562490,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"bbd98381-d869-47d4-84ee-254dfa97363c"},"source":["batch_norm = False\n","knock_layer = False\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","# testAgents(agent0,agent1,1,verbose=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:329, P1:671.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qVXQN2TfNEej","executionInfo":{"elapsed":262305,"status":"ok","timestamp":1615314051367,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"738dc578-97e6-416c-88ea-dfe2cee20c7b"},"source":["batch_norm = False\n","knock_layer = False # T = Keep, F = Remove\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","# testAgents(agent0,agent2,1,verbose=True)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:495, P1:505.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjLrRBvBSCpC","executionInfo":{"elapsed":236690,"status":"ok","timestamp":1615315329289,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"edb9adb7-78df-407d-f225-d8fec752fcef"},"source":["batch_norm = False\n","knock_layer = False # T = Keep, F = Remove\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","# testAgents(agent0,agent2,1,verbose=True)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:510, P1:490.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ez2HZOHu8nB","executionInfo":{"elapsed":1389074,"status":"ok","timestamp":1615308305410,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"dc96a3a7-701a-4d6e-cda1-080fdd38be8d"},"source":["batch_norm = False\n","knock_layer = False # T = Keep, F = Remove\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","# testAgents(agent0,agent2,1,verbose=True)\n","testAgents(agent0,agent2,numGames*10,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Game ...  1000\n","Game ...  1250\n","Game ...  1500\n","Game ...  1750\n","Game ...  2000\n","Game ...  2250\n","Game ...  2500\n","Game ...  2750\n","Game ...  3000\n","Game ...  3250\n","Game ...  3500\n","Game ...  3750\n","Game ...  4000\n","Game ...  4250\n","Game ...  4500\n","Game ...  4750\n","Game ...  5000\n","Game ...  5250\n","Game ...  5500\n","Game ...  5750\n","Game ...  6000\n","Game ...  6250\n","Game ...  6500\n","Game ...  6750\n","Game ...  7000\n","Game ...  7250\n","Game ...  7500\n","Game ...  7750\n","Game ...  8000\n","Game ...  8250\n","Game ...  8500\n","Game ...  8750\n","Game ...  9000\n","Game ...  9250\n","Game ...  9500\n","Game ...  9750\n","Games Won: P0:4929, P1:5071.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"79tgjAsOqtGn"},"source":["batch_norm = False\n","knock_layer = True # T = Keep, F = Remove\n","knock_layer = False # T = Keep, F = Remove\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,1,verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aqTsIwHbqpin"},"source":["#### run"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPmShvNzS5nW","executionInfo":{"elapsed":119798,"status":"ok","timestamp":1615064101765,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"e532408c-3cbe-4dba-b43a-51a3003ea87d"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:286, P1:714.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5HoUhHESJY3","executionInfo":{"elapsed":164450,"status":"ok","timestamp":1615064591521,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"0e37d4b3-2cfd-47e8-f2c4-f42305f6b5aa"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:513, P1:487.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HO-5qxMaSJY3","executionInfo":{"elapsed":161791,"status":"ok","timestamp":1615065816672,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"fd3f155f-11af-4b3e-ed13-753409a17d76"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:489, P1:511.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9QyIp_USJY4","executionInfo":{"elapsed":324616,"status":"ok","timestamp":1615065980997,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"db8cc490-ed3a-4bd3-ac2d-0637eca7c78a"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:503, P1:497.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6wYW-sWSJY4","executionInfo":{"elapsed":165352,"status":"ok","timestamp":1615066146359,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"42d46360-7527-46a3-922c-2be02f294114"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:498, P1:502.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-z0lCIpbSJY4","executionInfo":{"elapsed":328878,"status":"ok","timestamp":1615066309895,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"b0935436-c3c4-4a55-b507-0d5215ddf0f8"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:498, P1:502.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Tw33Ux4SJY5","executionInfo":{"elapsed":492985,"status":"ok","timestamp":1615066474009,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLFdOlRKdV41J9N9Qclh0m7u6wngNtLlkBLRRDA=s64","userId":"09144838891693247193"},"user_tz":300},"outputId":"2c274ab0-113c-41e0-bcf8-c057eb06492e"},"source":["batch_norm = False\n","knock_layer = True\n","top_layer = False\n","model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:501, P1:499.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oxy_G_tqE8L3"},"source":["### DQN - top layer (SGRAgent)"]},{"cell_type":"markdown","metadata":{"id":"SYymyUOz5WH0"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"_AxBH0Fj5WH0"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","# model = 'models/dqn/topLayer_sgr/base'\n","# Wins: 285/289/287/284/289\n","# Wins2: 252/270/300\n","# model = 'models/dqn/topLayer_sgr/base_unfrozen'\n","# Wins: 289/259/237/260/278\n","# Wins2: 277/285/292\n","\n","# knock_layer = True\n","# top_layer = False\n","# model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","# Wins: 291/290/307/274/281\n","# Wins2: 252/282/266\n","# model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","# Wins: 250/277/315/261/295\n","# Wins2: 292/271/268\n","# model = 'models/dqn/topLayer_sgr/base_knock_point2'\n","# Wins: 294/277/253/272/279\n","# Wins2: 279/283/289\n","# model = 'models/dqn/topLayer_sgr/base_knock_2'\n","# Wins: 10/16/10/13/14\n","# Wins2: 12/12/15\n","\n","knock_layer = False\n","top_layer = False\n","# model = 'models/dqn/topLayer_sgr/base_payoffv2'\n","# Wins: 285/285/271/256/265\n","# Wins2: 264/287/273\n","# model = 'models/dqn/topLayer_sgr/base_payoffv3'\n","# Wins: 275/246/261/280/278\n","# Wins2: 265/280/251\n","model = 'models/dqn/topLayer_sgr/base_payoffv4'\n","# Wins: 268/275/276/287/298\n","# Wins2: 281/277/260\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGICsQrY5WH1","executionInfo":{"elapsed":117067,"status":"ok","timestamp":1615192608413,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"26ef0d01-bc8f-4a0c-eb7d-540362467c15"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:268, P1:732.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GcgNJXp05WH1"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4g8MD3BF5WH2","executionInfo":{"elapsed":235604,"status":"ok","timestamp":1615192726958,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"b435918e-2b93-4a17-8fcf-5e7980379e47"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:275, P1:725.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyG1riUa5WH2","executionInfo":{"elapsed":353288,"status":"ok","timestamp":1615192844648,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"b07cefa6-3fcf-4158-fdfe-e7e765c245d6"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:276, P1:724.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eat7nPJ35WH2","executionInfo":{"elapsed":470286,"status":"ok","timestamp":1615192961653,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"cd28c503-38f6-4854-fc66-8a6c99f829c2"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:287, P1:713.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-LYq3D-O5WH3","executionInfo":{"elapsed":589338,"status":"ok","timestamp":1615193080712,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"1a8dd72f-0608-4741-cfeb-29e330eca35c"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:298, P1:702.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TXXNMpZD5WH3","executionInfo":{"elapsed":707725,"status":"ok","timestamp":1615193199107,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"9b8cd62a-a155-4329-f854-dfa2ff7ee887"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:281, P1:719.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmg60eTe5WH3","executionInfo":{"elapsed":825613,"status":"ok","timestamp":1615193317002,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"8a172762-3bbb-46d6-fe42-1e347ea66551"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:277, P1:723.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tv5VuXCx5WH3","executionInfo":{"elapsed":942236,"status":"ok","timestamp":1615193433631,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"ce71ead4-5577-4481-be0b-437dc133db55"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:260, P1:740.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ke-DQfbpsMdc"},"source":["### DQN - top layer (SGRAgent - disable knock layer)"]},{"cell_type":"markdown","metadata":{"id":"BTV4Ge0BsMdm"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"fpmSgzKSsMdn"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","# no knock layer\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","# model = 'models/dqn/topLayer_sgr/base_knock_point002'\n","# Wins: 268/275/276/287/298\n","# Wins2: 281/277/260\n","# model = 'models/dqn/topLayer_sgr/base_knock_point02'\n","# Wins: 311/258/294/277/299\n","# Wins2: 284/270/278\n","# model = 'models/dqn/topLayer_sgr/base_knock_point2'\n","# Wins: 293/302/243/295/275\n","# Wins2: 293/265/265\n","model = 'models/dqn/topLayer_sgr/base_knock_2'\n","# Wins: 273/281/283/261/298\n","# Wins2: 260/256/268\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","mlp_layers=[520, 520, 110]\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qF20tCu5sMdn","executionInfo":{"status":"ok","timestamp":1616491227786,"user_tz":240,"elapsed":147405,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"a5f0fd69-c9f6-4979-c6f4-ef1af6577346"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:304, P1:696.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zNUWKThSsMdp"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDbabXR9sMdq","executionInfo":{"status":"ok","timestamp":1616491373349,"user_tz":240,"elapsed":292959,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"62143116-3bda-484e-8181-93f39868b03c"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:295, P1:705.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OqVmkMUhsMdr","executionInfo":{"status":"ok","timestamp":1616491519254,"user_tz":240,"elapsed":438853,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"6bb92c3a-94be-484f-bf85-4c64c38d44cc"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:294, P1:706.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MycRls-8sMdr","executionInfo":{"status":"ok","timestamp":1616491664527,"user_tz":240,"elapsed":584117,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"a94816cf-7267-4ca7-9b5f-51af9f749a4a"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:295, P1:705.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mg1kNsp3sMds","executionInfo":{"status":"ok","timestamp":1616491809739,"user_tz":240,"elapsed":729321,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"cd51d7a2-39a4-4ebc-9a5f-cdeeb00335ee"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:302, P1:698.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2sz15j0csMds","executionInfo":{"status":"ok","timestamp":1616491955454,"user_tz":240,"elapsed":875027,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"db31d0d0-dc3f-4485-954d-6c38fc3af9d7"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:304, P1:696.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"35kSriI7sMds","executionInfo":{"status":"ok","timestamp":1616492100876,"user_tz":240,"elapsed":1020431,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"4a1dec82-7697-42e2-dfa5-86fc3b90020c"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:304, P1:696.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Kt1JVhjsMdt","executionInfo":{"status":"ok","timestamp":1616492246628,"user_tz":240,"elapsed":1166167,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"bfdef494-abc3-4649-849a-709d9e45a054"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:304, P1:696.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kuPiD3xxaLH7"},"source":["### DQN - SGRAgent additional testing"]},{"cell_type":"markdown","metadata":{"id":"tS7qXlDjaLH8"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"ujTSA5mnaLH8"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","mlp_layers=[520, 520, 110]\n","\n","# model = 'models/dqn/sgr_testing/small_lr_large_epsd'\n","# Wins: 281/271/282/292/253\n","# Wins2: 301/285/271\n","# model = 'models/dqn/sgr_testing/2HL_2kbase'\n","# Wins: 230/242/292/252/230\n","# Wins2: 255/260/234\n","\n","mlp_layers = [520, 520, 260, 110]\n","model = 'models/dqn/sgr_testing/3HL'\n","# Wins: 281/268/269/293/254\n","# Wins2: 290/256/244\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OlpaZxpeaLH9","executionInfo":{"elapsed":122384,"status":"ok","timestamp":1615272584652,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"6b017a79-687e-4298-e3c4-55f364203d6c"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:283, P1:717.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m_RHwnW9aLH9"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H8iEud1EaLH9","executionInfo":{"elapsed":246093,"status":"ok","timestamp":1615272708381,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"2cb481ee-0cd3-4bda-996d-f97083f836bb"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:276, P1:724.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAK1tuY3aLH-","executionInfo":{"elapsed":369151,"status":"ok","timestamp":1615272831464,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"c7d956a7-7b77-401f-954a-4eb03f4fdc3d"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:241, P1:759.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hAijxkFwaLH_","executionInfo":{"elapsed":490823,"status":"ok","timestamp":1615272953154,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"31e0b9b8-aca6-41f1-89b3-0736adddc075"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:268, P1:732.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocYrOrk_aLH_","executionInfo":{"elapsed":609475,"status":"ok","timestamp":1615273071828,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"c0ee80c5-dbf5-4025-c3e4-df65ca4b036f"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:276, P1:724.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cNmOV-QTaLH_","executionInfo":{"elapsed":731774,"status":"ok","timestamp":1615273194141,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"76e302b5-494a-4f1b-a630-7c30c2a5d3cd"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:251, P1:749.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXOy4GKIaLIA","executionInfo":{"elapsed":852905,"status":"ok","timestamp":1615273315288,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"3b14966b-adfa-4039-c7ed-cc68666ca414"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:265, P1:735.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"367lwOY3aLIA","executionInfo":{"elapsed":975847,"status":"ok","timestamp":1615273438252,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":300},"outputId":"c24a40fc-0094-4dd8-886b-ef1e6af09e04"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:273, P1:727.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y6looxhFsJa-"},"source":["### DQN - SGRAgent additional testing2"]},{"cell_type":"code","metadata":{"id":"GNyR_8p5xUPa"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","mlp_layers=[520, 520, 110]\n","\n","model = 'models/dqn/sgr_testing/small_lr_small_batch'\n","# Wins: \n","# Wins2:\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BI9gTD3rywHD","executionInfo":{"elapsed":140795,"status":"ok","timestamp":1615709374561,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"e94ad4af-20ea-489c-b3b4-41ee0ad1124d"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:333, P1:667.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZH3qEs8xQqu","executionInfo":{"elapsed":997623,"status":"ok","timestamp":1615709093679,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"b4682830-2e4d-4430-db43-678c3c391979"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:327, P1:673.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T0dmaiblsJbO"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"T4_hS-CisJbO"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","mlp_layers=[520, 520, 110]\n","\n","model = 'models/dqn/sgr_testing/small_lr_small_batch'\n","# Wins: \n","# Wins2:\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUAJI2u8sJbP","executionInfo":{"elapsed":141627,"status":"ok","timestamp":1615708237625,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"9c33ff3b-4bb0-46ac-c407-b31f96d4aa5f"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:274, P1:726.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I-mOrFNVsJbP"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJhy39o3wQZj","executionInfo":{"elapsed":140795,"status":"ok","timestamp":1615709374561,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"e94ad4af-20ea-489c-b3b4-41ee0ad1124d"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:333, P1:667.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQsXaGqksJbQ","executionInfo":{"elapsed":425820,"status":"ok","timestamp":1615708521839,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"0af1d886-64b1-4da0-9183-1c98371f2bc4"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:305, P1:695.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yebMwpKHsJbQ","executionInfo":{"elapsed":568016,"status":"ok","timestamp":1615708664043,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"5f6135ce-0efd-46ee-d812-363983139903"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:284, P1:716.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjiRUHopsJbR","executionInfo":{"elapsed":710196,"status":"ok","timestamp":1615708806234,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"ba32e503-cfa3-4770-e556-5f828e822175"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:282, P1:718.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YAw8Q4BksJbR","executionInfo":{"elapsed":854163,"status":"ok","timestamp":1615708950209,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"697cc35e-7285-469d-efe4-36cb1393f5ce"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:317, P1:683.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLS7T26ssJbR","executionInfo":{"elapsed":281014,"status":"ok","timestamp":1615709514793,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"3ce3cc9a-46a2-4421-ac62-c20097a8bc8b"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:304, P1:696.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1Z5MDlAsJbS","executionInfo":{"elapsed":1136415,"status":"ok","timestamp":1615709232479,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"a5ae7c44-ef40-4f1e-8b0c-a7f2ebf55192"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:297, P1:703.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ijh7E63Pruf_"},"source":["### DQN - SGRAgent additional testing (4HL)"]},{"cell_type":"markdown","metadata":{"id":"daKKvjiprugR"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"34gMg8P0rugS"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","mlp_layers = [520, 1040, 1040, 520, 110]\n","# model = 'models/dqn/sgr_testing/4HL'\n","# Wins: 208/189/195/205/195\n","# Wins2: 193/210/202\n","model = 'models/dqn/sgr_testing/4HL_unfrozen'\n","# Wins: \n","# Wins2: \n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edISLGNirugT","executionInfo":{"elapsed":221663,"status":"ok","timestamp":1615710890797,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"4ac08ddf-658c-4a9e-d427-bd81b51cbc90"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:208, P1:792.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NEEKt1strugU"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eunGQ5K6rugV","executionInfo":{"elapsed":446513,"status":"ok","timestamp":1615711115650,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"e6da26c7-5fdf-46ff-eadc-5ca5199b11fa"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:189, P1:811.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNxP-cwDrugV","executionInfo":{"elapsed":680886,"status":"ok","timestamp":1615711350025,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"1e3e1aa0-9446-4b70-ef0c-db0e82423b18"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:195, P1:805.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFlegMdErugW","executionInfo":{"elapsed":907073,"status":"ok","timestamp":1615711576218,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"7b052990-8c5c-411f-9b5c-d05bef41192b"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:205, P1:795.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YED4JUu8rugX","executionInfo":{"elapsed":1126813,"status":"ok","timestamp":1615711795961,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"bb57daec-fc0f-4e1f-a8cd-2f7a0caccb0a"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:196, P1:804.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h085jUDYrugX","executionInfo":{"elapsed":1354646,"status":"ok","timestamp":1615712023801,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"1cc8f6d6-8b37-4933-ef2b-c226662c5ba8"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:193, P1:807.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8872ownrugY","executionInfo":{"elapsed":1579635,"status":"ok","timestamp":1615712248792,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"9c27f4bb-b897-4dda-be04-de8e0307227c"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:210, P1:790.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Al-BpbkurugY","executionInfo":{"elapsed":1812848,"status":"ok","timestamp":1615712482010,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"},"user_tz":240},"outputId":"18ba5bf0-dd32-4870-9964-ced7e7d67bb1"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:202, P1:798.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"21PObgbOD75E"},"source":["### DQN - SGRAgent additional testing (2HL_160K)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTAHK6iIy-ev","executionInfo":{"status":"ok","timestamp":1615793469580,"user_tz":240,"elapsed":146169,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"3c8da163-452f-494e-c4f2-152e0b3e5564"},"source":["batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","knock_layer = True # Include Knock layer\n","model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point2'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent1 = SimpleGinRummyPlayer()\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:332, P1:668.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3pnMb9I4N2C","executionInfo":{"status":"ok","timestamp":1615794665828,"user_tz":240,"elapsed":1010844,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"b854dc8c-9625-4177-d218-29468339eb83"},"source":["batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","knock_layer = True # Include Knock layer\n","model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point8'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent1 = SimpleGinRummyPlayer()\n","\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:357, P1:643.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1cSADqo6yWtQ"},"source":["### DQN - SGRAgent additional testing (2HL_160K)"]},{"cell_type":"markdown","metadata":{"id":"lyLf9qIaD75L"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"vPvhvKdtD75M"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k'\n","# Wins: 299/248/274/276/255\n","# Wins2: 304/285/305\n","\n","# knock_layer = False # No Knock layer\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point002'\n","# Wins: 297/285/289/314/253\n","# Wins2: 315/320/294\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point02'\n","# Wins: 318/236/256/292/243\n","# Wins2: 300/315/292\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point2'\n","# Wins: 306/293/275/268/255\n","# Wins2: 304/327/300\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point8'\n","# Wins: 309/296/315/307/276\n","# Wins2: 306/309/307\n","\n","# knock_layer = True # Include Knock layer\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point002'\n","# Wins: 308/292/281/284/247\n","# Wins2: 300/283/298\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point02'\n","# Wins: 310/257/258/273/241\n","# Wins2: 290/300/304\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point2'\n","# Wins: 307/258/297/294/258\n","# Wins2: 313/308/332\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point8'\n","# Wins: 347/327/346/330/320\n","# Wins2: 333/357/306\n","\n","# knock_layer = False # No Knock layer\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point8_payoff_v2'\n","# Wins: 297/259/287/317/246\n","# Wins2: 310/307/18\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point8_payoff_v9'\n","# Wins: 308/318/302/289/208\n","# Wins2: 316/323/305\n","\n","knock_layer = True # Include Knock layer\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point8_payoff_v2'\n","# Wins: 362/329/332/349/321\n","# Wins2: 342/306/323\n","model = 'models/dqn/sgr_testing/2HL_160k_6k_knock_point8_payoff_v9'\n","# Wins: 322/327/323/306/308\n","# Wins2: 334/326/338\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irGJyRscD75N","executionInfo":{"status":"ok","timestamp":1615874617000,"user_tz":240,"elapsed":151887,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"d7a0af49-be09-4357-8c2b-2672f99d71ce"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:322, P1:678.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5x2D901HD75O"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"di_ngsjhD75P","executionInfo":{"status":"ok","timestamp":1615874765062,"user_tz":240,"elapsed":299941,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"6e91259c-589a-41b0-f230-bea76e015654"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:327, P1:673.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KI8SSX-yD75P","executionInfo":{"status":"ok","timestamp":1615874914970,"user_tz":240,"elapsed":449841,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"dec91323-effc-4c14-8571-f387ed5abaf7"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:323, P1:677.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TpO51dTmD75Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615875064024,"user_tz":240,"elapsed":598883,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"26fece4e-0634-4b70-842c-c8d9750c24b0"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:306, P1:694.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CzR38ZYKD75R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615875212080,"user_tz":240,"elapsed":746929,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"c8ae4737-9195-4fa9-e28f-324bb0e1a1fe"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:308, P1:692.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_kO6ldhuD75R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615875360778,"user_tz":240,"elapsed":895618,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"0a79d266-44a3-4edb-8527-ec199fa09877"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:334, P1:666.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PHk34vcVD75S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615875513588,"user_tz":240,"elapsed":1048419,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"105678e8-d7cb-4a6b-d986-341452942040"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:326, P1:674.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ri1Dqsy_D75S","executionInfo":{"status":"ok","timestamp":1615875663393,"user_tz":240,"elapsed":1198216,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"7db5642c-8cee-4724-8ad3-6c91ab571736"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:338, P1:662.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L1KuXQusqQmX"},"source":["### DQN - SGRAgent additional testing (2HL_wide_160K_6k)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-feRFNeq0seB","executionInfo":{"status":"ok","timestamp":1615860912153,"user_tz":240,"elapsed":1201544,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"b76a7cd3-45d0-4bf2-ce90-45cc94702efe"},"source":["batch_norm = False\n","knock_layer = False\n","top_layer = False\n","mlp_layers = [1040, 1040, 110]\n","model = 'models/dqn/sgr_testing/2HL_wide_160k_6k'\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:358, P1:642.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NuvJtnWK0x8p"},"source":["### DQN - SGRAgent additional testing (2HL_wide_160K_6k)"]},{"cell_type":"markdown","metadata":{"id":"BuSCKeFsqQmc"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"c2JxXN4aqQmd"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","mlp_layers = [1040, 1040, 110]\n","# model = 'models/dqn/sgr_testing/2HL_wide_160k_6k'\n","# Wins: 330/314/271/329/302\n","# Wins2: 358/343/344\n","\n","top_layer = True\n","model = 'models/dqn/sgr_testing/2HL_wide_160k_6k_toplayer'\n","# Wins: 174/17/12/43/0\n","# Wins2: 152/4/169\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbQVSV00qQme","executionInfo":{"status":"ok","timestamp":1615861496906,"user_tz":240,"elapsed":192192,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"1b348f02-2602-4208-b1ab-9d2e09406373"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:174, P1:826.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mf3ym5UPqQmf"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cs33bzUPqQmf","executionInfo":{"status":"ok","timestamp":1615861635194,"user_tz":240,"elapsed":330473,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"b7a29e59-ea6a-47fb-df10-4791130fc08e"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:17, P1:983.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNRHxCIJqQmg","executionInfo":{"status":"ok","timestamp":1615861777972,"user_tz":240,"elapsed":473243,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"a4d9ea1d-948b-4e6d-aaed-eb7a175a68bc"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:12, P1:988.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAC41mdsqQmg","executionInfo":{"status":"ok","timestamp":1615861935147,"user_tz":240,"elapsed":630406,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"e4a627bb-7800-4a7c-a2f2-b2e2d1a7c9cd"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:43, P1:957.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c72O5-7oqQmh","executionInfo":{"status":"ok","timestamp":1615862060331,"user_tz":240,"elapsed":755579,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"33550ff0-e9b3-427c-b28f-a876cf06457f"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QYvFtIdoqQmi","executionInfo":{"status":"ok","timestamp":1615862246996,"user_tz":240,"elapsed":942237,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"1b9636e8-a0b5-4f7b-bab2-271d4dfa2a63"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:152, P1:848.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OSldp2F2qQmi","executionInfo":{"status":"ok","timestamp":1615862392789,"user_tz":240,"elapsed":1088021,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"081d35e4-624e-4f3c-b3df-0bac5556e14a"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:4, P1:996.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0QECV1hqQmj","executionInfo":{"status":"ok","timestamp":1615862580953,"user_tz":240,"elapsed":1276171,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"0569abee-061a-41cd-a16b-6f275a18eb00"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:169, P1:831.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0XBq4MHG6ugb"},"source":["### DQN - SGRAgent additional testing (stack layers 2HL_160K_6k)"]},{"cell_type":"markdown","metadata":{"id":"7_Wawx4v6ugt"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"k6r4QaU06ugt"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","knock_layer = False\n","top_layer = False\n","mlp_layers = [1040, 520, 110]\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_stackLayers'\n","# Wins: 241/216/238/205/184\n","# Wins2: 225/216/220\n","model = 'models/dqn/sgr_testing/2HL_160k_6k_stackLayers_unfrozen'\n","# Wins: 228/61/75/198/62\n","# Wins2: 209/201/204\n","\n","# mlp_layers = [1040, 1040, 110]\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_stackLayers2'\n","# Wins: 227/198/253/211/201\n","# Wins2: 264/230/241\n","\n","# mlp_layers = [1560, 520, 110]\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_stackLayers_3wide'\n","# Wins: 204/187/184/198/149\n","# Wins2: 161/188/190\n","\n","# mlp_layers = [1560, 1560, 110]\n","# model = 'models/dqn/sgr_testing/2HL_160k_6k_stackLayers_3wide2'\n","# Wins: 204/187/184/198/149\n","# Wins2: 161/188/190\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EiG8WFO-6ugu","executionInfo":{"status":"ok","timestamp":1615869475731,"user_tz":240,"elapsed":161446,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"38c4c445-e681-4739-cb8e-fcb6d08ed92e"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:228, P1:772.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SB9LW0BW6ugv"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEK8oFsi6ugv","executionInfo":{"status":"ok","timestamp":1615869642481,"user_tz":240,"elapsed":327570,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"cf713d0e-12f7-4d2b-925a-45d3c8bceea3"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:61, P1:939.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tT2J0M7E6ugw","executionInfo":{"status":"ok","timestamp":1615869811865,"user_tz":240,"elapsed":496941,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"d840c31a-4c5e-4c90-fd2f-94cf68cc8f67"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:75, P1:925.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"egNNZS2k6ugw","executionInfo":{"status":"ok","timestamp":1615869969886,"user_tz":240,"elapsed":654954,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"14ad4743-28b5-4c72-9108-403782ff1c7f"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:198, P1:802.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rgJAj3fn6ugw","executionInfo":{"status":"ok","timestamp":1615870135702,"user_tz":240,"elapsed":820761,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"17f584d9-e76f-47f0-b226-03151130e7d1"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:62, P1:938.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHp07-gU6ugx","executionInfo":{"status":"ok","timestamp":1615870296769,"user_tz":240,"elapsed":981820,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"c417a71d-b6b4-4c86-a94d-1be969bf7fc0"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:209, P1:791.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yaBk5-ne6ugx","executionInfo":{"status":"ok","timestamp":1615870457299,"user_tz":240,"elapsed":1142341,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"154d3a4d-ff20-4d72-f3ba-71efeef62e03"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:201, P1:799.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jqqPw37E6ugy","executionInfo":{"status":"ok","timestamp":1615870617728,"user_tz":240,"elapsed":1302763,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"ef5b8317-a4ea-45ca-bf41-8b760036fa7e"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:204, P1:796.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TUoy-A6cBlkH"},"source":["# Test Agents"]},{"cell_type":"markdown","metadata":{"id":"lc9rtMKCZ44i"},"source":["## MLP Models vs. SimpleGinRummyAgent (Current Batch)"]},{"cell_type":"markdown","metadata":{"id":"D3TEziyNZ2Bh"},"source":["### DQN - SGRAgent with knock layers + BS Testing (Best Models)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GV0g5o3obM-5","executionInfo":{"status":"ok","timestamp":1616484936417,"user_tz":240,"elapsed":203373,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"0304d365-6ec6-41f9-e9bf-a4c5315f3217"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/347/362/355/343\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Max Turns exceeded, restart\n","Game ...  500\n","Max Turns exceeded, restart\n","Game ...  750\n","Games Won: P0:510, P1:490.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIWb8HPaeL1o","executionInfo":{"status":"ok","timestamp":1616480442376,"user_tz":240,"elapsed":400110,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"097ab2a3-9f3b-49bd-d120-51a829b7e1d0"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/347/362/355/343\n","\n","numGames = 2000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Game ...  1000\n","Game ...  1250\n","Game ...  1500\n","Game ...  1750\n","Games Won: P0:1015, P1:985.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZa24tXSAegP","executionInfo":{"status":"ok","timestamp":1616490888502,"user_tz":240,"elapsed":1999503,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"6fff65e1-1f51-4573-e7e2-14a1c4ec82da"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/347/362/355/343\n","\n","numGames = 10000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Max Turns exceeded, restart\n","Game ...  500\n","Max Turns exceeded, restart\n","Game ...  750\n","Game ...  1000\n","Game ...  1250\n","Game ...  1500\n","Game ...  1750\n","Game ...  2000\n","Game ...  2250\n","Game ...  2500\n","Game ...  2750\n","Game ...  3000\n","Game ...  3250\n","Game ...  3500\n","Game ...  3750\n","Game ...  4000\n","Game ...  4250\n","Game ...  4500\n","Game ...  4750\n","Game ...  5000\n","Game ...  5250\n","Game ...  5500\n","Game ...  5750\n","Max Turns exceeded, restart\n","Game ...  6000\n","Game ...  6250\n","Game ...  6500\n","Game ...  6750\n","Game ...  7000\n","Game ...  7250\n","Game ...  7500\n","Game ...  7750\n","Max Turns exceeded, restart\n","Game ...  8000\n","Max Turns exceeded, restart\n","Game ...  8250\n","Game ...  8500\n","Game ...  8750\n","Game ...  9000\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  9250\n","Game ...  9500\n","Game ...  9750\n","Games Won: P0:4991, P1:5009.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pVq4ZH1oYN1o","executionInfo":{"status":"ok","timestamp":1616484049742,"user_tz":240,"elapsed":199728,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"04e126d8-395e-4ef6-b720-42bf296d7249"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/347/362/355/343\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Max Turns exceeded, restart\n","Game ...  500\n","Max Turns exceeded, restart\n","Game ...  750\n","Games Won: P0:521, P1:479.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZP99MGOndm8A","executionInfo":{"status":"ok","timestamp":1616477776819,"user_tz":240,"elapsed":1944535,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"be998e30-9724-4578-be17-3a0d55d78f1a"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/347/362/355/343\n","\n","numGames = 10000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Game ...  1000\n","Game ...  1250\n","Game ...  1500\n","Game ...  1750\n","Game ...  2000\n","Game ...  2250\n","Game ...  2500\n","Game ...  2750\n","Game ...  3000\n","Game ...  3250\n","Game ...  3500\n","Game ...  3750\n","Game ...  4000\n","Game ...  4250\n","Game ...  4500\n","Game ...  4750\n","Game ...  5000\n","Game ...  5250\n","Game ...  5500\n","Game ...  5750\n","Game ...  6000\n","Game ...  6250\n","Game ...  6500\n","Game ...  6750\n","Game ...  7000\n","Game ...  7250\n","Game ...  7500\n","Game ...  7750\n","Game ...  8000\n","Game ...  8250\n","Game ...  8500\n","Game ...  8750\n","Game ...  9000\n","Game ...  9250\n","Game ...  9500\n","Game ...  9750\n","Games Won: P0:5327, P1:4673.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZrHxmv7pAbrL","executionInfo":{"status":"ok","timestamp":1616488888940,"user_tz":240,"elapsed":3952146,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"27285e1a-69e9-4c27-c5fd-92f68802c1f0"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/347/362/355/343\n","\n","numGames = 10000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Max Turns exceeded, restart\n","Game ...  500\n","Max Turns exceeded, restart\n","Game ...  750\n","Game ...  1000\n","Game ...  1250\n","Game ...  1500\n","Max Turns exceeded, restart\n","Game ...  1750\n","Game ...  2000\n","Game ...  2250\n","Game ...  2500\n","Game ...  2750\n","Game ...  3000\n","Game ...  3250\n","Game ...  3500\n","Game ...  3750\n","Max Turns exceeded, restart\n","Game ...  4000\n","Game ...  4250\n","Game ...  4500\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  4750\n","Game ...  5000\n","Game ...  5250\n","Game ...  5500\n","Game ...  5750\n","Game ...  6000\n","Game ...  6250\n","Game ...  6500\n","Game ...  6750\n","Game ...  7000\n","Game ...  7250\n","Game ...  7500\n","Game ...  7750\n","Game ...  8000\n","Max Turns exceeded, restart\n","Game ...  8250\n","Game ...  8500\n","Game ...  8750\n","Game ...  9000\n","Max Turns exceeded, restart\n","Game ...  9250\n","Max Turns exceeded, restart\n","Game ...  9500\n","Game ...  9750\n","Games Won: P0:5331, P1:4669.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i62puAI8DKIU","executionInfo":{"status":"ok","timestamp":1616484250489,"user_tz":240,"elapsed":200736,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"be093bc3-94d4-4c50-bb03-4eaeabc92253"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/347/362/355/343\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Max Turns exceeded, restart\n","Game ...  500\n","Max Turns exceeded, restart\n","Game ...  750\n","Games Won: P0:537, P1:463.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ftxTgPXnH4SX","executionInfo":{"status":"ok","timestamp":1616471987310,"user_tz":240,"elapsed":1931804,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"5869c270-006b-4a48-8af5-c69cc7ff70a8"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/347/362/355/343\n","\n","numGames = 10000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Game ...  1000\n","Game ...  1250\n","Game ...  1500\n","Game ...  1750\n","Game ...  2000\n","Game ...  2250\n","Game ...  2500\n","Game ...  2750\n","Game ...  3000\n","Game ...  3250\n","Game ...  3500\n","Game ...  3750\n","Game ...  4000\n","Game ...  4250\n","Game ...  4500\n","Game ...  4750\n","Game ...  5000\n","Game ...  5250\n","Game ...  5500\n","Game ...  5750\n","Game ...  6000\n","Game ...  6250\n","Game ...  6500\n","Game ...  6750\n","Game ...  7000\n","Game ...  7250\n","Game ...  7500\n","Game ...  7750\n","Game ...  8000\n","Game ...  8250\n","Game ...  8500\n","Game ...  8750\n","Game ...  9000\n","Game ...  9250\n","Game ...  9500\n","Game ...  9750\n","Games Won: P0:5179, P1:4821.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zd2h2yI3AYmz","executionInfo":{"status":"ok","timestamp":1616486917436,"user_tz":240,"elapsed":1980654,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"a76c07c9-2f7a-45a3-9e67-9d73ddcabe8e"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/347/362/355/343\n","\n","numGames = 10000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Game ...  250\n","Max Turns exceeded, restart\n","Game ...  500\n","Max Turns exceeded, restart\n","Game ...  750\n","Game ...  1000\n","Game ...  1250\n","Game ...  1500\n","Max Turns exceeded, restart\n","Game ...  1750\n","Game ...  2000\n","Game ...  2250\n","Game ...  2500\n","Game ...  2750\n","Game ...  3000\n","Game ...  3250\n","Game ...  3500\n","Game ...  3750\n","Max Turns exceeded, restart\n","Game ...  4000\n","Game ...  4250\n","Game ...  4500\n","Max Turns exceeded, restart\n","Game ...  4750\n","Game ...  5000\n","Game ...  5250\n","Game ...  5500\n","Game ...  5750\n","Max Turns exceeded, restart\n","Game ...  6000\n","Game ...  6250\n","Game ...  6500\n","Max Turns exceeded, restart\n","Game ...  6750\n","Game ...  7000\n","Game ...  7250\n","Game ...  7500\n","Game ...  7750\n","Game ...  8000\n","Game ...  8250\n","Game ...  8500\n","Game ...  8750\n","Game ...  9000\n","Max Turns exceeded, restart\n","Game ...  9250\n","Max Turns exceeded, restart\n","Game ...  9500\n","Game ...  9750\n","Games Won: P0:5316, P1:4684.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MBNA7FOd46W8"},"source":["### DQN - SGRAgent with knock layers + BS Testing"]},{"cell_type":"markdown","metadata":{"id":"qvDjo4AqZ2Bl"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"re5YCDweZ2Bl"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# knock layer, bias = 1, frozen layers\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 304/302/308/314/306\n","# Wins2: 308/304/304\n","# knock_layer = True\n","# model = 'models/dqn/sgr_testing2/test5'\n","# Wins: 335/343/358/343/371\n","# Wins2: 337/335/335\n","\n","# knock layer, bias = 1, frozen layers, trained on selfplay\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test6'\n","# Wins: 304/251/192/297/216\n","# Wins2: 304/304/304\n","# knock_layer = True\n","# model = 'models/dqn/sgr_testing2/test6'\n","# Wins: \n","# Wins2:\n","\n","\n","# top layer and knock layer, bias = 1, frozen layers\n","# top_layer = True\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test7'\n","# Wins: \n","# Wins2:\n","# knock_layer = True\n","# model = 'models/dqn/sgr_testing2/test7'\n","# Wins: \n","# Wins2:\n","\n","\n","# frozen layers\n","# BS = 2048\n","# top_layer = False\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test8'\n","# Wins: \n","# Wins2:\n","\n","# knock layer, bias = 1, frozen layers\n","# BS = 2048\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test9'\n","# Wins: 304/304/304/304/304\n","# Wins2: 304/304/304\n","# knock_layer = True\n","# model = 'models/dqn/selfplay/test9'\n","# Wins: 335/335/335/335\n","# Wins2: 335/335/335\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c_7dEjmSZ2Bm","executionInfo":{"status":"ok","timestamp":1616808422241,"user_tz":240,"elapsed":68661,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"7c72017b-c65f-4601-bba9-02d9ec1078ce"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:359, P1:641.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZR4ZEGIZZ2Bn"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_ITPwRJZ2Bn","executionInfo":{"status":"ok","timestamp":1616808597402,"user_tz":240,"elapsed":53473,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"ef938654-41ea-4c46-8dba-54230527aa2e"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:355, P1:645.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRl7OnXIZ2Bo","executionInfo":{"status":"ok","timestamp":1616808779464,"user_tz":240,"elapsed":10269,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"88a91652-dd03-44ce-ff47-00088d4ca8c5"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:350, P1:650.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7c_K2yRTZ2Bo","executionInfo":{"status":"ok","timestamp":1616808960525,"user_tz":240,"elapsed":181078,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"3524a9b2-8e6c-4492-ba57-d7f7da58c54a"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:348, P1:652.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxlRX9CAZ2Bp","executionInfo":{"status":"ok","timestamp":1616809143680,"user_tz":240,"elapsed":183179,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"9cb9e477-23c5-4c05-b012-e8ca9b8a4f57"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:352, P1:648.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZGkoPZxZ2Bp","executionInfo":{"status":"ok","timestamp":1616809321677,"user_tz":240,"elapsed":178017,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"32bb333b-9f2d-4d07-f81a-19cc69026c5e"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:347, P1:653.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUt5llp8Z2Bp","executionInfo":{"status":"ok","timestamp":1616809497314,"user_tz":240,"elapsed":175658,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"8447132c-4b72-48a9-f9ef-24df47fb84fb"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:349, P1:651.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAYIp1dCZ2Bq","executionInfo":{"status":"ok","timestamp":1616809674056,"user_tz":240,"elapsed":176768,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"e06643fb-5689-4a47-9ba4-b6fd72d5e4a3"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:354, P1:646.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FICJzP2Qyflk"},"source":["### DQN - test5 additional training (Best Models)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AaHwg68-rG2W","executionInfo":{"status":"ok","timestamp":1616982900823,"user_tz":240,"elapsed":236040,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"7fd06299-143d-4f70-9375-60cdac4de6c3"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# test5 -> unfrozen knock layer\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test11'\n","# Wins: 371/373/372/368/374\n","# Wins2: 371/371/371\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Max Turns exceeded, restart\n","Game ...  250\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  500\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  750\n","Max Turns exceeded, restart\n","Games Won: P0:504, P1:496.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rU8alPBIrY-V","executionInfo":{"status":"ok","timestamp":1616985171249,"user_tz":240,"elapsed":2490884,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"1a0d6135-d139-4b85-cade-e65a96ca7100"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# test5 -> unfrozen knock layer\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test11'\n","# Wins: 371/373/372/368/374\n","# Wins2: 371/371/371\n","\n","numGames = 10000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","agent2 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent2.loadModel(qnet)\n","testAgents(agent0,agent2,numGames,verbose=False)"],"execution_count":59,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","Game ...  0\n","Max Turns exceeded, restart\n","Game ...  250\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  500\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  750\n","Max Turns exceeded, restart\n","Game ...  1000\n","Game ...  1250\n","Max Turns exceeded, restart\n","Game ...  1500\n","Max Turns exceeded, restart\n","Game ...  1750\n","Game ...  2000\n","Game ...  2250\n","Max Turns exceeded, restart\n","Game ...  2500\n","Max Turns exceeded, restart\n","Game ...  2750\n","Game ...  3000\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  3250\n","Game ...  3500\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  3750\n","Max Turns exceeded, restart\n","Game ...  4000\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  4250\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  4500\n","Game ...  4750\n","Game ...  5000\n","Game ...  5250\n","Game ...  5500\n","Game ...  5750\n","Max Turns exceeded, restart\n","Game ...  6000\n","Max Turns exceeded, restart\n","Game ...  6250\n","Game ...  6500\n","Game ...  6750\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  7000\n","Max Turns exceeded, restart\n","Game ...  7250\n","Max Turns exceeded, restart\n","Game ...  7500\n","Max Turns exceeded, restart\n","Game ...  7750\n","Game ...  8000\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Max Turns exceeded, restart\n","Game ...  8250\n","Game ...  8500\n","Max Turns exceeded, restart\n","Game ...  8750\n","Max Turns exceeded, restart\n","Game ...  9000\n","Max Turns exceeded, restart\n","Game ...  9250\n","Max Turns exceeded, restart\n","Game ...  9500\n","Game ...  9750\n","Games Won: P0:4982, P1:5018.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wi8TR_UmrE23"},"source":["### DQN - test5 additional training"]},{"cell_type":"markdown","metadata":{"id":"MvmGjThgyfl0"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"1bB3XYVayfl0"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","mlp_layers = [520, 520, 110]\n","\n","# test5 -> knock layer = 0.8\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test10'\n","# Wins: 306/306/306/306/306\n","# Wins2: 306/306/306\n","# knock_layer = True\n","# model = 'models/dqn/sgr_testing2/test10'\n","# Wins: 359/358/359/359/358\n","# Wins2: 359/359/359\n","\n","\n","# test5 -> unfrozen knock layer\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test11'\n","# Wins: 306/306/306/306/306\n","# Wins2: 306/306/306\n","# knock_layer = True\n","# model = 'models/dqn/sgr_testing2/test11'\n","# Wins: 371/373/372/368/374\n","# Wins2: 371/371/371\n","\n","\n","# test5 -> knock layer = 0.8 = test10 -> knock layer = 0.6\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test12'\n","# Wins: 306/306/308/307/308\n","# Wins2: 307/307/306\n","# knock_layer = True\n","# model = 'models/dqn/sgr_testing2/test12'\n","# Wins: 351/351/352/352/352\n","# Wins2: 352/352/251\n","\n","\n","# test5 -> knock layer = 0.8 + unfrozen knock layer\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test13'\n","# Wins: 306/306/306/306/306\n","# Wins2: 306/306/306\n","# knock_layer = True\n","# model = 'models/dqn/sgr_testing2/test13'\n","# Wins: 359/355/350/348/352\n","# Wins2: 347/349/354\n","\n","# test5 -> knock layer = 0.8 + unfrozen knock layer (and top)\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test14'\n","# Wins: 306/271/293/280/275\n","# Wins2: 297/297/295\n","# knock_layer = True\n","# model = 'models/dqn/sgr_testing2/test14'\n","# Wins: 359/304/337/306/308\n","# Wins2: 321/319/330\n","\n","\n","# test5 -> knock layer = 0.8 + unfrozen knock layer (and top), larger LR\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test15'\n","# Wins: 306/256/259/268/250\n","# Wins2: 236/241/243\n","# knock_layer = True\n","# model = 'models/dqn/sgr_testing2/test15'\n","# Wins: 359/286/156/173/156\n","# Wins2: 167/164/184\n","\n","\n","# test5 BUT unfrozen biases\n","# knock_layer = False\n","# model = 'models/dqn/sgr_testing2/test16'\n","# Wins: 304/323/297/291/286\n","# Wins2: 304/304/304\n","knock_layer = True\n","model = 'models/dqn/sgr_testing2/test16'\n","# Wins: 335/309/321/302/299\n","# Wins2: 335/335/335\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IbxZOu_Jyfl1","executionInfo":{"status":"ok","timestamp":1616871905779,"user_tz":240,"elapsed":170085,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"a3340b8e-7102-44d8-eb2c-0a59ea037e6f"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:335, P1:665.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VF0f6rRyyfl2"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OBAguAD1yfl2","executionInfo":{"status":"ok","timestamp":1616872071173,"user_tz":240,"elapsed":335469,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"ad69f7ba-9c88-4ccc-f81c-f56636a03176"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:309, P1:691.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ad7k5G1Gyfl3","executionInfo":{"status":"ok","timestamp":1616872243339,"user_tz":240,"elapsed":507625,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"9ad53c70-2fe4-4a0c-8e56-d58aa73ce71d"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:321, P1:679.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBF58AOKyfl3","executionInfo":{"status":"ok","timestamp":1616872414657,"user_tz":240,"elapsed":678934,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"83fc68d5-bb34-4e45-ad50-ba1ca9f74a72"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:302, P1:698.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YDWMrW7yfl4","executionInfo":{"status":"ok","timestamp":1616872584666,"user_tz":240,"elapsed":848935,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"b070ed25-a4f2-4bf5-b8dd-e95c86d06184"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:299, P1:701.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k7QEfjAyyfl4","executionInfo":{"status":"ok","timestamp":1616872750575,"user_tz":240,"elapsed":1014835,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"896272fe-fddb-4a1e-e15d-8b9214dc245c"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:335, P1:665.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cmMkCe16yfl4","executionInfo":{"status":"ok","timestamp":1616872918681,"user_tz":240,"elapsed":1182932,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"8f185a59-b19f-4353-b47a-272224ce5578"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:335, P1:665.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kf596Yy5yfl5","executionInfo":{"status":"ok","timestamp":1616873086432,"user_tz":240,"elapsed":1350674,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"97eda6f6-8b2c-4356-9d66-6fb98e48e5b4"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:335, P1:665.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gnhbtFfXT5tU"},"source":["### DQN - identity training"]},{"cell_type":"markdown","metadata":{"id":"at0kCCc-T5th"},"source":["#### Pre Training"]},{"cell_type":"code","metadata":{"id":"ENt6XG0vT5th"},"source":["# Wins: pre/rand/self/sgr/post\n","# Wins2: rand_k/self_k/sgr_k\n","# Wins: \n","# Wins2:\n","\n","batch_norm = False\n","top_layer = False\n","knock_layer = True\n","mlp_layers = [520, 520, 110]\n","\n","# both identity and bias trained layer\n","# model = 'models/dqn/identity/test1'\n","# Wins: 261/240/219/224/220\n","# Wins2: 258/239/251\n","\n","# only identity layer with knock layer bias\n","# model = 'models/dqn/identity/test2'\n","# Wins: 314/301/305/297/278\n","# Wins2: 314/314/314\n","\n","# both identity and bias trained layer, clamped to [-0.5, 0.5]\n","# model = 'models/dqn/identity/test3'\n","# Wins: 172/191/194/185/191\n","# Wins2: 179/180/199\n","\n","# only identity layer (10% data) with knock layer bias, clamped to [-0.5, 0.5]\n","# model = 'models/dqn/identity/test4'\n","# Wins: 1/26/29/27/34\n","# Wins2: 1/1/1\n","\n","# both identity and bias trained layer (5K samples), clamped to [-0.5, 0.5]\n","model = 'models/dqn/identity/test5'\n","# Wins: 0/0/0/0/0\n","# Wins2: 0/0/0\n","\n","# only identity layer (5K samples) with knock layer bias, clamped to [-0.5, 0.5]\n","# model = 'models/dqn/identity/test6'\n","# Wins: 0/0/0/0/0\n","# Wins2: 0/0/0\n","\n","numGames = 1000\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","agent1 = SimpleGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CHqj6XGqT5ti","executionInfo":{"status":"ok","timestamp":1616981654762,"user_tz":240,"elapsed":44673,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"bcbc369e-7014-4074-a080-d1667aa574d2"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FFAeFYu8T5tk"},"source":["#### Post DQN Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aPwdSnKvT5tl","executionInfo":{"status":"ok","timestamp":1616981698613,"user_tz":240,"elapsed":88494,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"94f6a057-181e-433c-d7c6-92543965c64c"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LHy0rNEGT5tl","executionInfo":{"status":"ok","timestamp":1616981742942,"user_tz":240,"elapsed":132803,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"23b30235-1165-420e-c4a9-ef7d33da2fe9"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6z2K9RVIT5tm","executionInfo":{"status":"ok","timestamp":1616981787051,"user_tz":240,"elapsed":176891,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"281dddd9-7a37-42d1-8b07-db0d3a2c9047"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lniVjj_0T5tm","executionInfo":{"status":"ok","timestamp":1616981831246,"user_tz":240,"elapsed":221070,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"cbe863b9-9667-47be-d786-e0ef2130106f"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFzc0VE4T5tn","executionInfo":{"status":"ok","timestamp":1616981875334,"user_tz":240,"elapsed":265144,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"b382623c-d6f0-462d-c4f0-b06d1b838527"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hy_WkRJIT5tn","executionInfo":{"status":"ok","timestamp":1616981919182,"user_tz":240,"elapsed":308976,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"6f4ccae6-e624-4735-9014-bdb6e438b91b"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Msk0WPXbT5to","executionInfo":{"status":"ok","timestamp":1616981963427,"user_tz":240,"elapsed":353208,"user":{"displayName":"Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5tnT6-9qtBGPuIb6oMhXIc5dSfo2mGGOQWKMHqf8=s64","userId":"12200632467998545940"}},"outputId":"0183664a-3952-4583-a7d8-db61af9c4bc3"},"source":["agent0 = MLPGinRummyPlayer()\n","checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n","qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n","qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n","agent0.loadModel(qnet)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  250\n","Game ...  500\n","Game ...  750\n","Games Won: P0:0, P1:1000.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jRDlFr6BrtD7"},"source":["## Test"]},{"cell_type":"markdown","metadata":{"id":"hm0ghfYvVKjZ"},"source":["### Single Game Verbose"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HlO2BNiS_6Ud","executionInfo":{"elapsed":1907,"status":"ok","timestamp":1613498404549,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"a0949488-19b0-420c-9346-67ad7373953a"},"source":["numGames = 1\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST2/model_pretrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Player 0 is dealt [5C, 8H, KH, 8C, 4S, KS, 2S, TD, 5H, 2D].\n","\n","Player 1 is dealt [TH, 9S, 6D, JD, JC, QS, QH, 3C, 3D, 2H].\n","\n","Player 1 starts.\n","\n","The initial face up card is 6H.\n","\n","Player 1 declines 6H.\n","\n","Update States\n","Draw new card: 0.019223161\n","Pickup from discard: 0.019223161\n","Player 0 declines 6H.\n","\n","Draw from deck\n","Player 1 draws KD.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [9S, 6D, JD, JC, QS, QH, 3C, 3D, 2H, KD] with 73 deadwood.\n","\n","Update States\n","Draw new card: 0.019204292\n","Pickup from discard: 0.019204292\n","Draw from deck\n","Player 0 draws AH.\n","\n","Update States\n","Current Hand: [5C, 8H, KH, 8C, 4S, KS, 2S, TD, 5H, 2D, AH]\n","Discard KS | D: KS | K: TD | 18\n","MAX:0.0182, 0.0136\n","Discard Action\n","Player 0 discards KS.\n","\n","Player 0 has [5C, 8H, KH, 8C, 4S, 2S, TD, 5H, 2D, AH] with 55 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6S.\n","\n","Player 1 discards JC.\n","\n","Player 1 has [9S, 6D, JD, QS, QH, 3C, 3D, 2H, KD, 6S] with 69 deadwood.\n","\n","Update States\n","Draw new card: 0.021352563\n","Pickup from discard: 0.021352563\n","Draw from deck\n","Player 0 draws TS.\n","\n","Update States\n","Current Hand: [5C, 8H, KH, 8C, 4S, 2S, TD, 5H, 2D, AH, TS]\n","Discard TS | D: TS | K: AH | 15\n","MAX:0.0184, 0.0068\n","Discard Action\n","Player 0 discards TS.\n","\n","Player 0 has [5C, 8H, KH, 8C, 4S, 2S, TD, 5H, 2D, AH] with 55 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5D.\n","\n","Player 1 discards QH.\n","\n","Player 1 has [9S, 6D, JD, QS, 3C, 3D, 2H, KD, 6S, 5D] with 64 deadwood.\n","\n","Update States\n","Draw new card: 0.019704962\n","Pickup from discard: 0.019704962\n","Draw from deck\n","Player 0 draws 4H.\n","\n","Update States\n","Current Hand: [5C, 8H, KH, 8C, 4S, 2S, TD, 5H, 2D, AH, 4H]\n","Discard 8H | D: 8H | K: TD | 26\n","MAX:0.0184, 0.0137\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [5C, KH, 8C, 4S, 2S, TD, 5H, 2D, AH, 4H] with 51 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4D.\n","\n","Player 1 discards JD.\n","\n","Player 1 has [[3D, 4D, 5D, 6D], 9S, QS, 3C, 2H, KD, 6S] with 40 deadwood.\n","\n","Update States\n","Draw new card: 0.022697309\n","Pickup from discard: 0.022697307\n","Draw from deck\n","Player 0 draws 6C.\n","\n","Update States\n","Current Hand: [5C, KH, 8C, 4S, 2S, TD, 5H, 2D, AH, 4H, 6C]\n","Discard KH | D: KH | K: TD | 31\n","MAX:0.0198, 0.0121\n","Discard Action\n","Player 0 discards KH.\n","\n","Player 0 has [5C, 8C, 4S, 2S, TD, 5H, 2D, AH, 4H, 6C] with 47 deadwood.\n","\n","Draw from deck\n","Player 1 draws JH.\n","\n","Player 1 discards JH.\n","\n","Player 1 has [[3D, 4D, 5D, 6D], 9S, QS, 3C, 2H, KD, 6S] with 40 deadwood.\n","\n","Update States\n","Draw new card: 0.021325398\n","Pickup from discard: 0.021324947\n","Draw from deck\n","Player 0 draws AD.\n","\n","Update States\n","Current Hand: [5C, 8C, 4S, 2S, TD, 5H, 2D, AH, 4H, 6C, AD]\n","Discard TD | D: TD | K: TD | 41\n","MAX:0.0192, 0.0192\n","Knock Action\n","Player 0 discards TD.\n","\n","Player 0 has [5C, 8C, 4S, 2S, 5H, 2D, AH, 4H, 6C, AD] with 38 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7H.\n","\n","Player 1 discards QS.\n","\n","Player 1 has [[3D, 4D, 5D, 6D], 9S, 3C, 2H, KD, 6S, 7H] with 37 deadwood.\n","\n","Update States\n","Draw new card: 0.023061443\n","Pickup from discard: 0.023061438\n","Draw from deck\n","Player 0 draws 5S.\n","\n","Update States\n","Current Hand: [[5S, 5H, 5C], 8C, 4S, 2S, 2D, AH, 4H, 6C, AD]\n","Discard 8C | D: 8C | K: 8C | 52\n","MAX:0.0192, 0.0192\n","Discard Action\n","Player 0 discards 8C.\n","\n","Player 0 has [[5S, 5H, 5C], 4S, 2S, 2D, AH, 4H, 6C, AD] with 20 deadwood.\n","\n","Draw from deck\n","Player 1 draws TC.\n","\n","Player 1 discards KD.\n","\n","Player 1 has [[3D, 4D, 5D, 6D], 9S, 3C, 2H, 6S, 7H, TC] with 37 deadwood.\n","\n","Update States\n","Draw new card: 0.023577109\n","Pickup from discard: 0.023577094\n","Draw from deck\n","Player 0 draws QD.\n","\n","Update States\n","Current Hand: [[5S, 5H, 5C], 4S, 2S, 2D, AH, 4H, 6C, AD, QD]\n","Discard QD | D: QD | K: QD | 43\n","MAX:0.0174, 0.0174\n","Knock Action\n","Player 0 discards QD.\n","\n","Player 0 has [[5S, 5H, 5C], 4S, 2S, 2D, AH, 4H, 6C, AD] with 20 deadwood.\n","\n","Draw from deck\n","Player 1 draws 8S.\n","\n","Player 1 discards TC.\n","\n","Player 1 has [[3D, 4D, 5D, 6D], 9S, 3C, 2H, 6S, 7H, 8S] with 35 deadwood.\n","\n","Update States\n","Draw new card: 0.023449665\n","Pickup from discard: 0.023449628\n","Draw from deck\n","Player 0 draws 9C.\n","\n","Update States\n","Current Hand: [[5S, 5H, 5C], 4S, 2S, 2D, AH, 4H, 6C, AD, 9C]\n","Discard 9C | D: 9C | K: 9C | 53\n","MAX:0.0200, 0.0200\n","Knock Action\n","Player 0 discards 9C.\n","\n","Player 0 has [[5S, 5H, 5C], 4S, 2S, 2D, AH, 4H, 6C, AD] with 20 deadwood.\n","\n","Draw from deck\n","Player 1 draws JS.\n","\n","Player 1 discards JS.\n","\n","Player 1 has [[3D, 4D, 5D, 6D], 9S, 3C, 2H, 6S, 7H, 8S] with 35 deadwood.\n","\n","Update States\n","Draw new card: 0.023496853\n","Pickup from discard: 0.023412526\n","Draw from deck\n","Player 0 draws AC.\n","\n","Update States\n","Current Hand: [[AH, AD, AC], [5S, 5H, 5C], 4S, 2S, 2D, 4H, 6C]\n","Discard 6C | D: 6C | K: 6C | 50\n","MAX:0.0197, 0.0197\n","Discard Action\n","Player 0 discards 6C.\n","\n","Player 0 has [[AH, AD, AC], [5S, 5H, 5C], 4S, 2S, 2D, 4H] with 12 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 6C.\n","\n","Player 1 discards 9S.\n","\n","Player 1 has [[3D, 4D, 5D], [6S, 6D, 6C], 3C, 2H, 7H, 8S] with 20 deadwood.\n","\n","Update States\n","Draw new card: 0.023377\n","Pickup from discard: 0.023377\n","Draw from deck\n","Player 0 draws 8D.\n","\n","Update States\n","Current Hand: [[AH, AD, AC], [5S, 5H, 5C], 4S, 2S, 2D, 4H, 8D]\n","Discard 8D | D: 8D | K: 8D | 39\n","MAX:0.0193, 0.0193\n","Knock Action\n","Player 0 discards 8D.\n","\n","Player 0 has [[AH, AD, AC], [5S, 5H, 5C], 4S, 2S, 2D, 4H] with 12 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9D.\n","\n","Player 1 discards 9D.\n","\n","Player 1 has [[3D, 4D, 5D], [6S, 6D, 6C], 3C, 2H, 7H, 8S] with 20 deadwood.\n","\n","Update States\n","Draw new card: 0.02364324\n","Pickup from discard: 0.023643017\n","Draw from deck\n","Player 0 draws 2C.\n","\n","Update States\n","Current Hand: [[AH, AD, AC], [2S, 2D, 2C], [5S, 5H, 5C], 4S, 4H]\n","Knock 4S | D: 4S | K: 4S | 61\n","MAX:0.0163, 0.0163\n","Knock Action\n","Player 0 discards 4S.\n","\n","Player 0 has [[AH, AD, AC], [2S, 2D, 2C], [5S, 5H, 5C], 4H] with 4 deadwood.\n","\n","True\n","Player 0 melds [[AH, AD, AC], [2S, 2D, 2C], [5S, 5H, 5C]] with 4 deadwood from [4H].\n","\n","Player 1 melds [[3D, 4D, 5D], [6S, 6D, 6C]].\n","\n","Player 1 lays off 2H on [2S, 2D, 2C].\n","\n","Player 1 has 18 deadwood with [8S, 7H, 3C]\n","\n","Player 0 scores the deadwood difference of 14.\n","\n","Player\tScore\n","0\t14\n","1\t0\n","\n","Player 0 is dealt [5H, 4H, QH, JC, JD, 8D, 5S, 6C, 4C, KC].\n","\n","Player 1 is dealt [JS, 6H, TD, TH, 2H, 8S, TC, KS, 2D, 9D].\n","\n","Player 0 starts.\n","\n","The initial face up card is JH.\n","\n","Update States\n","Draw new card: 0.020194687\n","Pickup from discard: 0.020194687\n","Player 0 declines JH.\n","\n","Player 1 declines JH.\n","\n","Draw from deck\n","Player 0 draws QC.\n","\n","Update States\n","Current Hand: [[JC, QC, KC], 5H, 4H, QH, JD, 8D, 5S, 6C, 4C]\n","Discard JD | D: JD | K: JD | 42\n","MAX:0.0177, 0.0176\n","Discard Action\n","Player 0 discards JD.\n","\n","Player 0 has [[JC, QC, KC], 5H, 4H, QH, 8D, 5S, 6C, 4C] with 42 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws JD.\n","\n","Player 1 discards JS.\n","\n","Player 1 has [[TH, TD, TC], 6H, 2H, 8S, KS, 2D, 9D, JD] with 47 deadwood.\n","\n","Update States\n","Draw new card: 0.022573186\n","Pickup from discard: 0.022573186\n","Draw from deck\n","Player 0 draws AC.\n","\n","Update States\n","Current Hand: [[JC, QC, KC], 5H, 4H, QH, 8D, 5S, 6C, 4C, AC]\n","Discard QH | D: QH | K: QH | 30\n","MAX:0.0191, 0.0081\n","Discard Action\n","Player 0 discards QH.\n","\n","Player 0 has [[JC, QC, KC], 5H, 4H, 8D, 5S, 6C, 4C, AC] with 33 deadwood.\n","\n","Draw from deck\n","Player 1 draws AH.\n","\n","Player 1 discards JD.\n","\n","Player 1 has [[TH, TD, TC], 6H, 2H, 8S, KS, 2D, 9D, AH] with 38 deadwood.\n","\n","Update States\n","Draw new card: 0.022364242\n","Pickup from discard: 0.022364242\n","Draw from deck\n","Player 0 draws 5D.\n","\n","Update States\n","Current Hand: [[JC, QC, KC], [5S, 5H, 5D], 4H, 8D, 6C, 4C, AC]\n","Discard 8D | D: 8D | K: 8D | 39\n","MAX:0.0185, 0.0185\n","Discard Action\n","Player 0 discards 8D.\n","\n","Player 0 has [[JC, QC, KC], [5S, 5H, 5D], 4H, 6C, 4C, AC] with 15 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 8D.\n","\n","Player 1 discards KS.\n","\n","Player 1 has [[TH, TD, TC], 6H, 2H, 8S, 2D, 9D, AH, 8D] with 36 deadwood.\n","\n","Update States\n","Draw new card: 0.023179192\n","Pickup from discard: 0.023179192\n","Draw from deck\n","Player 0 draws 9S.\n","\n","Update States\n","Current Hand: [[JC, QC, KC], [5S, 5H, 5D], 4H, 6C, 4C, AC, 9S]\n","Discard 9S | D: 9S | K: 9S | 14\n","MAX:0.0184, 0.0184\n","Discard Action\n","Player 0 discards 9S.\n","\n","Player 0 has [[JC, QC, KC], [5S, 5H, 5D], 4H, 6C, 4C, AC] with 15 deadwood.\n","\n","Draw from deck\n","Player 1 draws AD.\n","\n","Player 1 discards 9D.\n","\n","Player 1 has [[TH, TD, TC], 6H, 2H, 8S, 2D, AH, 8D, AD] with 28 deadwood.\n","\n","Update States\n","Draw new card: 0.022988789\n","Pickup from discard: 0.022988789\n","Draw from deck\n","Player 0 draws 4S.\n","\n","Update States\n","Current Hand: [[JC, QC, KC], [4S, 4H, 4C], [5S, 5H, 5D], 6C, AC]\n","Discard 6C | D: 6C | K: AC | 50\n","MAX:0.0193, 0.0076\n","Discard Action\n","Player 0 discards 6C.\n","\n","Player 0 has [[JC, QC, KC], [4S, 4H, 4C], [5S, 5H, 5D], AC] with 1 deadwood.\n","\n","False\n","Draw from deck\n","Player 1 draws 3D.\n","\n","Player 1 discards 8D.\n","\n","Player 1 has [[AD, 2D, 3D], [TH, TD, TC], 6H, 2H, 8S, AH] with 17 deadwood.\n","\n","Update States\n","Draw new card: 0.023603946\n","Pickup from discard: 0.023603946\n","Draw from deck\n","Player 0 draws 3C.\n","\n","Update States\n","Current Hand: [[JC, QC, KC], [4S, 4H, 4C], [5S, 5H, 5D], AC, 3C]\n","Knock 4C | D: 5S | K: 4C | 100\n","MAX:0.0172, 0.0172\n","Knock Action\n","Player 0 discards 4C.\n","\n","Player 0 has [[JC, QC, KC], [5S, 5H, 5D], 4H, AC, 4S, 3C] with 12 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7D.\n","\n","Player 1 discards 8S.\n","\n","Player 1 has [[AD, 2D, 3D], [TH, TD, TC], 6H, 2H, AH, 7D] with 16 deadwood.\n","\n","Update States\n","Draw new card: 0.023553126\n","Pickup from discard: 0.023553126\n","Draw from deck\n","Player 0 draws 3S.\n","\n","Update States\n","Current Hand: [[JC, QC, KC], [5S, 5H, 5D], 4H, AC, 4S, 3C, 3S]\n","Knock AC | D: 4S | K: AC | 97\n","MAX:0.0198, 0.0198\n","Knock Action\n","Player 0 discards AC.\n","\n","Player 0 has [[JC, QC, KC], [5S, 5H, 5D], 4H, 4S, 3C, 3S] with 14 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws AC.\n","\n","Player 1 discards 7D.\n","\n","Player 1 has [[AD, 2D, 3D], [TH, TD, TC], 6H, 2H, AH, AC] with 10 deadwood.\n","\n","Player 1 melds [[AD, 2D, 3D], [TH, TD, TC]] with 10 deadwood from [AH, 2H, 6H, AC].\n","\n","Player 0 melds [[JC, QC, KC], [5S, 5H, 5D]].\n","\n","Player 0 has 14 deadwood with [3S, 4S, 4H, 3C]\n","\n","Player 1 scores the deadwood difference of 4.\n","\n","Player\tScore\n","0\t14\n","1\t4\n","\n","Player 0 is dealt [JS, TC, 6S, AD, TD, 5C, 2H, 4S, 3S, 9D].\n","\n","Player 1 is dealt [6C, 3C, 9H, JC, 8S, 2D, 2S, JD, QH, 9S].\n","\n","Player 1 starts.\n","\n","The initial face up card is 7D.\n","\n","Player 1 declines 7D.\n","\n","Update States\n","Draw new card: 0.019494707\n","Pickup from discard: 0.019494707\n","Player 0 declines 7D.\n","\n","Draw from deck\n","Player 1 draws 3H.\n","\n","Player 1 discards QH.\n","\n","Player 1 has [6C, 3C, 9H, JC, 8S, 2D, 2S, JD, 9S, 3H] with 62 deadwood.\n","\n","Update States\n","Draw new card: 0.021372914\n","Pickup from discard: 0.021372914\n","Draw from deck\n","Player 0 draws JH.\n","\n","Update States\n","Current Hand: [JS, TC, 6S, AD, TD, 5C, 2H, 4S, 3S, 9D, JH]\n","Discard JS | D: JS | K: JH | 16\n","MAX:0.0179, 0.0179\n","Discard Action\n","Player 0 discards JS.\n","\n","Player 0 has [TC, 6S, AD, TD, 5C, 2H, 4S, 3S, 9D, JH] with 60 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws JS.\n","\n","Player 1 discards 9S.\n","\n","Player 1 has [[JS, JD, JC], 6C, 3C, 9H, 8S, 2D, 2S, 3H] with 33 deadwood.\n","\n","Update States\n","Draw new card: 0.02022956\n","Pickup from discard: 0.02022956\n","Draw from deck\n","Player 0 draws 5S.\n","\n","Update States\n","Current Hand: [[3S, 4S, 5S, 6S], TC, AD, TD, 5C, 2H, 9D, JH]\n","Discard JH | D: JH | K: JH | 29\n","MAX:0.0180, 0.0180\n","Knock Action\n","Player 0 discards JH.\n","\n","Player 0 has [[3S, 4S, 5S, 6S], TC, AD, TD, 5C, 2H, 9D] with 37 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws JH.\n","\n","Player 1 discards 9H.\n","\n","Player 1 has [[JS, JH, JD, JC], 6C, 3C, 8S, 2D, 2S, 3H] with 24 deadwood.\n","\n","Update States\n","Draw new card: 0.021842796\n","Pickup from discard: 0.02184279\n","Draw from deck\n","Player 0 draws KC.\n","\n","Update States\n","Current Hand: [[3S, 4S, 5S, 6S], TC, AD, TD, 5C, 2H, 9D, KC]\n","Discard TD | D: TD | K: KC | 41\n","MAX:0.0178, 0.0178\n","Discard Action\n","Player 0 discards TD.\n","\n","Player 0 has [[3S, 4S, 5S, 6S], TC, AD, 5C, 2H, 9D, KC] with 37 deadwood.\n","\n","Draw from deck\n","Player 1 draws QC.\n","\n","Player 1 discards QC.\n","\n","Player 1 has [[JS, JH, JD, JC], 6C, 3C, 8S, 2D, 2S, 3H] with 24 deadwood.\n","\n","Update States\n","Draw new card: 0.02112055\n","Pickup from discard: 0.02112055\n","Draw from deck\n","Player 0 draws AH.\n","\n","Update States\n","Current Hand: [[3S, 4S, 5S, 6S], TC, AD, 5C, 2H, 9D, KC, AH]\n","Discard TC | D: TC | K: TC | 54\n","MAX:0.0181, 0.0181\n","Discard Action\n","Player 0 discards TC.\n","\n","Player 0 has [[3S, 4S, 5S, 6S], AD, 5C, 2H, 9D, KC, AH] with 28 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7H.\n","\n","Player 1 discards 8S.\n","\n","Player 1 has [[JS, JH, JD, JC], 6C, 3C, 2D, 2S, 3H, 7H] with 23 deadwood.\n","\n","Update States\n","Draw new card: 0.022201914\n","Pickup from discard: 0.022201914\n","Draw from deck\n","Player 0 draws QD.\n","\n","Update States\n","Current Hand: [[3S, 4S, 5S, 6S], AD, 5C, 2H, 9D, KC, AH, QD]\n","Discard QD | D: QD | K: QD | 43\n","MAX:0.0189, 0.0189\n","Discard Action\n","Player 0 discards QD.\n","\n","Player 0 has [[3S, 4S, 5S, 6S], AD, 5C, 2H, 9D, KC, AH] with 28 deadwood.\n","\n","Draw from deck\n","Player 1 draws QS.\n","\n","Player 1 discards QS.\n","\n","Player 1 has [[JS, JH, JD, JC], 6C, 3C, 2D, 2S, 3H, 7H] with 23 deadwood.\n","\n","Update States\n","Draw new card: 0.02285829\n","Pickup from discard: 0.022858156\n","Draw from deck\n","Player 0 draws 2C.\n","\n","Update States\n","Current Hand: [[3S, 4S, 5S, 6S], AD, 5C, 2H, 9D, KC, AH, 2C]\n","Discard KC | D: KC | K: KC | 57\n","MAX:0.0197, 0.0197\n","Discard Action\n","Player 0 discards KC.\n","\n","Player 0 has [[3S, 4S, 5S, 6S], AD, 5C, 2H, 9D, AH, 2C] with 20 deadwood.\n","\n","Draw from deck\n","Player 1 draws 3D.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[3H, 3D, 3C], [JS, JH, JD, JC], 6C, 2D, 2S] with 10 deadwood.\n","\n","Player 1 melds [[3H, 3D, 3C], [JS, JH, JD, JC]] with 10 deadwood from [2S, 2D, 6C].\n","\n","Player 0 melds [[3S, 4S, 5S, 6S]].\n","\n","Player 0 has 20 deadwood with [AH, 2H, AD, 9D, 2C, 5C]\n","\n","Player 1 scores the deadwood difference of 10.\n","\n","Player\tScore\n","0\t14\n","1\t14\n","\n","Player 0 is dealt [3H, QC, QD, 8S, 2S, QS, 4C, TS, 7S, 5C].\n","\n","Player 1 is dealt [KH, AH, KD, JH, 4S, JD, 9S, 7H, AC, 3D].\n","\n","Player 0 starts.\n","\n","The initial face up card is 6H.\n","\n","Update States\n","Draw new card: 0.020703575\n","Pickup from discard: 0.020703575\n","Player 0 declines 6H.\n","\n","Player 1 declines 6H.\n","\n","Draw from deck\n","Player 0 draws 8C.\n","\n","Update States\n","Current Hand: [[QS, QD, QC], 3H, 8S, 2S, 4C, TS, 7S, 5C, 8C]\n","Discard TS | D: TS | K: TS | 15\n","MAX:0.0179, 0.0104\n","Discard Action\n","Player 0 discards TS.\n","\n","Player 0 has [[QS, QD, QC], 3H, 8S, 2S, 4C, 7S, 5C, 8C] with 37 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7C.\n","\n","Player 1 discards KH.\n","\n","Player 1 has [AH, KD, JH, 4S, JD, 9S, 7H, AC, 3D, 7C] with 62 deadwood.\n","\n","Update States\n","Draw new card: 0.022282304\n","Pickup from discard: 0.022282304\n","Draw from deck\n","Player 0 draws TH.\n","\n","Update States\n","Current Hand: [[QS, QD, QC], 3H, 8S, 2S, 4C, 7S, 5C, 8C, TH]\n","Discard TH | D: TH | K: TH | 28\n","MAX:0.0188, 0.0130\n","Discard Action\n","Player 0 discards TH.\n","\n","Player 0 has [[QS, QD, QC], 3H, 8S, 2S, 4C, 7S, 5C, 8C] with 37 deadwood.\n","\n","Draw from deck\n","Player 1 draws 2C.\n","\n","Player 1 discards JD.\n","\n","Player 1 has [AH, KD, JH, 4S, 9S, 7H, AC, 3D, 7C, 2C] with 54 deadwood.\n","\n","Update States\n","Draw new card: 0.023171045\n","Pickup from discard: 0.023171045\n","Draw from deck\n","Player 0 draws 3C.\n","\n","Update States\n","Current Hand: [[3C, 4C, 5C], [QS, QD, QC], 3H, 8S, 2S, 7S, 8C]\n","Discard 7S | D: 7S | K: 8C | 12\n","MAX:0.0207, 0.0178\n","Discard Action\n","Player 0 discards 7S.\n","\n","Player 0 has [[3C, 4C, 5C], [QS, QD, QC], 3H, 8S, 2S, 8C] with 21 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 7S.\n","\n","Player 1 discards JH.\n","\n","Player 1 has [[7S, 7H, 7C], AH, KD, 4S, 9S, AC, 3D, 2C] with 30 deadwood.\n","\n","Update States\n","Draw new card: 0.023385802\n","Pickup from discard: 0.023385802\n","Draw from deck\n","Player 0 draws JS.\n","\n","Update States\n","Current Hand: [[3C, 4C, 5C], [QS, QD, QC], 3H, 8S, 2S, 8C, JS]\n","Discard JS | D: JS | K: JS | 16\n","MAX:0.0186, 0.0186\n","Discard Action\n","Player 0 discards JS.\n","\n","Player 0 has [[3C, 4C, 5C], [QS, QD, QC], 3H, 8S, 2S, 8C] with 21 deadwood.\n","\n","Draw from deck\n","Player 1 draws 2H.\n","\n","Player 1 discards KD.\n","\n","Player 1 has [[7S, 7H, 7C], AH, 4S, 9S, AC, 3D, 2C, 2H] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.022908153\n","Pickup from discard: 0.022908153\n","Draw from deck\n","Player 0 draws AD.\n","\n","Update States\n","Current Hand: [[3C, 4C, 5C], [QS, QD, QC], 3H, 8S, 2S, 8C, AD]\n","Discard 8S | D: 8S | K: 8S | 13\n","MAX:0.0215, 0.0097\n","Discard Action\n","Player 0 discards 8S.\n","\n","Player 0 has [[3C, 4C, 5C], [QS, QD, QC], 3H, 2S, 8C, AD] with 14 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 8S.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[7S, 8S, 9S], AH, 4S, AC, 3D, 7C, 2C, 2H] with 20 deadwood.\n","\n","Update States\n","Draw new card: 0.023283549\n","Pickup from discard: 0.023272196\n","Draw from deck\n","Player 0 draws 5H.\n","\n","Update States\n","Current Hand: [[3C, 4C, 5C], [QS, QD, QC], 3H, 2S, 8C, AD, 5H]\n","Discard 8C | D: 8C | K: 8C | 52\n","MAX:0.0201, 0.0201\n","Discard Action\n","Player 0 discards 8C.\n","\n","Player 0 has [[3C, 4C, 5C], [QS, QD, QC], 3H, 2S, AD, 5H] with 11 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9D.\n","\n","Player 1 discards 9D.\n","\n","Player 1 has [[7S, 8S, 9S], AH, 4S, AC, 3D, 7C, 2C, 2H] with 20 deadwood.\n","\n","Update States\n","Draw new card: 0.023419963\n","Pickup from discard: 0.023318898\n","Draw from deck\n","Player 0 draws AS.\n","\n","Update States\n","Current Hand: [[3C, 4C, 5C], [QS, QD, QC], 3H, 2S, AD, 5H, AS]\n","Knock 5H | D: 5H | K: 5H | 75\n","MAX:0.0197, 0.0197\n","Knock Action\n","Player 0 discards 5H.\n","\n","Player 0 has [[3C, 4C, 5C], [QS, QD, QC], 3H, 2S, AD, AS] with 7 deadwood.\n","\n","True\n","Player 0 melds [[3C, 4C, 5C], [QS, QD, QC]] with 7 deadwood from [AS, 2S, 3H, AD].\n","\n","Player 1 melds [[7S, 8S, 9S]].\n","\n","Player 1 lays off 2C on [3C, 4C, 5C].\n","\n","Player 1 lays off AC on [3C, 4C, 5C, 2C].\n","\n","Player 1 has 17 deadwood with [4S, AH, 2H, 3D, 7C]\n","\n","Player 0 scores the deadwood difference of 10.\n","\n","Player\tScore\n","0\t24\n","1\t14\n","\n","Player 0 is dealt [KC, 6D, 2S, 7H, 4H, 4C, JD, QH, 3S, QD].\n","\n","Player 1 is dealt [3D, 7S, 3C, 9S, TC, 9C, JC, 9D, 6S, JS].\n","\n","Player 1 starts.\n","\n","The initial face up card is 3H.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 3H.\n","\n","Player 1 discards JS.\n","\n","Player 1 has [[9C, TC, JC], [3H, 3D, 3C], 7S, 9S, 9D, 6S] with 31 deadwood.\n","\n","Update States\n","Draw new card: 0.020867627\n","Pickup from discard: 0.020867627\n","Draw from deck\n","Player 0 draws AC.\n","\n","Update States\n","Current Hand: [KC, 6D, 2S, 7H, 4H, 4C, JD, QH, 3S, QD, AC]\n","Discard QH | D: QH | K: KC | 30\n","MAX:0.0180, 0.0066\n","Discard Action\n","Player 0 discards QH.\n","\n","Player 0 has [KC, 6D, 2S, 7H, 4H, 4C, JD, 3S, QD, AC] with 57 deadwood.\n","\n","Draw from deck\n","Player 1 draws 8D.\n","\n","Player 1 discards 9D.\n","\n","Player 1 has [[9C, TC, JC], [3H, 3D, 3C], 7S, 9S, 6S, 8D] with 30 deadwood.\n","\n","Update States\n","Draw new card: 0.020223418\n","Pickup from discard: 0.020223418\n","Draw from deck\n","Player 0 draws 5C.\n","\n","Update States\n","Current Hand: [KC, 6D, 2S, 7H, 4H, 4C, JD, 3S, QD, AC, 5C]\n","Discard JD | D: JD | K: QD | 42\n","MAX:0.0180, 0.0067\n","Discard Action\n","Player 0 discards JD.\n","\n","Player 0 has [KC, 6D, 2S, 7H, 4H, 4C, 3S, QD, AC, 5C] with 52 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9H.\n","\n","Player 1 discards 9S.\n","\n","Player 1 has [[9C, TC, JC], [3H, 3D, 3C], 7S, 6S, 8D, 9H] with 30 deadwood.\n","\n","Update States\n","Draw new card: 0.02012729\n","Pickup from discard: 0.02012729\n","Draw from deck\n","Player 0 draws 8H.\n","\n","Update States\n","Current Hand: [KC, 6D, 2S, 7H, 4H, 4C, 3S, QD, AC, 5C, 8H]\n","Discard QD | D: QD | K: QD | 43\n","MAX:0.0185, 0.0068\n","Discard Action\n","Player 0 discards QD.\n","\n","Player 0 has [KC, 6D, 2S, 7H, 4H, 4C, 3S, AC, 5C, 8H] with 50 deadwood.\n","\n","Draw from deck\n","Player 1 draws AD.\n","\n","Player 1 discards 9H.\n","\n","Player 1 has [[9C, TC, JC], [3H, 3D, 3C], 7S, 6S, 8D, AD] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.019169567\n","Pickup from discard: 0.019169567\n","Draw from deck\n","Player 0 draws 5S.\n","\n","Update States\n","Current Hand: [KC, 6D, 2S, 7H, 4H, 4C, 3S, AC, 5C, 8H, 5S]\n","Discard 8H | D: 8H | K: KC | 26\n","MAX:0.0181, 0.0067\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [KC, 6D, 2S, 7H, 4H, 4C, 3S, AC, 5C, 5S] with 47 deadwood.\n","\n","Draw from deck\n","Player 1 draws KH.\n","\n","Player 1 discards KH.\n","\n","Player 1 has [[9C, TC, JC], [3H, 3D, 3C], 7S, 6S, 8D, AD] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.021490399\n","Pickup from discard: 0.021490399\n","Draw from deck\n","Player 0 draws QS.\n","\n","Update States\n","Current Hand: [KC, 6D, 2S, 7H, 4H, 4C, 3S, AC, 5C, 5S, QS]\n","Discard QS | D: QS | K: QS | 17\n","MAX:0.0196, 0.0081\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [KC, 6D, 2S, 7H, 4H, 4C, 3S, AC, 5C, 5S] with 47 deadwood.\n","\n","Draw from deck\n","Player 1 draws 8S.\n","\n","Player 1 discards 8D.\n","\n","Player 1 has [[6S, 7S, 8S], [9C, TC, JC], [3H, 3D, 3C], AD] with 1 deadwood.\n","\n","Player 1 melds [[6S, 7S, 8S], [9C, TC, JC], [3H, 3D, 3C]] with 1 deadwood from [AD].\n","\n","Player 0 melds [].\n","\n","Player 0 lays off 3S on [3H, 3D, 3C].\n","\n","Player 0 lays off 5S on [6S, 7S, 8S].\n","\n","Player 0 has 39 deadwood with [2S, 4H, 7H, 6D, AC, 4C, 5C, KC]\n","\n","Player 1 scores the deadwood difference of 38.\n","\n","Player\tScore\n","0\t24\n","1\t52\n","\n","Player 0 is dealt [2S, AS, JC, 2H, 2C, JH, 2D, AH, 8D, 7D].\n","\n","Player 1 is dealt [JS, QH, 8C, 7C, QS, 9H, KS, TD, 7S, 8H].\n","\n","Player 0 starts.\n","\n","The initial face up card is 3C.\n","\n","Update States\n","Draw new card: 0.019256687\n","Pickup from discard: 0.019256694\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 3C.\n","\n","Update States\n","Current Hand: [[2S, 2H, 2D, 2C], AS, JC, JH, AH, 8D, 7D, 3C]\n","Discard JH | D: JH | K: JC | 29\n","MAX:0.0161, 0.0161\n","Knock Action\n","Player 0 discards JC.\n","\n","Player 0 has [[2S, 2H, 2D, 2C], AS, JH, AH, 8D, 7D, 3C] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4H.\n","\n","Player 1 discards TD.\n","\n","Player 1 has [[JS, QS, KS], QH, 8C, 7C, 9H, 7S, 8H, 4H] with 53 deadwood.\n","\n","Update States\n","Draw new card: 0.020453904\n","Pickup from discard: 0.02045239\n","Draw from deck\n","Player 0 draws AC.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [2S, 2H, 2D], AS, JH, AH, 8D, 7D]\n","Discard JH | D: JH | K: JH | 29\n","MAX:0.0160, 0.0160\n","Knock Action\n","Player 0 discards JH.\n","\n","Player 0 has [[AC, 2C, 3C], [2S, 2H, 2D], AS, AH, 8D, 7D] with 17 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6C.\n","\n","Player 1 discards QH.\n","\n","Player 1 has [[JS, QS, KS], [6C, 7C, 8C], 9H, 7S, 8H, 4H] with 28 deadwood.\n","\n","Update States\n","Draw new card: 0.022636557\n","Pickup from discard: 0.022636555\n","Draw from deck\n","Player 0 draws 5H.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [2S, 2H, 2D], AS, AH, 8D, 7D, 5H]\n","Discard 8D | D: 8D | K: 8D | 39\n","MAX:0.0181, 0.0181\n","Discard Action\n","Player 0 discards 8D.\n","\n","Player 0 has [[AC, 2C, 3C], [2S, 2H, 2D], AS, AH, 7D, 5H] with 14 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 8D.\n","\n","Player 1 discards 9H.\n","\n","Player 1 has [[JS, QS, KS], [8H, 8D, 8C], 7C, 7S, 4H, 6C] with 24 deadwood.\n","\n","Update States\n","Draw new card: 0.023518836\n","Pickup from discard: 0.023518836\n","Draw from deck\n","Player 0 draws AD.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [AS, AH, AD], [2S, 2H, 2D], 7D, 5H]\n","Discard 7D | D: 7D | K: 7D | 38\n","MAX:0.0189, 0.0189\n","Knock Action\n","Player 0 discards 7D.\n","\n","Player 0 has [[AC, 2C, 3C], [AS, AH, AD], [2S, 2H, 2D], 5H] with 5 deadwood.\n","\n","True\n","Player 0 melds [[AC, 2C, 3C], [AS, AH, AD], [2S, 2H, 2D]] with 5 deadwood from [5H].\n","\n","Player 1 melds [[JS, QS, KS], [8H, 8D, 8C]].\n","\n","Player 1 has 24 deadwood with [7S, 4H, 6C, 7C]\n","\n","Player 0 scores the deadwood difference of 19.\n","\n","Player\tScore\n","0\t43\n","1\t52\n","\n","Player 0 is dealt [QS, KS, TH, AS, 2D, 4D, KC, 7C, 8D, JD].\n","\n","Player 1 is dealt [JS, KH, 9H, 6D, 6H, 5C, 6S, 3C, TS, 5S].\n","\n","Player 1 starts.\n","\n","The initial face up card is AC.\n","\n","Player 1 declines AC.\n","\n","Update States\n","Draw new card: 0.021557935\n","Pickup from discard: 0.021557935\n","Player 0 declines AC.\n","\n","Draw from deck\n","Player 1 draws QD.\n","\n","Player 1 discards KH.\n","\n","Player 1 has [[6S, 6H, 6D], JS, 9H, 5C, 3C, TS, 5S, QD] with 52 deadwood.\n","\n","Update States\n","Draw new card: 0.02201925\n","Pickup from discard: 0.02201925\n","Draw from deck\n","Player 0 draws 7D.\n","\n","Update States\n","Current Hand: [QS, KS, TH, AS, 2D, 4D, KC, 7C, 8D, JD, 7D]\n","Discard QS | D: QS | K: JD | 17\n","MAX:0.0186, 0.0186\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [KS, TH, AS, 2D, 4D, KC, 7C, 8D, JD, 7D] with 69 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws QS.\n","\n","Player 1 discards QD.\n","\n","Player 1 has [[TS, JS, QS], [6S, 6H, 6D], 9H, 5C, 3C, 5S] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.021424863\n","Pickup from discard: 0.021424863\n","Draw from deck\n","Player 0 draws 9C.\n","\n","Update States\n","Current Hand: [KS, TH, AS, 2D, 4D, KC, 7C, 8D, JD, 7D, 9C]\n","Discard KS | D: KS | K: KS | 18\n","MAX:0.0186, 0.0117\n","Discard Action\n","Player 0 discards KS.\n","\n","Player 0 has [TH, AS, 2D, 4D, KC, 7C, 8D, JD, 7D, 9C] with 68 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws KS.\n","\n","Player 1 discards 9H.\n","\n","Player 1 has [[TS, JS, QS, KS], [6S, 6H, 6D], 5C, 3C, 5S] with 13 deadwood.\n","\n","Update States\n","Draw new card: 0.022311673\n","Pickup from discard: 0.022311673\n","Draw from deck\n","Player 0 draws 3D.\n","\n","Update States\n","Current Hand: [[2D, 3D, 4D], TH, AS, KC, 7C, 8D, JD, 7D, 9C]\n","Discard TH | D: TH | K: JD | 28\n","MAX:0.0198, 0.0140\n","Discard Action\n","Player 0 discards TH.\n","\n","Player 0 has [[2D, 3D, 4D], AS, KC, 7C, 8D, JD, 7D, 9C] with 52 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4C.\n","\n","Player 1 discards 5S.\n","\n","Player 1 has [[TS, JS, QS, KS], [3C, 4C, 5C], [6S, 6H, 6D]] with 0 deadwood.\n","\n","Player 1 goes gin with melds [[TS, JS, QS, KS], [3C, 4C, 5C], [6S, 6H, 6D]].\n","\n","Player 0 melds [[2D, 3D, 4D]].\n","\n","Player 0 has 52 deadwood with [AS, 7D, 8D, JD, 7C, 9C, KC]\n","\n","Player 1 scores the gin bonus of 25 plus opponent deadwood 52 for 77 total points.\n","\n","Player\tScore\n","0\t43\n","1\t129\n","\n","Player 1 wins.\n","\n","Games Won: P0:0, P1:1.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ax0VVg7Ya9ss","executionInfo":{"elapsed":2067,"status":"ok","timestamp":1613421640195,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"cfd0e069-26e4-4112-8826-61387ae5d527"},"source":["numGames = 1\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST2/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Player 0 is dealt [4H, 9H, 5H, 6S, AS, 2H, 7D, KH, QS, 7H].\n","\n","Player 1 is dealt [4S, 6C, 2C, AC, 5C, TS, 6H, TC, 9S, 4D].\n","\n","Player 1 starts.\n","\n","The initial face up card is 2S.\n","\n","Player 1 declines 2S.\n","\n","Update States\n","Draw new card: 0.19178025\n","Pickup from discard: 0.21570157\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 2S.\n","\n","Update States\n","Current Hand: [4H, 9H, 5H, 6S, AS, 2H, 7D, KH, QS, 7H, 2S]\n","Discard QS | D: QS | K: KH | 17\n","MAX:0.2130, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [4H, 9H, 5H, 6S, AS, 2H, 7D, KH, 7H, 2S] with 53 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9C.\n","\n","Player 1 discards TS.\n","\n","Player 1 has [4S, 6C, 2C, AC, 5C, 6H, TC, 9S, 4D, 9C] with 56 deadwood.\n","\n","Update States\n","Draw new card: 0.23447645\n","Pickup from discard: 0.23782119\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TS.\n","\n","Update States\n","Current Hand: [4H, 9H, 5H, 6S, AS, 2H, 7D, KH, 7H, 2S, TS]\n","Discard 9H | D: 9H | K: 9H | 27\n","MAX:0.2475, 0.0000\n","Discard Action\n","Player 0 discards 9H.\n","\n","Player 0 has [4H, 5H, 6S, AS, 2H, 7D, KH, 7H, 2S, TS] with 54 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 9H.\n","\n","Player 1 discards TC.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 6C, 2C, AC, 5C, 6H, 4D] with 28 deadwood.\n","\n","Update States\n","Draw new card: 0.21597537\n","Pickup from discard: 0.22181357\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TC.\n","\n","Update States\n","Current Hand: [4H, 5H, 6S, AS, 2H, 7D, KH, 7H, 2S, TS, TC]\n","Discard TC | D: KH | K: TS | 54\n","MAX:0.1586, 0.0000\n","Discard Action\n","Player 0 discards KH.\n","\n","Player 0 has [4H, 5H, 6S, AS, 2H, 7D, 7H, 2S, TS, TC] with 54 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5S.\n","\n","Player 1 discards 6C.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 6H, 4D, 5S] with 27 deadwood.\n","\n","Update States\n","Draw new card: 0.19635026\n","Pickup from discard: 0.22420259\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 6C.\n","\n","Update States\n","Current Hand: [4H, 5H, 6S, AS, 2H, 7D, 7H, 2S, TS, TC, 6C]\n","Discard TC | D: TC | K: TS | 54\n","MAX:0.2110, 0.0000\n","Discard Action\n","Player 0 discards TC.\n","\n","Player 0 has [4H, 5H, 6S, AS, 2H, 7D, 7H, 2S, TS, 6C] with 50 deadwood.\n","\n","Draw from deck\n","Player 1 draws 3D.\n","\n","Player 1 discards 6H.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 5S, 3D] with 24 deadwood.\n","\n","Update States\n","Draw new card: 0.15591727\n","Pickup from discard: 0.1927547\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 6H.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, TS, 6C]\n","Discard TS | D: TS | K: TS | 15\n","MAX:0.1843, 0.0000\n","Discard Action\n","Player 0 discards TS.\n","\n","Player 0 has [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 6C] with 24 deadwood.\n","\n","Draw from deck\n","Player 1 draws 3H.\n","\n","Player 1 discards 5S.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 3D, 3H] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.22109471\n","Pickup from discard: 0.23564899\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 5S.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 6C, 5S]\n","Discard 6C | D: 6C | K: 6C | 50\n","MAX:0.2920, 0.0000\n","Discard Action\n","Player 0 discards 6C.\n","\n","Player 0 has [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 5S] with 23 deadwood.\n","\n","Draw from deck\n","Player 1 draws JD.\n","\n","Player 1 discards JD.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 3D, 3H] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.24849562\n","Pickup from discard: 0.2374717\n","Draw from deck\n","Player 0 draws 8S.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 5S, 8S]\n","Discard 8S | D: 8S | K: 7D | 13\n","MAX:0.3001, 0.0000\n","Discard Action\n","Player 0 discards 8S.\n","\n","Player 0 has [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 5S] with 23 deadwood.\n","\n","Draw from deck\n","Player 1 draws 8C.\n","\n","Player 1 discards 8C.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 3D, 3H] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.2464057\n","Pickup from discard: 0.119752035\n","Draw from deck\n","Player 0 draws 8D.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 5S, 8D]\n","Discard 7H | D: 7H | K: 8D | 25\n","MAX:0.2349, 0.0000\n","Discard Action\n","Player 0 discards 7H.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 8D] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7C.\n","\n","Player 1 discards 7C.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 3D, 3H] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.2441092\n","Pickup from discard: 0.24571918\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 7C.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 8D, 7C]\n","Discard 7C | D: 8D | K: 8D | 51\n","MAX:0.1282, 0.0000\n","Discard Action\n","Player 0 discards 8D.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 7C] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws AD.\n","\n","Player 1 discards 5C.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.24846092\n","Pickup from discard: 0.25041822\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 5C.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 7C, 5C]\n","Discard 7C | D: 7C | K: 7D | 51\n","MAX:0.2746, 0.0000\n","Discard Action\n","Player 0 discards 7C.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 5C] with 28 deadwood.\n","\n","Draw from deck\n","Player 1 draws KS.\n","\n","Player 1 discards KS.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.26035672\n","Pickup from discard: 0.2549223\n","Draw from deck\n","Player 0 draws JS.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 5C, JS]\n","Discard 7D | D: 7D | K: 7D | 38\n","MAX:0.2605, 0.0000\n","Discard Action\n","Player 0 discards 7D.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, JS] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws JH.\n","\n","Player 1 discards JH.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.2528556\n","Pickup from discard: 0.2601952\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws JH.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, JS, JH]\n","Discard JH | D: JS | K: 5C | 29\n","MAX:0.1543, 0.0000\n","Discard Action\n","Player 0 discards JS.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, JH] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws QC.\n","\n","Player 1 discards QC.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.24311474\n","Pickup from discard: 0.24599224\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws QC.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, JH, QC]\n","Discard JH | D: JH | K: JH | 29\n","MAX:0.2577, 0.0000\n","Discard Action\n","Player 0 discards JH.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, QC] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7S.\n","\n","Player 1 discards 7S.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.25287387\n","Pickup from discard: 0.2456371\n","Draw from deck\n","Player 0 draws 2D.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], [2S, 2H, 2D], 6S, AS, 5S, 5C, QC]\n","Discard QC | D: QC | K: QC | 56\n","MAX:0.2949, 0.0000\n","Discard Action\n","Player 0 discards QC.\n","\n","Player 0 has [[4H, 5H, 6H], [2S, 2H, 2D], 6S, AS, 5S, 5C] with 17 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9D.\n","\n","Player 1 discards 4S.\n","\n","Player 1 has [[9S, 9H, 9D, 9C], 2C, AC, 4D, 3D, 3H, AD] with 14 deadwood.\n","\n","Update States\n","Draw new card: 0.258333\n","Pickup from discard: 0.25973317\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 4S.\n","\n","Update States\n","Current Hand: [[4S, 5S, 6S], [4H, 5H, 6H], [2S, 2H, 2D], AS, 5C]\n","Discard 5C | D: 5C | K: 5C | 49\n","MAX:0.2192, 0.0000\n","Discard Action\n","Player 0 discards 5C.\n","\n","Player 0 has [[4S, 5S, 6S], [4H, 5H, 6H], [2S, 2H, 2D], AS] with 1 deadwood.\n","\n","False\n","Draw from deck\n","Player 1 draws 3S.\n","\n","Player 1 discards 4D.\n","\n","Player 1 has [[3S, 3H, 3D], [9S, 9H, 9D, 9C], 2C, AC, AD] with 4 deadwood.\n","\n","Player 1 melds [[3S, 3H, 3D], [9S, 9H, 9D, 9C]] with 4 deadwood from [AD, AC, 2C].\n","\n","Player 0 melds [[4S, 5S, 6S], [4H, 5H, 6H], [2S, 2H, 2D]].\n","\n","Player 0 has 1 deadwood with [AS]\n","\n","Player 0 undercuts and scores the undercut bonus of 25 plus deadwood difference of 3 for 28 total points.\n","\n","Player\tScore\n","0\t28\n","1\t0\n","\n","Player 0 is dealt [7C, 4D, 8H, 2C, 5D, TD, JS, 2D, 9S, 9D].\n","\n","Player 1 is dealt [5C, 4C, 5S, 7H, KC, 3S, AD, 8D, KD, 6S].\n","\n","Player 0 starts.\n","\n","The initial face up card is 2H.\n","\n","Update States\n","Draw new card: 0.2081592\n","Pickup from discard: 0.2117284\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 2H.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 8H, 5D, TD, JS, 9S, 9D]\n","Discard 8H | D: 8H | K: 8H | 26\n","MAX:0.2621, 0.0000\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, TD, JS, 9S, 9D] with 54 deadwood.\n","\n","Draw from deck\n","Player 1 draws AH.\n","\n","Player 1 discards KC.\n","\n","Player 1 has [5C, 4C, 5S, 7H, 3S, AD, 8D, KD, 6S, AH] with 50 deadwood.\n","\n","Update States\n","Draw new card: 0.23392132\n","Pickup from discard: 0.23656318\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws KC.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 5D, TD, JS, 9S, 9D, KC]\n","Discard TD | D: TD | K: JS | 41\n","MAX:0.1731, 0.0000\n","Discard Action\n","Player 0 discards TD.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, JS, 9S, 9D, KC] with 54 deadwood.\n","\n","Draw from deck\n","Player 1 draws TH.\n","\n","Player 1 discards KD.\n","\n","Player 1 has [5C, 4C, 5S, 7H, 3S, AD, 8D, 6S, AH, TH] with 50 deadwood.\n","\n","Update States\n","Draw new card: 0.21139659\n","Pickup from discard: 0.2096929\n","Draw from deck\n","Player 0 draws KS.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 5D, JS, 9S, 9D, KC, KS]\n","Discard TH | D: 9S | K: 7C | 28\n","MAX:0.1531, 0.0000\n","Discard Action\n","Player 0 discards 9S.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, JS, 9D, KC, KS] with 55 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4H.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [5C, 4C, 5S, 7H, 3S, AD, 8D, 6S, AH, 4H] with 44 deadwood.\n","\n","Update States\n","Draw new card: 0.20769706\n","Pickup from discard: 0.21099262\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TH.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 5D, JS, 9D, KC, KS, TH]\n","Discard TH | D: 9D | K: JS | 28\n","MAX:0.1897, 0.0000\n","Discard Action\n","Player 0 discards 9D.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, JS, KC, KS, TH] with 56 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7S.\n","\n","Player 1 discards 8D.\n","\n","Player 1 has [[5S, 6S, 7S], 5C, 4C, 7H, 3S, AD, AH, 4H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.21857391\n","Pickup from discard: 0.2150963\n","Draw from deck\n","Player 0 draws TC.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 5D, JS, KC, KS, TH, TC]\n","Discard TH | D: TH | K: JS | 28\n","MAX:0.2279, 0.0000\n","Discard Action\n","Player 0 discards TH.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, JS, KC, KS, TC] with 56 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4S.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[5S, 6S, 7S], [4S, 4H, 4C], 5C, 3S, AD, AH] with 10 deadwood.\n","\n","Player 1 melds [[5S, 6S, 7S], [4S, 4H, 4C]] with 10 deadwood from [3S, AH, AD, 5C].\n","\n","Player 0 melds [[2H, 2D, 2C]].\n","\n","Player 0 lays off 4D on [4S, 4H, 4C].\n","\n","Player 0 has 52 deadwood with [JS, KS, 5D, 7C, TC, KC]\n","\n","Player 1 scores the deadwood difference of 42.\n","\n","Player\tScore\n","0\t28\n","1\t42\n","\n","Player 0 is dealt [3C, AH, 7C, 6H, 6D, 2H, 9C, JC, 2C, 4H].\n","\n","Player 1 is dealt [QH, 9H, TD, 2S, 4S, 4D, AD, 9D, 8S, 8H].\n","\n","Player 1 starts.\n","\n","The initial face up card is 3D.\n","\n","Player 1 declines 3D.\n","\n","Update States\n","Draw new card: 0.20878309\n","Pickup from discard: 0.21072072\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 3D.\n","\n","Update States\n","Current Hand: [3C, AH, 7C, 6H, 6D, 2H, 9C, JC, 2C, 4H, 3D]\n","Discard JC | D: JC | K: JC | 55\n","MAX:0.1714, 0.0000\n","Discard Action\n","Player 0 discards JC.\n","\n","Player 0 has [3C, AH, 7C, 6H, 6D, 2H, 9C, 2C, 4H, 3D] with 43 deadwood.\n","\n","Draw from deck\n","Player 1 draws TH.\n","\n","Player 1 discards QH.\n","\n","Player 1 has [[8H, 9H, TH], TD, 2S, 4S, 4D, AD, 9D, 8S] with 38 deadwood.\n","\n","Update States\n","Draw new card: 0.21904057\n","Pickup from discard: 0.21942674\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws QH.\n","\n","Update States\n","Current Hand: [3C, AH, 7C, 6H, 6D, 2H, 9C, 2C, 4H, 3D, QH]\n","Discard QH | D: 7C | K: 7C | 30\n","MAX:0.1710, 0.0000\n","Discard Action\n","Player 0 discards 7C.\n","\n","Player 0 has [3C, AH, 6H, 6D, 2H, 9C, 2C, 4H, 3D, QH] with 46 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7D.\n","\n","Player 1 discards TD.\n","\n","Player 1 has [[8H, 9H, TH], 2S, 4S, 4D, AD, 9D, 8S, 7D] with 35 deadwood.\n","\n","Update States\n","Draw new card: 0.22798033\n","Pickup from discard: 0.22098477\n","Draw from deck\n","Player 0 draws JH.\n","\n","Update States\n","Current Hand: [3C, AH, 6H, 6D, 2H, 9C, 2C, 4H, 3D, QH, JH]\n","Discard 9C | D: 9C | K: JH | 53\n","MAX:0.2343, 0.0000\n","Discard Action\n","Player 0 discards 9C.\n","\n","Player 0 has [3C, AH, 6H, 6D, 2H, 2C, 4H, 3D, QH, JH] with 47 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 9C.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 8S, 8H, 7D] with 34 deadwood.\n","\n","Update States\n","Draw new card: 0.207056\n","Pickup from discard: 0.21552747\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TH.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 6H, 6D, 2H, 2C, 4H, 3D]\n","Discard KD | D: 6H | K: QH | 44\n","MAX:0.1694, 0.0000\n","Discard Action\n","Player 0 discards 6H.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 6D, 2H, 2C, 4H, 3D] with 21 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7H.\n","\n","Player 1 discards 8H.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 8S, 7D, 7H] with 33 deadwood.\n","\n","Update States\n","Draw new card: 0.25151443\n","Pickup from discard: 0.24763985\n","Draw from deck\n","Player 0 draws TC.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 6D, 2H, 2C, 4H, 3D, TC]\n","Discard 6D | D: 6D | K: 6D | 37\n","MAX:0.2653, 0.0000\n","Discard Action\n","Player 0 discards 6D.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, TC] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws TS.\n","\n","Player 1 discards TS.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 8S, 7D, 7H] with 33 deadwood.\n","\n","Update States\n","Draw new card: 0.25013253\n","Pickup from discard: 0.2402273\n","Draw from deck\n","Player 0 draws QS.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, TC, QS]\n","Discard QS | D: QS | K: TC | 17\n","MAX:0.2593, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, TC] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws 8D.\n","\n","Player 1 discards 8S.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 7D, 7H, 8D] with 33 deadwood.\n","\n","Update States\n","Draw new card: 0.24472368\n","Pickup from discard: 0.23512243\n","Draw from deck\n","Player 0 draws AS.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, TC, AS]\n","Discard TC | D: TC | K: TC | 54\n","MAX:0.2046, 0.0000\n","Discard Action\n","Player 0 discards TC.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, AS] with 16 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5S.\n","\n","Player 1 discards 8D.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 7D, 7H, 5S] with 30 deadwood.\n","\n","Update States\n","Draw new card: 0.25990722\n","Pickup from discard: 0.25098306\n","Draw from deck\n","Player 0 draws JS.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, AS, JS]\n","Discard JS | D: JS | K: JS | 16\n","MAX:0.2946, 0.0000\n","Discard Action\n","Player 0 discards JS.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, AS] with 16 deadwood.\n","\n","Draw from deck\n","Player 1 draws KC.\n","\n","Player 1 discards KC.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 7D, 7H, 5S] with 30 deadwood.\n","\n","Update States\n","Draw new card: 0.26878157\n","Pickup from discard: 0.25692803\n","Draw from deck\n","Player 0 draws 3S.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], [3S, 3D, 3C], AH, 2H, 2C, 4H, AS]\n","Discard 4H | D: 4H | K: 4H | 22\n","MAX:0.2727, 0.0000\n","Discard Action\n","Player 0 discards 4H.\n","\n","Player 0 has [[TH, JH, QH], [3S, 3D, 3C], AH, 2H, 2C, AS] with 6 deadwood.\n","\n","False\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 4H.\n","\n","Player 1 discards 7D.\n","\n","Player 1 has [[4S, 4H, 4D], [9H, 9D, 9C], 2S, AD, 7H, 5S] with 15 deadwood.\n","\n","Update States\n","Draw new card: 0.26836678\n","Pickup from discard: 0.255994\n","Draw from deck\n","Player 0 draws KS.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], [3S, 3D, 3C], AH, 2H, 2C, AS, KS]\n","Discard KS | D: KS | K: KS | 18\n","MAX:0.2874, 0.0000\n","Discard Action\n","Player 0 discards KS.\n","\n","Player 0 has [[TH, JH, QH], [3S, 3D, 3C], AH, 2H, 2C, AS] with 6 deadwood.\n","\n","False\n","Draw from deck\n","Player 1 draws QD.\n","\n","Player 1 discards QD.\n","\n","Player 1 has [[4S, 4H, 4D], [9H, 9D, 9C], 2S, AD, 7H, 5S] with 15 deadwood.\n","\n","Update States\n","Draw new card: 0.26869798\n","Pickup from discard: 0.2572033\n","Draw from deck\n","Player 0 draws KH.\n","\n","Update States\n","Current Hand: [[TH, JH, QH, KH], [3S, 3D, 3C], AH, 2H, 2C, AS]\n","Discard TH | D: TH | K: AH | 28\n","MAX:0.2018, 0.0000\n","Discard Action\n","Player 0 discards TH.\n","\n","Player 0 has [[JH, QH, KH], [3S, 3D, 3C], AH, 2H, 2C, AS] with 6 deadwood.\n","\n","False\n","Draw from deck\n","Player 1 draws 9S.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[4S, 4H, 4D], [9S, 9H, 9D, 9C], 2S, AD, 5S] with 8 deadwood.\n","\n","Player 1 melds [[4S, 4H, 4D], [9S, 9H, 9D, 9C]] with 8 deadwood from [2S, 5S, AD].\n","\n","Player 0 melds [[JH, QH, KH], [3S, 3D, 3C]].\n","\n","Player 0 has 6 deadwood with [AS, AH, 2H, 2C]\n","\n","Player 0 undercuts and scores the undercut bonus of 25 plus deadwood difference of 2 for 27 total points.\n","\n","Player\tScore\n","0\t55\n","1\t42\n","\n","Player 0 is dealt [9D, 3D, 5D, 4H, 7C, QC, 8S, 5S, 8D, AD].\n","\n","Player 1 is dealt [2D, 3C, 3S, 9C, AC, KC, 3H, 4S, TC, KS].\n","\n","Player 0 starts.\n","\n","The initial face up card is 8C.\n","\n","Update States\n","Draw new card: 0.21009327\n","Pickup from discard: 0.21122344\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 8C.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 9D, 3D, 5D, 4H, 7C, QC, 5S, AD]\n","Discard TH | D: 9D | K: 7C | 28\n","MAX:0.1536, 0.0000\n","Discard Action\n","Player 0 discards 9D.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, 7C, QC, 5S, AD] with 35 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4C.\n","\n","Player 1 discards KC.\n","\n","Player 1 has [[3S, 3H, 3C], 2D, 9C, AC, 4S, TC, KS, 4C] with 40 deadwood.\n","\n","Update States\n","Draw new card: 0.24916296\n","Pickup from discard: 0.24170417\n","Draw from deck\n","Player 0 draws JH.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, 7C, QC, 5S, AD, JH]\n","Discard 7C | D: 7C | K: 7C | 51\n","MAX:0.2233, 0.0000\n","Discard Action\n","Player 0 discards 7C.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, QC, 5S, AD, JH] with 38 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5C.\n","\n","Player 1 discards TC.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, 9C, AC, 3H, 4S, KS] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.2329164\n","Pickup from discard: 0.2269174\n","Draw from deck\n","Player 0 draws 7D.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, QC, 5S, AD, JH, 7D]\n","Discard 7D | D: 7D | K: JH | 38\n","MAX:0.2097, 0.0000\n","Discard Action\n","Player 0 discards 7D.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, QC, 5S, AD, JH] with 38 deadwood.\n","\n","Draw from deck\n","Player 1 draws JS.\n","\n","Player 1 discards KS.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, 9C, AC, 3H, 4S, JS] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.23402613\n","Pickup from discard: 0.22692306\n","Draw from deck\n","Player 0 draws 6H.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, QC, 5S, AD, JH, 6H]\n","Discard QC | D: QC | K: JH | 56\n","MAX:0.2647, 0.0000\n","Discard Action\n","Player 0 discards QC.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, JH, 6H] with 34 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7S.\n","\n","Player 1 discards JS.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, 9C, AC, 3H, 4S, 7S] with 29 deadwood.\n","\n","Update States\n","Draw new card: 0.25101602\n","Pickup from discard: 0.2427342\n","Draw from deck\n","Player 0 draws 7H.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, JH, 6H, 7H]\n","Discard JH | D: JH | K: JH | 29\n","MAX:0.2772, 0.0000\n","Discard Action\n","Player 0 discards JH.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, 6H, 7H] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9H.\n","\n","Player 1 discards 9C.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 9H] with 29 deadwood.\n","\n","Update States\n","Draw new card: 0.26487398\n","Pickup from discard: 0.25391686\n","Draw from deck\n","Player 0 draws QD.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, 6H, 7H, QD]\n","Discard 7H | D: 7H | K: 7H | 25\n","MAX:0.2722, 0.0000\n","Discard Action\n","Player 0 discards 7H.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, 6H, QD] with 34 deadwood.\n","\n","Draw from deck\n","Player 1 draws TD.\n","\n","Player 1 discards TD.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 9H] with 29 deadwood.\n","\n","Update States\n","Draw new card: 0.25365508\n","Pickup from discard: 0.25192294\n","Draw from deck\n","Player 0 draws 6C.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, 6H, QD, 6C]\n","Discard 8D | D: 8D | K: QD | 39\n","MAX:0.1794, 0.0000\n","Discard Action\n","Player 0 discards 8D.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, 8C, 6H, QD, 6C] with 56 deadwood.\n","\n","Draw from deck\n","Player 1 draws TH.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 9H] with 29 deadwood.\n","\n","Update States\n","Draw new card: 0.26286232\n","Pickup from discard: 0.22595087\n","Draw from deck\n","Player 0 draws 9S.\n","\n","Update States\n","Current Hand: [3D, 5D, 4H, 8S, 5S, AD, 8C, 6H, QD, 6C, 9S]\n","Discard 6H | D: 6H | K: 6C | 24\n","MAX:0.1866, 0.0000\n","Discard Action\n","Player 0 discards 6H.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, 8C, QD, 6C, 9S] with 59 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5H.\n","\n","Player 1 discards 9H.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 5H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.23144723\n","Pickup from discard: 0.13199279\n","Draw from deck\n","Player 0 draws 2C.\n","\n","Update States\n","Current Hand: [3D, 5D, 4H, 8S, 5S, AD, 8C, QD, 6C, 9S, 2C]\n","Discard 8C | D: 8C | K: 9S | 52\n","MAX:0.2325, 0.0000\n","Discard Action\n","Player 0 discards 8C.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 9S, 2C] with 53 deadwood.\n","\n","Draw from deck\n","Player 1 draws QS.\n","\n","Player 1 discards QS.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 5H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.23555\n","Pickup from discard: 0.23801099\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws QS.\n","\n","Update States\n","Current Hand: [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 9S, 2C, QS]\n","Discard QS | D: 9S | K: 9S | 17\n","MAX:0.1890, 0.0000\n","Discard Action\n","Player 0 discards 9S.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 2C, QS] with 54 deadwood.\n","\n","Draw from deck\n","Player 1 draws QH.\n","\n","Player 1 discards QH.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 5H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.22084098\n","Pickup from discard: 0.21852793\n","Draw from deck\n","Player 0 draws 2H.\n","\n","Update States\n","Current Hand: [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 2C, QS, 2H]\n","Discard QS | D: QS | K: 6C | 17\n","MAX:0.2520, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 2C, 2H] with 46 deadwood.\n","\n","Draw from deck\n","Player 1 draws JC.\n","\n","Player 1 discards JC.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 5H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.25052187\n","Pickup from discard: 0.23954792\n","Draw from deck\n","Player 0 draws 4D.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], 4H, 8S, 5S, AD, QD, 6C, 2C, 2H]\n","Discard 8S | D: 8S | K: 6C | 13\n","MAX:0.2436, 0.0000\n","Discard Action\n","Player 0 discards 8S.\n","\n","Player 0 has [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6D.\n","\n","Player 1 discards 7S.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 5H, 6D] with 24 deadwood.\n","\n","Update States\n","Draw new card: 0.2523581\n","Pickup from discard: 0.24225847\n","Draw from deck\n","Player 0 draws JD.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H, JD]\n","Discard JD | D: JD | K: 6C | 42\n","MAX:0.2622, 0.0000\n","Discard Action\n","Player 0 discards JD.\n","\n","Player 0 has [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws KH.\n","\n","Player 1 discards KH.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 5H, 6D] with 24 deadwood.\n","\n","Update States\n","Draw new card: 0.2656818\n","Pickup from discard: 0.2229946\n","Draw from deck\n","Player 0 draws 8H.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H, 8H]\n","Discard 8H | D: 8H | K: QD | 26\n","MAX:0.2536, 0.0000\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws 2S.\n","\n","Player 1 discards 6D.\n","\n","Player 1 has [[2S, 3S, 4S], [3C, 4C, 5C], 2D, AC, 3H, 5H] with 11 deadwood.\n","\n","Update States\n","Draw new card: 0.25027367\n","Pickup from discard: 0.24394903\n","Draw from deck\n","Player 0 draws AH.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H, AH]\n","Discard QD | D: QD | K: QD | 43\n","MAX:0.2779, 0.0000\n","Discard Action\n","Player 0 discards QD.\n","\n","Player 0 has [[3D, 4D, 5D], 4H, 5S, AD, 6C, 2C, 2H, AH] with 21 deadwood.\n","\n","Draw from deck\n","Player 1 draws AS.\n","\n","Player 1 discards 5H.\n","\n","Player 1 has [[AS, 2S, 3S, 4S], [3C, 4C, 5C], 2D, AC, 3H] with 6 deadwood.\n","\n","Player 1 melds [[AS, 2S, 3S, 4S], [3C, 4C, 5C]] with 6 deadwood from [3H, 2D, AC].\n","\n","Player 0 melds [[3D, 4D, 5D]].\n","\n","Player 0 lays off 5S on [AS, 2S, 3S, 4S].\n","\n","Player 0 lays off 2C on [3C, 4C, 5C].\n","\n","Player 0 lays off 6C on [3C, 4C, 5C, 2C].\n","\n","Player 0 has 8 deadwood with [AH, 2H, 4H, AD]\n","\n","Player 1 scores the deadwood difference of 2.\n","\n","Player\tScore\n","0\t55\n","1\t44\n","\n","Player 0 is dealt [AS, 4C, 3S, KH, 6D, 2C, 5H, AH, 2S, QD].\n","\n","Player 1 is dealt [JS, 7H, JD, 2H, AC, 9H, 8S, JH, 5C, 4H].\n","\n","Player 1 starts.\n","\n","The initial face up card is 2D.\n","\n","Player 1 declines 2D.\n","\n","Update States\n","Draw new card: 0.17259115\n","Pickup from discard: 0.20116647\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 2D.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], 4C, KH, 6D, 2C, 5H, AH, QD, 2D]\n","Discard KH | D: KH | K: QD | 31\n","MAX:0.2434, 0.0000\n","Discard Action\n","Player 0 discards KH.\n","\n","Player 0 has [[AS, 2S, 3S], 4C, 6D, 2C, 5H, AH, QD, 2D] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5S.\n","\n","Player 1 discards 9H.\n","\n","Player 1 has [[JS, JH, JD], 7H, 2H, AC, 8S, 5C, 4H, 5S] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.25112793\n","Pickup from discard: 0.26998216\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 9H.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], 4C, 6D, 2C, 5H, AH, QD, 2D, 9H]\n","Discard 9H | D: QD | K: QD | 27\n","MAX:0.0429, 0.0000\n","Discard Action\n","Player 0 discards QD.\n","\n","Player 0 has [[AS, 2S, 3S], 4C, 6D, 2C, 5H, AH, 2D, 9H] with 29 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9C.\n","\n","Player 1 discards 9C.\n","\n","Player 1 has [[JS, JH, JD], 7H, 2H, AC, 8S, 5C, 4H, 5S] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.21277547\n","Pickup from discard: 0.21174602\n","Draw from deck\n","Player 0 draws 3C.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], [2C, 3C, 4C], 6D, 5H, AH, 2D, 9H]\n","Discard TD | D: 9H | K: 9H | 41\n","MAX:0.1992, 0.0000\n","Discard Action\n","Player 0 discards 9H.\n","\n","Player 0 has [[AS, 2S, 3S], [2C, 3C, 4C], 6D, 5H, AH, 2D] with 14 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4S.\n","\n","Player 1 discards 8S.\n","\n","Player 1 has [[JS, JH, JD], 7H, 2H, AC, 5C, 4H, 5S, 4S] with 28 deadwood.\n","\n","Update States\n","Draw new card: 0.25412098\n","Pickup from discard: 0.2541765\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 8S.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], [2C, 3C, 4C], 6D, 5H, AH, 2D, 8S]\n","Discard 6D | D: 6D | K: 5H | 37\n","MAX:0.2513, 0.0000\n","Discard Action\n","Player 0 discards 6D.\n","\n","Player 0 has [[AS, 2S, 3S], [2C, 3C, 4C], 5H, AH, 2D, 8S] with 16 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9D.\n","\n","Player 1 discards 9D.\n","\n","Player 1 has [[JS, JH, JD], 7H, 2H, AC, 5C, 4H, 5S, 4S] with 28 deadwood.\n","\n","Update States\n","Draw new card: 0.25563738\n","Pickup from discard: 0.24818705\n","Draw from deck\n","Player 0 draws AD.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], [2C, 3C, 4C], 5H, AH, 2D, 8S, AD]\n","Discard 5H | D: 5H | K: 8S | 23\n","MAX:0.2912, 0.0000\n","Discard Action\n","Player 0 discards 5H.\n","\n","Player 0 has [[AS, 2S, 3S], [2C, 3C, 4C], AH, 2D, 8S, AD] with 12 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 5H.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[5S, 5H, 5C], [JS, JH, JD], 2H, AC, 4H, 4S] with 11 deadwood.\n","\n","Update States\n","Draw new card: 0.2588717\n","Pickup from discard: 0.25022733\n","Draw from deck\n","Player 0 draws 3D.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], [AD, 2D, 3D], [2C, 3C, 4C], AH, 8S]\n","Discard 8S | D: 8S | K: 2S | 13\n","MAX:0.2447, 0.0000\n","Discard Action\n","Player 0 discards 8S.\n","\n","Player 0 has [[AS, 2S, 3S], [AD, 2D, 3D], [2C, 3C, 4C], AH] with 1 deadwood.\n","\n","False\n","Draw from deck\n","Player 1 draws 4D.\n","\n","Player 1 discards 2H.\n","\n","Player 1 has [[4S, 4H, 4D], [5S, 5H, 5C], [JS, JH, JD], AC] with 1 deadwood.\n","\n","Player 1 melds [[4S, 4H, 4D], [5S, 5H, 5C], [JS, JH, JD]] with 1 deadwood from [AC].\n","\n","Player 0 melds [[AS, 2S, 3S], [AD, 2D, 3D], [2C, 3C, 4C]].\n","\n","Player 0 has 1 deadwood with [AH]\n","\n","Player 0 undercuts and scores the undercut bonus of 25 plus deadwood difference of 0 for 25 total points.\n","\n","Player\tScore\n","0\t80\n","1\t44\n","\n","Player 0 is dealt [TD, 2C, 8H, 3C, JH, 7C, QS, 5S, KH, 6S].\n","\n","Player 1 is dealt [6D, 9D, 5H, QD, 3D, 8C, 4C, 3H, 3S, JD].\n","\n","Player 0 starts.\n","\n","The initial face up card is 8D.\n","\n","Update States\n","Draw new card: 0.19440046\n","Pickup from discard: 0.19278602\n","Player 0 declines 8D.\n","\n","Player 1 declines 8D.\n","\n","Draw from deck\n","Player 0 draws TC.\n","\n","Update States\n","Current Hand: [TD, 2C, 8H, 3C, JH, 7C, QS, 5S, KH, 6S, TC]\n","Discard 8H | D: 8H | K: 7C | 26\n","MAX:0.1976, 0.0000\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [TD, 2C, 3C, JH, 7C, QS, 5S, KH, 6S, TC] with 73 deadwood.\n","\n","Draw from deck\n","Player 1 draws TS.\n","\n","Player 1 discards JD.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 9D, 5H, QD, 8C, 4C, TS] with 52 deadwood.\n","\n","Update States\n","Draw new card: 0.19031166\n","Pickup from discard: 0.18991007\n","Draw from deck\n","Player 0 draws 4H.\n","\n","Update States\n","Current Hand: [TD, 2C, 3C, JH, 7C, QS, 5S, KH, 6S, TC, 4H]\n","Discard QS | D: QS | K: QS | 17\n","MAX:0.1931, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [TD, 2C, 3C, JH, 7C, 5S, KH, 6S, TC, 4H] with 67 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7H.\n","\n","Player 1 discards TS.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 9D, 5H, QD, 8C, 4C, 7H] with 49 deadwood.\n","\n","Update States\n","Draw new card: 0.20649223\n","Pickup from discard: 0.2042986\n","Draw from deck\n","Player 0 draws 7D.\n","\n","Update States\n","Current Hand: [TD, 2C, 3C, JH, 7C, 5S, KH, 6S, TC, 4H, 7D]\n","Discard TC | D: TC | K: 7C | 54\n","MAX:0.1831, 0.0000\n","Discard Action\n","Player 0 discards TC.\n","\n","Player 0 has [TD, 2C, 3C, JH, 7C, 5S, KH, 6S, 4H, 7D] with 64 deadwood.\n","\n","Draw from deck\n","Player 1 draws 2S.\n","\n","Player 1 discards QD.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 9D, 5H, 8C, 4C, 7H, 2S] with 41 deadwood.\n","\n","Update States\n","Draw new card: 0.20974505\n","Pickup from discard: 0.20826152\n","Draw from deck\n","Player 0 draws 7S.\n","\n","Update States\n","Current Hand: [[7S, 7D, 7C], TD, 2C, 3C, JH, 5S, KH, 6S, 4H]\n","Discard KH | D: KH | K: TD | 31\n","MAX:0.2505, 0.0000\n","Discard Action\n","Player 0 discards KH.\n","\n","Player 0 has [[7S, 7D, 7C], TD, 2C, 3C, JH, 5S, 6S, 4H] with 40 deadwood.\n","\n","Draw from deck\n","Player 1 draws 2D.\n","\n","Player 1 discards 9D.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 8C, 4C, 7H, 2S, 2D] with 34 deadwood.\n","\n","Update States\n","Draw new card: 0.23176359\n","Pickup from discard: 0.22537553\n","Draw from deck\n","Player 0 draws AC.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, JH, 5S, 6S, 4H]\n","Discard JH | D: JH | K: 4H | 29\n","MAX:0.2525, 0.0000\n","Discard Action\n","Player 0 discards JH.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9C.\n","\n","Player 1 discards 9C.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 8C, 4C, 7H, 2S, 2D] with 34 deadwood.\n","\n","Update States\n","Draw new card: 0.24725774\n","Pickup from discard: 0.2388761\n","Draw from deck\n","Player 0 draws KS.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H, KS]\n","Discard KS | D: KS | K: TD | 18\n","MAX:0.2818, 0.0000\n","Discard Action\n","Player 0 discards KS.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5C.\n","\n","Player 1 discards 8C.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 4C, 7H, 2S, 2D, 5C] with 31 deadwood.\n","\n","Update States\n","Draw new card: 0.2473259\n","Pickup from discard: 0.23944388\n","Draw from deck\n","Player 0 draws JC.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H, JC]\n","Discard JC | D: JC | K: JC | 55\n","MAX:0.2793, 0.0000\n","Discard Action\n","Player 0 discards JC.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws AD.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 4C, 2S, 2D, 5C, AD] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.24457256\n","Pickup from discard: 0.24440259\n","Draw from deck\n","Player 0 draws 9S.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H, 9S]\n","Discard 9S | D: 9S | K: 9S | 14\n","MAX:0.2568, 0.0000\n","Discard Action\n","Player 0 discards 9S.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws QH.\n","\n","Player 1 discards QH.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 4C, 2S, 2D, 5C, AD] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.24742413\n","Pickup from discard: 0.23970284\n","Draw from deck\n","Player 0 draws AH.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H, AH]\n","Discard TD | D: TD | K: TD | 41\n","MAX:0.2833, 0.0000\n","Discard Action\n","Player 0 discards TD.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], 5S, 6S, 4H, AH] with 16 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6C.\n","\n","Player 1 discards 6D.\n","\n","Player 1 has [[4C, 5C, 6C], [3S, 3H, 3D], 5H, 2S, 2D, AD] with 10 deadwood.\n","\n","Player 1 melds [[4C, 5C, 6C], [3S, 3H, 3D]] with 10 deadwood from [2S, 5H, AD, 2D].\n","\n","Player 0 melds [[AC, 2C, 3C], [7S, 7D, 7C]].\n","\n","Player 0 has 16 deadwood with [5S, 6S, AH, 4H]\n","\n","Player 1 scores the deadwood difference of 6.\n","\n","Player\tScore\n","0\t80\n","1\t50\n","\n","Player 0 is dealt [4S, AS, 5H, JC, 2C, 9H, 9D, 7C, 4H, QS].\n","\n","Player 1 is dealt [AC, KS, 3S, 7S, 4D, JD, 7D, TS, QC, 4C].\n","\n","Player 1 starts.\n","\n","The initial face up card is 3C.\n","\n","Player 1 declines 3C.\n","\n","Update States\n","Draw new card: 0.21048538\n","Pickup from discard: 0.2099461\n","Player 0 declines 3C.\n","\n","Draw from deck\n","Player 1 draws 5S.\n","\n","Player 1 discards QC.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, JD, 7D, TS, 4C, 5S] with 61 deadwood.\n","\n","Update States\n","Draw new card: 0.20814455\n","Pickup from discard: 0.20772186\n","Draw from deck\n","Player 0 draws QH.\n","\n","Update States\n","Current Hand: [4S, AS, 5H, JC, 2C, 9H, 9D, 7C, 4H, QS, QH]\n","Discard JC | D: JC | K: QS | 55\n","MAX:0.2269, 0.0000\n","Discard Action\n","Player 0 discards JC.\n","\n","Player 0 has [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QS, QH] with 61 deadwood.\n","\n","Draw from deck\n","Player 1 draws JH.\n","\n","Player 1 discards JH.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, JD, 7D, TS, 4C, 5S] with 61 deadwood.\n","\n","Update States\n","Draw new card: 0.20161411\n","Pickup from discard: 0.20398493\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws JH.\n","\n","Update States\n","Current Hand: [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QS, QH, JH]\n","Discard QS | D: QS | K: QS | 17\n","MAX:0.2413, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QH, JH] with 61 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5D.\n","\n","Player 1 discards TS.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, JD, 7D, 4C, 5S, 5D] with 56 deadwood.\n","\n","Update States\n","Draw new card: 0.2398133\n","Pickup from discard: 0.23350981\n","Draw from deck\n","Player 0 draws 8D.\n","\n","Update States\n","Current Hand: [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QH, JH, 8D]\n","Discard 8D | D: 8D | K: 7C | 39\n","MAX:0.2250, 0.0000\n","Discard Action\n","Player 0 discards 8D.\n","\n","Player 0 has [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QH, JH] with 61 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6H.\n","\n","Player 1 discards JD.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, 7D, 4C, 5S, 5D, 6H] with 52 deadwood.\n","\n","Update States\n","Draw new card: 0.235021\n","Pickup from discard: 0.23214418\n","Draw from deck\n","Player 0 draws JS.\n","\n","Update States\n","Current Hand: [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QH, JH, JS]\n","Discard 9D | D: 9D | K: JS | 40\n","MAX:0.1749, 0.0000\n","Discard Action\n","Player 0 discards 9D.\n","\n","Player 0 has [4S, AS, 5H, 2C, 9H, 7C, 4H, QH, JH, JS] with 62 deadwood.\n","\n","Draw from deck\n","Player 1 draws TH.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, 7D, 4C, 5S, 5D, 6H] with 52 deadwood.\n","\n","Update States\n","Draw new card: 0.20487773\n","Pickup from discard: 0.21193998\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TH.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 7C, 4H, JS]\n","Discard JS | D: JS | K: 7C | 16\n","MAX:0.2895, 0.0000\n","Discard Action\n","Player 0 discards JS.\n","\n","Player 0 has [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 7C, 4H] with 23 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5C.\n","\n","Player 1 discards KS.\n","\n","Player 1 has [[5S, 5D, 5C], AC, 3S, 7S, 4D, 7D, 4C, 6H] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.26757225\n","Pickup from discard: 0.25636718\n","Draw from deck\n","Player 0 draws 2S.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 7C, 4H, 2S]\n","Discard 7C | D: 7C | K: 7C | 51\n","MAX:0.2671, 0.0000\n","Discard Action\n","Player 0 discards 7C.\n","\n","Player 0 has [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S] with 18 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 7C.\n","\n","Player 1 discards 6H.\n","\n","Player 1 has [[5S, 5D, 5C], [7S, 7D, 7C], AC, 3S, 4D, 4C] with 12 deadwood.\n","\n","Update States\n","Draw new card: 0.25941792\n","Pickup from discard: 0.24880427\n","Draw from deck\n","Player 0 draws KC.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S, KC]\n","Discard KC | D: KC | K: KC | 57\n","MAX:0.2364, 0.0000\n","Discard Action\n","Player 0 discards KC.\n","\n","Player 0 has [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S] with 18 deadwood.\n","\n","Draw from deck\n","Player 1 draws TC.\n","\n","Player 1 discards TC.\n","\n","Player 1 has [[5S, 5D, 5C], [7S, 7D, 7C], AC, 3S, 4D, 4C] with 12 deadwood.\n","\n","Update States\n","Draw new card: 0.25852424\n","Pickup from discard: 0.254448\n","Draw from deck\n","Player 0 draws 9S.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S, 9S]\n","Discard 9S | D: 9S | K: 9S | 14\n","MAX:0.2234, 0.0000\n","Discard Action\n","Player 0 discards 9S.\n","\n","Player 0 has [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S] with 18 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6D.\n","\n","Player 1 discards 6D.\n","\n","Player 1 has [[5S, 5D, 5C], [7S, 7D, 7C], AC, 3S, 4D, 4C] with 12 deadwood.\n","\n","Update States\n","Draw new card: 0.26014832\n","Pickup from discard: 0.2536934\n","Draw from deck\n","Player 0 draws KH.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH, KH], 4S, AS, 5H, 2C, 4H, 2S]\n","Discard 5H | D: 5H | K: 5H | 23\n","MAX:0.2828, 0.0000\n","Discard Action\n","Player 0 discards 5H.\n","\n","Player 0 has [[9H, TH, JH, QH, KH], 4S, AS, 2C, 4H, 2S] with 13 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 5H.\n","\n","Player 1 discards 4D.\n","\n","Player 1 has [[5S, 5H, 5D, 5C], [7S, 7D, 7C], AC, 3S, 4C] with 8 deadwood.\n","\n","Player 1 melds [[5S, 5H, 5D, 5C], [7S, 7D, 7C]] with 8 deadwood from [3S, AC, 4C].\n","\n","Player 0 melds [[9H, TH, JH, QH, KH]].\n","\n","Player 0 has 13 deadwood with [AS, 2S, 4S, 4H, 2C]\n","\n","Player 1 scores the deadwood difference of 5.\n","\n","Player\tScore\n","0\t80\n","1\t55\n","\n","Player 0 is dealt [KD, TS, 5D, 8S, JH, 2H, 9C, 4D, QD, 3D].\n","\n","Player 1 is dealt [5S, 7S, TH, 7H, 4S, 6H, AS, 2D, AH, 9H].\n","\n","Player 0 starts.\n","\n","The initial face up card is KH.\n","\n","Update States\n","Draw new card: 0.210971\n","Pickup from discard: 0.20767614\n","Player 0 declines KH.\n","\n","Player 1 declines KH.\n","\n","Draw from deck\n","Player 0 draws 8H.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], KD, TS, 8S, JH, 2H, 9C, QD, 8H]\n","Discard Pickup | D: KD | K: JH | 3\n","MAX:0.1815, 0.0000\n","Discard Action\n","Player 0 discards KD.\n","\n","Player 0 has [[3D, 4D, 5D], TS, 8S, JH, 2H, 9C, QD, 8H] with 57 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9S.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [5S, 7S, 7H, 4S, 6H, AS, 2D, AH, 9H, 9S] with 51 deadwood.\n","\n","Update States\n","Draw new card: 0.21197264\n","Pickup from discard: 0.2129256\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TH.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], TS, 8S, JH, 2H, 9C, QD, 8H, TH]\n","Discard 9C | D: 9C | K: 9C | 53\n","MAX:0.2377, 0.0000\n","Discard Action\n","Player 0 discards 9C.\n","\n","Player 0 has [[3D, 4D, 5D], TS, 8S, JH, 2H, QD, 8H, TH] with 58 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 9C.\n","\n","Player 1 discards 7S.\n","\n","Player 1 has [[9S, 9H, 9C], 5S, 7H, 4S, 6H, AS, 2D, AH] with 26 deadwood.\n","\n","Update States\n","Draw new card: 0.22360437\n","Pickup from discard: 0.2152475\n","Draw from deck\n","Player 0 draws 7D.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], TS, 8S, JH, 2H, QD, 8H, TH, 7D]\n","Discard 8S | D: 8S | K: TH | 13\n","MAX:0.1410, 0.0000\n","Discard Action\n","Player 0 discards 8S.\n","\n","Player 0 has [[3D, 4D, 5D], TS, JH, 2H, QD, 8H, TH, 7D] with 57 deadwood.\n","\n","Draw from deck\n","Player 1 draws 8C.\n","\n","Player 1 discards 8C.\n","\n","Player 1 has [[9S, 9H, 9C], 5S, 7H, 4S, 6H, AS, 2D, AH] with 26 deadwood.\n","\n","Update States\n","Draw new card: 0.23031096\n","Pickup from discard: 0.2172583\n","Draw from deck\n","Player 0 draws 2S.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], TS, JH, 2H, QD, 8H, TH, 7D, 2S]\n","Discard TH | D: TH | K: QD | 28\n","MAX:0.2036, 0.0000\n","Discard Action\n","Player 0 discards TH.\n","\n","Player 0 has [[3D, 4D, 5D], TS, JH, 2H, QD, 8H, 7D, 2S] with 49 deadwood.\n","\n","Draw from deck\n","Player 1 draws QC.\n","\n","Player 1 discards QC.\n","\n","Player 1 has [[9S, 9H, 9C], 5S, 7H, 4S, 6H, AS, 2D, AH] with 26 deadwood.\n","\n","Update States\n","Draw new card: 0.23176602\n","Pickup from discard: 0.22189823\n","Draw from deck\n","Player 0 draws 5H.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], TS, JH, 2H, QD, 8H, 7D, 2S, 5H]\n","Discard 8H | D: 8H | K: JH | 26\n","MAX:0.2125, 0.0000\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [[3D, 4D, 5D], TS, JH, 2H, QD, 7D, 2S, 5H] with 46 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 8H.\n","\n","Player 1 discards 5S.\n","\n","Player 1 has [[6H, 7H, 8H], [9S, 9H, 9C], 4S, AS, 2D, AH] with 8 deadwood.\n","\n","Player 1 melds [[6H, 7H, 8H], [9S, 9H, 9C]] with 8 deadwood from [AS, 4S, AH, 2D].\n","\n","Player 0 melds [[3D, 4D, 5D]].\n","\n","Player 0 lays off 5H on [6H, 7H, 8H].\n","\n","Player 0 has 41 deadwood with [2S, TS, 2H, JH, 7D, QD]\n","\n","Player 1 scores the deadwood difference of 33.\n","\n","Player\tScore\n","0\t80\n","1\t88\n","\n","Player 0 is dealt [6H, TD, 3D, 9C, AS, 2C, KH, JC, 2H, QH].\n","\n","Player 1 is dealt [QD, 9D, JD, KD, 3S, 6D, TC, 5D, AD, 4H].\n","\n","Player 1 starts.\n","\n","The initial face up card is 8C.\n","\n","Player 1 declines 8C.\n","\n","Update States\n","Draw new card: 0.19998352\n","Pickup from discard: 0.20046969\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 8C.\n","\n","Update States\n","Current Hand: [6H, TD, 3D, 9C, AS, 2C, KH, JC, 2H, QH, 8C]\n","Discard Pickup | D: TD | K: TD | 3\n","MAX:0.1637, 0.0000\n","Discard Action\n","Player 0 discards TD.\n","\n","Player 0 has [6H, 3D, 9C, AS, 2C, KH, JC, 2H, QH, 8C] with 61 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws TD.\n","\n","Player 1 discards TC.\n","\n","Player 1 has [[9D, TD, JD, QD, KD], 3S, 6D, 5D, AD, 4H] with 19 deadwood.\n","\n","Update States\n","Draw new card: 0.21080936\n","Pickup from discard: 0.21001954\n","Draw from deck\n","Player 0 draws 6S.\n","\n","Update States\n","Current Hand: [6H, 3D, 9C, AS, 2C, KH, JC, 2H, QH, 8C, 6S]\n","Discard QH | D: QH | K: JC | 30\n","MAX:0.1923, 0.0000\n","Discard Action\n","Player 0 discards QH.\n","\n","Player 0 has [6H, 3D, 9C, AS, 2C, KH, JC, 2H, 8C, 6S] with 57 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7D.\n","\n","Player 1 discards 4H.\n","\n","Player 1 has [[5D, 6D, 7D], [9D, TD, JD, QD, KD], 3S, AD] with 4 deadwood.\n","\n","Player 1 melds [[5D, 6D, 7D], [9D, TD, JD, QD, KD]] with 4 deadwood from [3S, AD].\n","\n","Player 0 melds [].\n","\n","Player 0 has 57 deadwood with [AS, 6S, 2H, 6H, KH, 3D, 2C, 8C, 9C, JC]\n","\n","Player 1 scores the deadwood difference of 53.\n","\n","Player\tScore\n","0\t80\n","1\t141\n","\n","Player 1 wins.\n","\n","Games Won: P0:0, P1:1.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qN33bkHlsWJh"},"source":["### Debugging"]},{"cell_type":"code","metadata":{"id":"vKQFUWa_pZrw"},"source":["a = GinRummyGame(agent0, agent1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"803xEEVGpcsv"},"source":["a.players"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DfbG3pgtuEy4"},"source":["numGames = 1000\n","agent0 = RandGinRummyPlayer()\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1dDypQcrsTlD"},"source":["### QNet"]},{"cell_type":"code","metadata":{"id":"Nl3wKveu9QIf"},"source":["numGames = 1\n","numGames = 2000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/TEST5/model_posttrain.pth', map_location=device)\n","mlp_layers=[520, 110]\n","# mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Afo_73eKMcpD"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/TEST9/model_posttrain.pth', map_location=device)\n","# mlp_layers=[520, 110]\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iqNHQ87hPdGo"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/TEST10/model_posttrain.pth', map_location=device)\n","# mlp_layers=[520, 110]\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZlMZQcFQiWD"},"source":["numGames = 100\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/TEST9/model_posttrain.pth', map_location=device)\n","# mlp_layers=[520, 110]\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent0.loadModel(qnet)\n","\n","agent1 = MLPGinRummyPlayer()\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/TEST10/model_posttrain.pth', map_location=device)\n","# mlp_layers=[520, 110]\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","agent1.loadModel(qnet)\n","\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NldHrWfOSTiR","executionInfo":{"elapsed":75109,"status":"ok","timestamp":1612766041963,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"14cb3b0b-6dad-4a07-99b8-eca50873c89b"},"source":["numGames = 1000\n","agent0 = MLPGinRummyPlayer()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\n","checkpoint = torch.load('models/dqn/selfplay/TEST2/model_posttrain.pth', map_location=device)\n","# mlp_layers=[520, 110]\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\n","\n","agent0.loadModel(qnet)\n","# print(model_name)\n","agent1 = SimpleGinRummyPlayer()\n","states, actions = [], []\n","# testAgents(agent0,agent1,numGames,verbose=True)\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:2, P1:998.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_TzQ2YoZly8b"},"source":["# Loading Agent Model Testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2wcepCrXrTt","executionInfo":{"elapsed":2776,"status":"ok","timestamp":1610900268153,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"fe734124-ad9b-47ae-fa7f-80c03bd9e707"},"source":["state = 'all'\n","action = 'all'\n","model_name = 'all_states_all_actions'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"cgMMeYPxgxz_"},"source":["state_s = 'apbd'\n","action_a = 'knock'\n","data_pth = '{}/data/{}/{}'.format(pth,state_s,action_a)\n","states = np.load('{}/s_2k.npy'.format(data_pth))\n","actions = np.load('{}/a_2k.npy'.format(data_pth))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UQXiRL0ZmWKs"},"source":["## Agent"]},{"cell_type":"code","metadata":{"id":"_eb_TcqLgm49"},"source":["agent = MLPGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGDoHYG9gri9","executionInfo":{"elapsed":333,"status":"ok","timestamp":1610900272191,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"87e78c01-ac9d-4d93-f651-dfa9aac09d84"},"source":["state_s = 'all'\n","action_a = 'all'\n","agent.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state_s,action_a,model_name), map_location=device))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CfeRVbDygt_m"},"source":["# input = np.expand_dims(states[0],axis=0)\n","# prob = agent.model(torch.from_numpy(input).type(torch.FloatTensor))\n","# action = prob.detach().numpy().reshape(-1)\n","# action[6:58]*np.zeros(52)\n","# # agent.model(np.expand_dims(,axis=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQ-N7W2O1BQg"},"source":["deck = Deck.getShuffle(random.randrange(10 ** 8))\n","hands = []\n","hands.extend([[], []])\n","hands[0] = []\n","hands[1] = []\n","for i in range(2 * GinRummyGame.HAND_SIZE):\n","    hands[i % 2] += [deck.pop()]\n","agent.startGame(0, 0, hands[0]);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IpdrZO2RlqjT","executionInfo":{"elapsed":269,"status":"ok","timestamp":1610900288796,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"a089ab29-b86f-4390-da40-a06f00f18e9b"},"source":["agent.updateStates(states[-1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Update States\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6AC2ZNehjDa","executionInfo":{"elapsed":347,"status":"ok","timestamp":1610901186207,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"2331f861-22b0-4d95-f576-2264e4bcf037"},"source":["c = Deck.strCardMap['AC']\n","agent.willDrawFaceUpCard(c)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Pickup from discard: 5.1510585e-10\n","Draw new card: 8.215045e-09\n","Draw Action\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k2969RH51HyG","executionInfo":{"elapsed":737,"status":"ok","timestamp":1610900291113,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"af5fa872-2ae9-4c7a-e069-f25c1f97e55e"},"source":["agent.playerNum"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103},"id":"ysY_xRb_lx0u","executionInfo":{"elapsed":316,"status":"ok","timestamp":1610900323625,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"ba53b30d-9993-45fa-9a16-44c22cb4783e"},"source":["i = 11\n","agent.updateStates(states[i])\n","agent.reportDraw(0, c)\n","agent.getDiscard()\n","all_classes[np.argmax(actions[i])]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Update States\n","6D 89\n","MAX:0.19825728237628937, 0.7989177107810974\n","Knock Action\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'6D'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6v532Z5EJF1E","executionInfo":{"elapsed":329,"status":"ok","timestamp":1610900429479,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"a4cee751-1e0f-4707-a489-7fda490cbb0e"},"source":["agent.model(torch.from_numpy(np.expand_dims(agent.state, axis=0)).type(torch.FloatTensor).to(device))\n","# state = np.expand_dims(self.state, axis=0)\n","# action = self.model(torch.from_numpy(state).type(torch.FloatTensor))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.5613e-08, 1.5413e-08, 5.1511e-10, 8.2150e-09, 2.9999e-08, 1.2821e-09,\n","         5.5631e-09, 2.5155e-08, 2.7546e-06, 4.5472e-07, 1.0434e-03, 8.9934e-17,\n","         3.4545e-15, 7.6638e-20, 1.2097e-23, 9.0395e-21, 3.3336e-16, 1.2249e-17,\n","         1.4306e-13, 1.5554e-08, 5.1269e-08, 1.0969e-08, 7.8594e-07, 7.9670e-12,\n","         4.4021e-18, 5.8035e-19, 3.2541e-18, 1.2281e-18, 1.5415e-15, 2.9808e-19,\n","         8.6931e-15, 8.5212e-14, 1.4021e-08, 1.0776e-08, 1.0269e-08, 2.9233e-09,\n","         6.7081e-11, 1.9826e-01, 8.6911e-15, 1.6958e-20, 6.8392e-18, 3.8210e-16,\n","         1.5054e-19, 4.5664e-16, 3.2462e-10, 1.5062e-07, 2.1884e-08, 1.1281e-08,\n","         1.1448e-04, 5.9201e-12, 1.1257e-13, 1.4764e-16, 3.0289e-24, 8.3574e-19,\n","         7.6238e-17, 3.5383e-14, 8.8625e-20, 1.4193e-20, 2.3093e-07, 1.5752e-07,\n","         4.3524e-05, 1.8425e-06, 1.4934e-03, 3.1863e-11, 4.4363e-08, 1.9563e-07,\n","         4.9013e-06, 1.5853e-08, 1.0693e-06, 1.3684e-08, 8.0732e-07, 1.6183e-08,\n","         2.2061e-05, 9.4124e-08, 4.5300e-10, 2.2975e-09, 1.6456e-13, 1.1721e-06,\n","         1.2828e-06, 2.7124e-07, 2.2376e-08, 1.5255e-08, 4.0729e-08, 1.1123e-08,\n","         7.2174e-08, 2.9650e-06, 1.6772e-06, 7.7064e-05, 4.1690e-17, 7.9892e-01,\n","         1.0043e-14, 1.5928e-07, 1.2464e-06, 1.6597e-08, 3.0182e-08, 1.3622e-06,\n","         8.1668e-07, 2.5266e-06, 1.7661e-07, 3.7193e-08, 2.2941e-07, 6.6019e-07,\n","         2.0783e-13, 2.1818e-06, 1.7139e-08, 1.1502e-08, 1.9091e-08, 1.4139e-07,\n","         5.2852e-08, 1.9630e-08]], grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"LSGRQrlB8NUn"},"source":["## QNet"]},{"cell_type":"code","metadata":{"id":"Vm47cXB90CI6"},"source":["class EstimatorNetwork(nn.Module):\n","    ''' The function approximation network for Estimator\n","        It is just a series of sigmoid layers. All in/out are torch.tensor\n","        (OLD) It is just a series of tanh layers. All in/out are torch.tensor\n","    '''\n","\n","    def __init__(self, mlp_layers=None, batch_norm=False):\n","        ''' Initialize the Q network\n","        Args:\n","            action_num (int): number of legal actions\n","            state_shape (list): shape of state tensor\n","            mlp_layers (list): output size of each fc layer\n","        '''\n","        super(EstimatorNetwork, self).__init__()\n","\n","        self.action_num = 110\n","        self.state_shape = 260\n","        self.mlp_layers = mlp_layers\n","        self.batch_norm = batch_norm\n","\n","        # build the Q network\n","        layer_dims = [np.prod(self.state_shape)] + self.mlp_layers\n","        fc = [nn.Flatten()]\n","        if batch_norm:\n","            fc.append(nn.BatchNorm1d(layer_dims[0]))\n","        for i in range(len(layer_dims)-1):\n","            fc.append(nn.Linear(layer_dims[i], layer_dims[i+1], bias=True))\n","            fc.append(nn.Sigmoid())\n","        fc.append(nn.Linear(layer_dims[-1], self.action_num, bias=True))\n","        fc.append(nn.Softmax(dim=1))\n","        self.fc_layers = nn.Sequential(*fc)\n","\n","    def forward(self, s):\n","        ''' Predict action values\n","        Args:\n","            s  (Tensor): (batch, state_shape)\n","        '''\n","        return self.fc_layers(s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIudaaMe0X1_"},"source":["state_shape = 260\n","action_num = 110\n","mlp_layers=[520, 520, 110]\n","batch_norm = False\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\n","qnet = qnet.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xo3rbpxH42Gz"},"source":["checkpoint = torch.load('models/dqn/TEST4/model_posttrain.pth', map_location=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgHKA0AZ6jfJ","executionInfo":{"elapsed":270,"status":"ok","timestamp":1611031143413,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"17a0cc15-f99e-4eb5-c8f9-8ad797add92c"},"source":["qnet.load_state_dict(checkpoint['dqn_q_estimator'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRTEjXPl8eQA","executionInfo":{"elapsed":235,"status":"ok","timestamp":1611031394344,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"},"user_tz":300},"outputId":"584a43b2-ff52-4260-d3f1-a2c2caf2361b"},"source":["qnet(torch.from_numpy(np.expand_dims(states[-1], axis=0)).type(torch.FloatTensor).to(device))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[7.2249e-09, 2.2420e-10, 9.7314e-16, 4.7728e-15, 1.2340e-20, 6.8497e-10,\n","         5.7679e-02, 3.3210e-02, 1.1054e-01, 2.0988e-02, 1.7701e-02, 6.7780e-03,\n","         1.2067e-02, 4.0160e-03, 2.8021e-04, 3.1774e-03, 5.9243e-03, 1.0486e-02,\n","         3.3039e-03, 2.7109e-02, 3.3363e-02, 4.7771e-02, 1.8946e-02, 2.7230e-02,\n","         9.2067e-03, 3.6598e-03, 2.2502e-03, 9.3831e-03, 7.2180e-03, 2.3893e-03,\n","         2.6061e-03, 6.0732e-03, 2.8625e-02, 4.8642e-02, 3.8667e-02, 3.7032e-02,\n","         1.3078e-02, 9.2480e-02, 9.3268e-04, 1.0151e-03, 4.8095e-03, 1.0041e-03,\n","         5.6105e-03, 2.7269e-03, 3.4772e-03, 3.9008e-02, 4.8259e-02, 3.4264e-02,\n","         4.3172e-02, 2.0446e-02, 1.8986e-02, 2.4711e-03, 7.2034e-03, 1.0481e-03,\n","         1.0171e-02, 4.2704e-03, 6.3416e-04, 8.6092e-03, 4.0611e-10, 3.4673e-10,\n","         1.6277e-10, 1.9494e-10, 3.1402e-10, 1.9318e-10, 2.3830e-10, 1.1181e-10,\n","         1.1989e-10, 1.7327e-10, 2.8693e-10, 8.1085e-11, 1.4320e-10, 9.0052e-11,\n","         2.9499e-10, 5.1579e-10, 4.1876e-10, 1.9062e-10, 9.0127e-11, 4.0147e-10,\n","         1.6223e-10, 9.0625e-11, 1.6091e-10, 1.4370e-10, 1.7994e-10, 1.3156e-10,\n","         6.4692e-10, 1.4115e-10, 1.7668e-10, 1.5604e-10, 1.7981e-10, 3.0449e-10,\n","         2.3876e-10, 4.4373e-10, 2.7965e-10, 8.9287e-11, 2.3358e-10, 2.2818e-10,\n","         1.5378e-10, 5.6208e-11, 1.0548e-10, 1.5618e-10, 2.6403e-10, 1.7098e-10,\n","         3.5305e-10, 2.2007e-10, 1.3393e-10, 4.6836e-10, 4.1738e-10, 2.1173e-10,\n","         3.6913e-10, 1.5075e-10]], grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":27}]}]}