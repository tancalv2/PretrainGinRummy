{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"testAgents.ipynb","provenance":[],"collapsed_sections":["Ssj566eQMxKZ","qfjPoV0kM1NH","o1K0a747bja2","Bh93Ni3UszBL","u-hik2PLM6C2","11qEEpVcXSun","uzVO9_zLKE8z","xjPYLr9oQ0SF","hBud_g_iQ5mn","t8siavYqRA6-","mK_BCGBJRGVh","chfSSIbcRf1O","yER8W1H6Tmrv","xD_LPqg2Tmr8","yfapetWbXYeK","6RteokMRTmr9","U70Ryjd2aMuG","jRDlFr6BrtD7","qN33bkHlsWJh","1dDypQcrsTlD","_TzQ2YoZly8b","UQXiRL0ZmWKs","LSGRQrlB8NUn"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RubzqOlEW1H2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613418917308,"user_tz":300,"elapsed":43113,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"57d2228b-b287-4092-f700-8e926253f217"},"source":["# Run this cell to mount your Google Drive.\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KPCni-gdFFeE","executionInfo":{"status":"ok","timestamp":1613418921340,"user_tz":300,"elapsed":734,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}}},"source":["pth = '/content/drive/MyDrive/Colab Notebooks/Thesis'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6Hs2guSyLy_","executionInfo":{"status":"ok","timestamp":1613418922338,"user_tz":300,"elapsed":1022,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}}},"source":["all_classes = ['SP0','SP1','Draw','Pickup','DH','GIN',\r\n","               'AS', '2S', '3S', '4S', '5S', '6S', '7S', '8S', '9S', 'TS', 'JS', 'QS', 'KS',\r\n","               'AH', '2H', '3H', '4H', '5H', '6H', '7H', '8H', '9H', 'TH', 'JH', 'QH', 'KH',\r\n","               'AD', '2D', '3D', '4D', '5D', '6D', '7D', '8D', '9D', 'TD', 'JD', 'QD', 'KD',\r\n","               'AC', '2C', '3C', '4C', '5C', '6C', '7C', '8C', '9C', 'TC', 'JC', 'QC', 'KC',\r\n","               'AS', '2S', '3S', '4S', '5S', '6S', '7S', '8S', '9S', 'TS', 'JS', 'QS', 'KS',\r\n","               'AH', '2H', '3H', '4H', '5H', '6H', '7H', '8H', '9H', 'TH', 'JH', 'QH', 'KH',\r\n","               'AD', '2D', '3D', '4D', '5D', '6D', '7D', '8D', '9D', 'TD', 'JD', 'QD', 'KD',\r\n","               'AC', '2C', '3C', '4C', '5C', '6C', '7C', '8C', '9C', 'TC', 'JC', 'QC', 'KC']\r\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ssj566eQMxKZ"},"source":["# Gin Rummy"]},{"cell_type":"markdown","metadata":{"id":"qfjPoV0kM1NH"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"oZZ3FbZfWmdn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613418931514,"user_tz":300,"elapsed":7161,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"faa29c90-61a5-40f4-940f-c4b09d2ad9a4"},"source":["#-------------------------------------------------------------------------------\n","# The following code was originally written by Todd Neller in Java.\n","# It was translated into Python by Anthony Hein.\n","#-------------------------------------------------------------------------------\n","\n","#-------------------------------------------------------------------------------\n","# A class for modeling a game of Gin Rummy\n","# @author Todd W. Neller\n","# @version 1.0\n","#-------------------------------------------------------------------------------\n","\n","#-------------------------------------------------------------------------------\n","# Copyright (C) 2020 Todd Neller\n","#\n","# This program is free software; you can redistribute it and/or\n","# modify it under the terms of the GNU General Public License\n","# as published by the Free Software Foundation; either version 2\n","# of the License, or (at your option) any later version.\n","#\n","# This program is distributed in the hope that it will be useful,\n","# but WITHOUT ANY WARRANTY; without even the implied warranty of\n","# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","# GNU General Public License for more details.\n","#\n","# Information about the GNU General Public License is available online at:\n","#   http://www.gnu.org/licenses/\n","# To receive a copy of the GNU General Public License, write to the Free\n","# Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n","# 02111-1307, USA.\n","#-------------------------------------------------------------------------------\n","\n","import random\n","import time\n","import numpy as np\n","import os\n","import torch\n","\n","%cd /content/drive/My Drive/Colab Notebooks/Thesis/GinRummy\n","\n","from Deck import Deck\n","from GinRummyUtil import GinRummyUtil\n","from SimpleGinRummyPlayer import SimpleGinRummyPlayer\n","\n","%cd /content/drive/My Drive/Colab Notebooks/Thesis/SupervisedLearning\n","\n","from models import *\n","\n","%cd /content/drive/My Drive/Colab Notebooks/Thesis\n","#-------------------------------------------------------------------------------\n","\n","# TRACKING\n","# Plane (5x52)      Feature\n","# 0\t currHand       the cards in current player's hand\n","# 1\t topCard        the top card of the discard pile\n","# 2\t deadCard       the dead cards: cards in discard pile (excluding the top card)\n","# 3\t oppCard        opponent known cards: cards picked up from discard pile, but not discarded\n","# 4\t unknownCard    the unknown cards: cards in stockpile or in opponent hand (but not known)\n","\n","# Action ID         Action\n","# 0\t                score_player_0_action\n","# 1\t                score_player_1_action\n","# 2\t                draw_card_action\n","# 3\t                pick_up_discard_action\n","# 4\t                declare_dead_hand_action\n","# 5\t                gin_action\n","# 6 - 57\t        discard_action\n","# 58 - 109\t        knock_action\n","\n","# Knock_bin\n","# Action ID         Action\n","# 0\t                No Knock\n","# 1\t                Knock\n","\n","def one_hot(cards):\n","    ret = np.zeros(52)\n","    for card in cards:\n","        ret[card.getId()] = 1\n","    return ret\n","\n","def un_one_hot(arr):\n","    rankNames = [\"A\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"T\", \"J\", \"Q\", \"K\"]\n","    suitNames = ['S', 'H', 'D', 'C']\n","    ret = []\n","    for i in range(len(arr)):\n","        if arr[i] != 0:\n","            ret.append(rankNames[i%13] + suitNames[i//13])\n","    return ret\n","\n","#-------------------------------------------------------------------------------"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Thesis/GinRummy\n","/content/drive/My Drive/Colab Notebooks/Thesis/SupervisedLearning\n","/content/drive/My Drive/Colab Notebooks/Thesis\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DVSCfSTL9KAL","executionInfo":{"status":"ok","timestamp":1613418931516,"user_tz":300,"elapsed":7158,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}}},"source":["class EstimatorNetwork(nn.Module):\r\n","    ''' The function approximation network for Estimator\r\n","        It is just a series of sigmoid layers. All in/out are torch.tensor\r\n","        (OLD) It is just a series of tanh layers. All in/out are torch.tensor\r\n","    '''\r\n","\r\n","    def __init__(self, mlp_layers=None, batch_norm=False):\r\n","        ''' Initialize the Q network\r\n","        Args:\r\n","            action_num (int): number of legal actions\r\n","            state_shape (list): shape of state tensor\r\n","            mlp_layers (list): output size of each fc layer\r\n","        '''\r\n","        super(EstimatorNetwork, self).__init__()\r\n","\r\n","        self.action_num = 110\r\n","        self.state_shape = 260\r\n","        self.mlp_layers = mlp_layers\r\n","        self.batch_norm = batch_norm\r\n","\r\n","        # build the Q network\r\n","        layer_dims = [np.prod(self.state_shape)] + self.mlp_layers\r\n","        fc = [nn.Flatten()]\r\n","        if batch_norm:\r\n","            fc.append(nn.BatchNorm1d(layer_dims[0]))\r\n","        for i in range(len(layer_dims)-1):\r\n","            fc.append(nn.Linear(layer_dims[i], layer_dims[i+1], bias=True))\r\n","            fc.append(nn.Sigmoid())\r\n","        fc.append(nn.Linear(layer_dims[-1], self.action_num, bias=True))\r\n","        fc.append(nn.Softmax(dim=1))\r\n","        self.fc_layers = nn.Sequential(*fc)\r\n","\r\n","    def forward(self, s):\r\n","        ''' Predict action values\r\n","        Args:\r\n","            s  (Tensor): (batch, state_shape)\r\n","        '''\r\n","        return self.fc_layers(s)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o1K0a747bja2"},"source":["## MLPGinRummyPlayer"]},{"cell_type":"code","metadata":{"id":"cxJaArOfbmUM","executionInfo":{"status":"ok","timestamp":1613418932919,"user_tz":300,"elapsed":8557,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}}},"source":["# -------------------------------------------------------------------------------\r\n","#  MLPGinRummyPlayer\r\n","#\r\n","#  This estimation will be calculated using a Multilayer Percepton trained on the\r\n","#  SimpleGinRummyPlayer written\r\n","#  by Calvin Tan.\r\n","#\r\n","#  @author Calvin Tan\r\n","#  @version 1.0\r\n","# -------------------------------------------------------------------------------\r\n","\r\n","# -------------------------------------------------------------------------------\r\n","# The following code was originally written by Todd Neller in Java.\r\n","# It was translated into Python by May Jiang.\r\n","# -------------------------------------------------------------------------------\r\n","\r\n","# -------------------------------------------------------------------------------\r\n","# Copyright (C) 2020 Todd Neller\r\n","# This program is free software; you can redistribute it and/or\r\n","# modify it under the terms of the GNU General Public License\r\n","# as published by the Free Software Foundation; either version 2\r\n","# of the License, or (at your option) any later version.\r\n","# This program is distributed in the hope that it will be useful,\r\n","# but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n","# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n","# GNU General Public License for more details.\r\n","# Information about the GNU General Public License is available online at:\r\n","#   http://www.gnu.org/licenses/\r\n","# To receive a copy of the GNU General Public License, write to the Free\r\n","# Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\r\n","# 02111-1307, USA.\r\n","# -------------------------------------------------------------------------------\r\n","\r\n","from typing import List, TypeVar\r\n","from random import randint\r\n","from GinRummyUtil import GinRummyUtil\r\n","from GinRummyPlayer import GinRummyPlayer\r\n","\r\n","# Import MLP Models\r\n","# from SupervisedLearning.models import *\r\n","\r\n","Card = TypeVar('Card')\r\n","\r\n","class MLPGinRummyPlayer(GinRummyPlayer):\r\n","\r\n","    def loadModel(self, model_pt):\r\n","        print('Load Model')\r\n","        self.model = model_pt\r\n","\r\n","    def setVerbose(self, verbose):\r\n","        self.playVerbose = verbose\r\n","\r\n","    def updateStates(self, states):\r\n","        if self.playVerbose:\r\n","            print('Update States')\r\n","        self.state = states\r\n","\r\n","    def knockAction(self) -> bool:\r\n","        return self.knock\r\n","\r\n","    # Inform player of 0-based player number (0/1), starting player number (0/1), and dealt cards\r\n","    def startGame(self, playerNum: int, startingPlayerNum: int, cards: List[Card]) -> None:\r\n","        self.playerNum = playerNum\r\n","        self.startingPlayerNum = startingPlayerNum\r\n","        self.cards = list(cards)\r\n","        self.opponentKnocked = False\r\n","        self.drawDiscardBitstrings = [] # long[], or List[int]\r\n","        self.faceUpCard = None\r\n","        self.faceUpCardBool = False\r\n","        self.drawnCard = None\r\n","        self.state = None\r\n","        self.knock = False\r\n","        self.playVerbose = False\r\n","\r\n","\r\n","\r\n","    # def willDrawFaceUpCard(self, card: Card) -> bool:\r\n","    #     # Return true if card would be a part of a meld, false otherwise.\r\n","    #     self.faceUpCard = card\r\n","    #     newCards = list(self.cards)\r\n","    #     newCards.append(card)\r\n","    #     for meld in GinRummyUtil.cardsToAllMelds(newCards):\r\n","    #         if card in meld:\r\n","    #             return True\r\n","    #     return False\r\n","\r\n","    # Return whether or not player will draw the given face-up card on the draw pile.\r\n","    def willDrawFaceUpCard(self, card: Card) -> bool:\r\n","        self.faceUpCard = card\r\n","        # BPBD, either draw(2)->False or pickup(3)->True\r\n","        state = np.expand_dims(self.state, axis=0)\r\n","        state = torch.from_numpy(state).type(torch.FloatTensor).to(device)\r\n","        action = self.model(state)\r\n","        action = action.detach().numpy().reshape(-1)\r\n","        if self.playVerbose:\r\n","            print('Draw new card:', action[2])\r\n","            print('Pickup from discard:', action[3])\r\n","        if action[3] > action[2]:\r\n","            # print('Pickup Discard Action')\r\n","            self.faceUpCardBool = True\r\n","            return True\r\n","        # print('Draw from Deck Action')\r\n","        self.faceUpCardBool = False\r\n","        return False\r\n","\r\n","\r\n","\r\n","\r\n","    # Report that the given player has drawn a given card and, if known, what the card is.\r\n","    # If the card is unknown because it is drawn from the face-down draw pile, the drawnCard is null.\r\n","    # Note that a player that returns false for willDrawFaceUpCard will learn of their face-down draw from this method.\r\n","    def reportDraw(self, playerNum: int, drawnCard: Card) -> None:\r\n","        # Ignore other player draws.  Add to cards if playerNum is this player.\r\n","        if playerNum == self.playerNum:\r\n","            self.cards.append(drawnCard)\r\n","            self.drawnCard = drawnCard\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","    # def getDiscard(self) -> Card:\r\n","    #     # Discard a random card (not just drawn face up) leaving minimal deadwood points.\r\n","    #     minDeadwood = float('inf')\r\n","    #     candidateCards = []\r\n","    #     for card in self.cards:\r\n","    #         # Cannot draw and discard face up card.\r\n","    #         if card == self.drawnCard and self.drawnCard == self.faceUpCard:\r\n","    #         # if card == self.drawnCard and self.faceUpCard:\r\n","    #             continue\r\n","    #         # Disallow repeat of draw and discard.\r\n","    #         drawDiscard = [self.drawnCard, card]\r\n","    #         if GinRummyUtil.cardsToBitstring(drawDiscard) in self.drawDiscardBitstrings:\r\n","    #             continue\r\n","\r\n","    #         remainingCards = list(self.cards)\r\n","    #         remainingCards.remove(card)\r\n","    #         bestMeldSets = GinRummyUtil.cardsToBestMeldSets(remainingCards)\r\n","    #         deadwood = GinRummyUtil.getDeadwoodPoints3(remainingCards) if len(bestMeldSets) == 0 \\\r\n","    #             else GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], remainingCards)\r\n","    #         if deadwood <= minDeadwood:\r\n","    #             if deadwood < minDeadwood:\r\n","    #                 minDeadwood = deadwood\r\n","    #                 candidateCards.clear()\r\n","    #             candidateCards.append(card)\r\n","    #     # Prevent future repeat of draw, discard pair.\r\n","    #     discard = candidateCards[randint(0, len(candidateCards)-1)]\r\n","    #     drawDiscard = [self.drawnCard, discard]\r\n","    #     self.drawDiscardBitstrings.append(GinRummyUtil.cardsToBitstring(drawDiscard))\r\n","    #     return discard\r\n","\r\n","    # Get the player's discarded card.  If you took the top card from the discard pile,\r\n","    # you must discard a different card.\r\n","    # If this is not a card in the player's possession, the player forfeits the game.\r\n","    # @return the player's chosen card for discarding\r\n","    def getDiscard(self) -> Card:\r\n","        # APBD, either either discard or knock...\r\n","        # determine the allowable actions (which cards can be discarded/knocked on)\r\n","        currHand = np.array(self.state[0:52])\r\n","        # if self.playVerbose:\r\n","        #     print('Current Hand:', un_one_hot(currHand))\r\n","        # disallow discarding PickUp FaceUp/Discarded Card\r\n","        if self.faceUpCardBool:\r\n","        # if self.drawnCard == self.faceUpCard:\r\n","            currHand[self.drawnCard.getId()] = 0\r\n","        \r\n","        state = np.expand_dims(self.state, axis=0)\r\n","        state = torch.from_numpy(state).type(torch.FloatTensor).to(device)\r\n","        action = self.model(state)\r\n","        action = action.detach().numpy().reshape(-1)\r\n","\r\n","        discardMax = max(currHand * action[6:58])\r\n","        knockMax = max(currHand * action[58:110])\r\n","\r\n","        if self.playVerbose:\r\n","            unmeldedCards = self.cards.copy()\r\n","            bestMelds = GinRummyUtil.cardsToBestMeldSets(unmeldedCards)\r\n","            if len(bestMelds) > 0:\r\n","                melds = bestMelds[0]\r\n","                for meld in melds:\r\n","                    for card in meld:\r\n","                        unmeldedCards.remove(card)\r\n","                melds.extend(unmeldedCards)\r\n","            else:\r\n","                melds = unmeldedCards\r\n","            print('Current Hand:', melds)\r\n","            if np.argmax(action) > 58:\r\n","                print('Knock', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(currHand * action[58:])), '|', np.argmax(action))\r\n","            else:\r\n","                print('Discard', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(currHand * action[58:])), '|', np.argmax(action))\r\n","            print('MAX:{:.4f}, {:.4f}'.format(discardMax, knockMax))\r\n","\r\n","        if discardMax > knockMax:\r\n","            if self.playVerbose:\r\n","                print('Discard Action')\r\n","            self.knock = False\r\n","            return Deck.getCard(np.argmax(currHand * action[6:58]))\r\n","        else:\r\n","            if self.playVerbose:\r\n","                print('Knock Action')\r\n","            self.knock = True\r\n","            return Deck.getCard(np.argmax(currHand * action[58:]))\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","    # Report that the given player has discarded a given card.\r\n","    def reportDiscard(self, playerNum: int, discardedCard: Card) -> None:\r\n","        # Ignore other player discards.  Remove from cards if playerNum is this player.\r\n","        if playerNum == self.playerNum:\r\n","            self.cards.remove(discardedCard)\r\n","\r\n","    # At the end of each turn, this method is called and the player that cannot (or will not) end the round will return a null value.\r\n","    # However, the first player to \"knock\" (that is, end the round), and then their opponent, will return an ArrayList of ArrayLists of melded cards.\r\n","    # All other cards are counted as \"deadwood\", unless they can be laid off (added to) the knocking player's melds.\r\n","    # When final melds have been reported for the other player, a player should return their final melds for the round.\r\n","    # @return null if continuing play and opponent hasn't melded, or an ArrayList of ArrayLists of melded cards.\r\n","    def getFinalMelds(self) -> List[List[Card]]:\r\n","        # Check if deadwood of maximal meld is low enough to go out.\r\n","        bestMeldSets = GinRummyUtil.cardsToBestMeldSets(self.cards) # List[List[List[Card]]]\r\n","        if not self.opponentKnocked and (len(bestMeldSets) == 0 or \\\r\n","            GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], self.cards) > \\\r\n","            GinRummyUtil.MAX_DEADWOOD):\r\n","            return None\r\n","        if len(bestMeldSets) == 0:\r\n","            return []\r\n","        return bestMeldSets[randint(0, len(bestMeldSets)-1)]\r\n","\r\n","    # When an player has ended play and formed melds, the melds (and deadwood) are reported to both players.\r\n","    def reportFinalMelds(self, playerNum: int, melds: List[List[Card]]) -> None:\r\n","        # Melds ignored by simple player, but could affect which melds to make for complex player.\r\n","        if playerNum != self.playerNum:\r\n","            self.opponentKnocked = True\r\n","\r\n","    # Report current player scores, indexed by 0-based player number.\r\n","    def reportScores(self, scores: List[int]) -> None:\r\n","        # Ignored by simple player, but could affect strategy of more complex player.\r\n","        return\r\n","\r\n","    # Report layoff actions.\r\n","    def reportLayoff(self, playerNum: int, layoffCard: Card, opponentMeld: List[Card]) -> None:\r\n","        # Ignored by simple player, but could affect strategy of more complex player.\r\n","        return\r\n","\r\n","    # Report the final hands of players.\r\n","    def reportFinalHand(self, playerNum: int, hand: List[Card]) -> None:\r\n","        # Ignored by simple player, but could affect strategy of more complex player.\r\n","        return"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bh93Ni3UszBL"},"source":["## RandGinRummyPlayer"]},{"cell_type":"code","metadata":{"id":"wNu79KMoszBN","executionInfo":{"status":"ok","timestamp":1613418932927,"user_tz":300,"elapsed":8561,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}}},"source":["# -------------------------------------------------------------------------------\r\n","#  RandGinRummyPlayer\r\n","#\r\n","#  This estimation will be calculated using a Multilayer Percepton trained on the\r\n","#  SimpleGinRummyPlayer written\r\n","#  by Calvin Tan.\r\n","#\r\n","#  @author Calvin Tan\r\n","#  @version 1.0\r\n","# -------------------------------------------------------------------------------\r\n","\r\n","# -------------------------------------------------------------------------------\r\n","# The following code was originally written by Todd Neller in Java.\r\n","# It was translated into Python by May Jiang.\r\n","# -------------------------------------------------------------------------------\r\n","\r\n","# -------------------------------------------------------------------------------\r\n","# Copyright (C) 2020 Todd Neller\r\n","# This program is free software; you can redistribute it and/or\r\n","# modify it under the terms of the GNU General Public License\r\n","# as published by the Free Software Foundation; either version 2\r\n","# of the License, or (at your option) any later version.\r\n","# This program is distributed in the hope that it will be useful,\r\n","# but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n","# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n","# GNU General Public License for more details.\r\n","# Information about the GNU General Public License is available online at:\r\n","#   http://www.gnu.org/licenses/\r\n","# To receive a copy of the GNU General Public License, write to the Free\r\n","# Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\r\n","# 02111-1307, USA.\r\n","# -------------------------------------------------------------------------------\r\n","\r\n","from typing import List, TypeVar\r\n","from random import randint\r\n","from GinRummyUtil import GinRummyUtil\r\n","from GinRummyPlayer import GinRummyPlayer\r\n","import random\r\n","\r\n","# Import MLP Models\r\n","# from SupervisedLearning.models import *\r\n","\r\n","Card = TypeVar('Card')\r\n","\r\n","class RandGinRummyPlayer(GinRummyPlayer):\r\n","\r\n","    # Inform player of 0-based player number (0/1), starting player number (0/1), and dealt cards\r\n","    def startGame(self, playerNum: int, startingPlayerNum: int, cards: List[Card]) -> None:\r\n","        self.playerNum = playerNum\r\n","        self.startingPlayerNum = startingPlayerNum\r\n","        self.cards = list(cards)\r\n","        self.opponentKnocked = False\r\n","        self.drawDiscardBitstrings = [] # long[], or List[int]\r\n","        self.faceUpCard = None\r\n","        self.drawnCard = None\r\n","        self.state = None\r\n","\r\n","    def willDrawFaceUpCard(self, card: Card) -> bool:\r\n","        # Return random choice\r\n","        self.faceUpCard = card\r\n","        newCards = list(self.cards)\r\n","        newCards.append(card)\r\n","        choice = random.randint(0, 1)\r\n","        if choice == 0:\r\n","            return True\r\n","        return False\r\n","\r\n","\r\n","    # Report that the given player has drawn a given card and, if known, what the card is.\r\n","    # If the card is unknown because it is drawn from the face-down draw pile, the drawnCard is null.\r\n","    # Note that a player that returns false for willDrawFaceUpCard will learn of their face-down draw from this method.\r\n","    def reportDraw(self, playerNum: int, drawnCard: Card) -> None:\r\n","        # Ignore other player draws.  Add to cards if playerNum is this player.\r\n","        if playerNum == self.playerNum:\r\n","            self.cards.append(drawnCard)\r\n","            self.drawnCard = drawnCard\r\n","\r\n","    # Get the player's discarded card.  If you took the top card from the discard pile,\r\n","    # you must discard a different card.\r\n","    # If this is not a card in the player's possession, the player forfeits the game.\r\n","    # @return the player's chosen card for discarding\r\n","    def getDiscard(self) -> Card:\r\n","\r\n","        choice = random.randint(0, len(self.cards)-1)\r\n","        discCard = self.cards[choice]\r\n","        while discCard == self.faceUpCard:\r\n","            choice = random.randint(0, len(self.cards)-1)\r\n","            discCard = self.cards[choice]\r\n","        return discCard\r\n","\r\n","\r\n","    # Report that the given player has discarded a given card.\r\n","    def reportDiscard(self, playerNum: int, discardedCard: Card) -> None:\r\n","        # Ignore other player discards.  Remove from cards if playerNum is this player.\r\n","        if playerNum == self.playerNum:\r\n","            self.cards.remove(discardedCard)\r\n","\r\n","    # At the end of each turn, this method is called and the player that cannot (or will not) end the round will return a null value.\r\n","    # However, the first player to \"knock\" (that is, end the round), and then their opponent, will return an ArrayList of ArrayLists of melded cards.\r\n","    # All other cards are counted as \"deadwood\", unless they can be laid off (added to) the knocking player's melds.\r\n","    # When final melds have been reported for the other player, a player should return their final melds for the round.\r\n","    # @return null if continuing play and opponent hasn't melded, or an ArrayList of ArrayLists of melded cards.\r\n","    def getFinalMelds(self) -> List[List[Card]]:\r\n","        # Check if deadwood of maximal meld is low enough to go out.\r\n","        bestMeldSets = GinRummyUtil.cardsToBestMeldSets(self.cards) # List[List[List[Card]]]\r\n","        if not self.opponentKnocked and (len(bestMeldSets) == 0 or \\\r\n","            GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], self.cards) > \\\r\n","            GinRummyUtil.MAX_DEADWOOD):\r\n","            return None\r\n","        if len(bestMeldSets) == 0:\r\n","            return []\r\n","        return bestMeldSets[randint(0, len(bestMeldSets)-1)]\r\n","\r\n","    # When an player has ended play and formed melds, the melds (and deadwood) are reported to both players.\r\n","    def reportFinalMelds(self, playerNum: int, melds: List[List[Card]]) -> None:\r\n","        # Melds ignored by simple player, but could affect which melds to make for complex player.\r\n","        if playerNum != self.playerNum:\r\n","            self.opponentKnocked = True\r\n","\r\n","    # Report current player scores, indexed by 0-based player number.\r\n","    def reportScores(self, scores: List[int]) -> None:\r\n","        # Ignored by simple player, but could affect strategy of more complex player.\r\n","        return\r\n","\r\n","    # Report layoff actions.\r\n","    def reportLayoff(self, playerNum: int, layoffCard: Card, opponentMeld: List[Card]) -> None:\r\n","        # Ignored by simple player, but could affect strategy of more complex player.\r\n","        return\r\n","\r\n","    # Report the final hands of players.\r\n","    def reportFinalHand(self, playerNum: int, hand: List[Card]) -> None:\r\n","        # Ignored by simple player, but could affect strategy of more complex player.\r\n","        return"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u-hik2PLM6C2"},"source":["## Game Definition"]},{"cell_type":"code","metadata":{"id":"gDVKIcsgWJwe","executionInfo":{"status":"ok","timestamp":1613418933432,"user_tz":300,"elapsed":9064,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}}},"source":["class GinRummyGame:\n","\n","    # Hand size (before and after turn). After draw and before discard there is one extra card.\n","    HAND_SIZE = 10;\n","\n","    # Whether or not to print information during game play\n","    playVerbose = False;\n","\n","    # Two Gin Rummy players numbered according to their array index.\n","    players = [];\n","\n","    # Set whether or not there is to be printed output during gameplay.\n","    def setPlayVerbose(self, playVerbose):\n","        self.playVerbose = playVerbose\n","    \n","    #-------------------------------- updateState --------------------------------#\n","    # 2020-12-20: Define a method to append states\n","    # 2021-01-16: modified append state to work for either player (0 or 1)\n","    def updateState(self, currentPlayer, discards, oppCard):\n","        currHand = one_hot(self.players[currentPlayer].cards)\n","        topCard = np.zeros(52)\n","        if len(discards) > 0:\n","            topCard[discards[-1].getId()] = 1\n","        deadCard = np.zeros(52)\n","        for d in range(len(discards) - 1):\n","            deadCard[discards[d].getId()] = 1\n","        unknownCard = np.ones(52) - currHand - topCard - deadCard - oppCard\n","        self.states = np.array([currHand, topCard, deadCard, oppCard, unknownCard]).flatten()\n","    #------------------------------------------------------------------------------#\n","\n","    # Create a self with two given players\n","    def __init__(self, player0, player1):\n","        self.players = []\n","        self.players.extend([player0, player1])\n","\n","    # Play a game of Gin Rummy and return the winning player number 0 or 1.\n","    # @return the winning player number 0 or 1\n","\n","    def play(self):\n","        scores = [0, 0]\n","        hands = []\n","        hands.extend([[], []])\n","\n","        startingPlayer = random.randrange(2);\n","\n","        # while game not over\n","        while scores[0] < GinRummyUtil.GOAL_SCORE and scores[1] < GinRummyUtil.GOAL_SCORE:\n","\n","            currentPlayer = startingPlayer\n","            opponent = (1 if currentPlayer == 0 else 0)\n","\n","            # get shuffled deck and deal cards\n","            deck = Deck.getShuffle(random.randrange(10 ** 8))\n","            hands[0] = []\n","            hands[1] = []\n","            for i in range(2 * self.HAND_SIZE):\n","                hands[i % 2] += [deck.pop()]\n","            for i in range(2):\n","                self.players[i].startGame(i, startingPlayer, hands[i]);\n","                if self.playVerbose:\n","                    print(\"Player %d is dealt %s.\\n\" % (i, hands[i]))\n","            if self.playVerbose:\n","                print(\"Player %d starts.\\n\" % (startingPlayer))\n","            discards = []\n","            discards.append(deck.pop())\n","            if self.playVerbose:\n","                print(\"The initial face up card is %s.\\n\" % (discards[len(discards) - 1]))\n","            firstFaceUpCard = discards[len(discards) - 1]\n","            turnsTaken = 0\n","            knockMelds = None\n","\n","            # 11/25 - Initial state, prior to any cards\n","            # 1/16 - Initialize oppCard to be two dimensional to track both players as opponents\n","            oppCard = []\n","            oppCard.extend([np.zeros(52), np.zeros(52)])\n","\n","            for i in range(2):\n","                if isinstance(self.players[i], MLPGinRummyPlayer):\n","                    self.players[i].setVerbose(self.playVerbose)\n","\n","            # while the deck has more than two cards remaining, play round\n","            while len(deck) > 2:\n","#-------------------------------------------------------------- BPBD --------------------------------------------------------------#\n","                drawFaceUp = False\n","                faceUpCard = discards[len(discards) - 1]\n","\n","                # offer draw face-up iff not 3rd turn with first face up card (decline automatically in that case)\n","                if not (turnsTaken == 2 and faceUpCard == firstFaceUpCard):\n","\n","                    #------------------------------------ DRAW ------------------------------------#\n","                    # 2020-12-01  -  Track states BEFORE the player PICKUP BEFORE player DISCARDS (track_bpbd)\n","                    # 2021-01-16  -  Track for both players instead of just player 0\n","                    # Action      -  PickUp from Discard(FaceUp) or Deck (Unknown)\n","                    # State       -  BPBD -> APBD\n","\n","                    self.updateState(currentPlayer,discards,oppCard[currentPlayer])\n","\n","                    #------------------------------------------------------------------------------#\n","\n","                    # 2021-01-16  -  Update player with current states\n","                    if isinstance(self.players[currentPlayer], MLPGinRummyPlayer):\n","                        self.players[currentPlayer].updateStates(self.states)\n","\n","                    # both players declined and 1st player must draw face down\n","                    drawFaceUp = self.players[currentPlayer].willDrawFaceUpCard(faceUpCard)\n","                    \n","                    if self.playVerbose and not drawFaceUp and faceUpCard == firstFaceUpCard and turnsTaken < 2:\n","                        print(\"Player %d declines %s.\\n\" % (currentPlayer, firstFaceUpCard))\n","\n","                if not (not drawFaceUp and turnsTaken < 2 and faceUpCard == firstFaceUpCard):\n","\n","                    # continue with turn if not initial declined option\n","                    if self.playVerbose:\n","                        if drawFaceUp:\n","                            print('drawFaceUp (Pickup discarded card)')\n","                        else:\n","                            print('Draw from deck')\n","                    drawCard = discards.pop() if drawFaceUp else deck.pop()\n","                    for i in range(2):\n","                        to_report = drawCard if i == currentPlayer or drawFaceUp else None\n","                        self.players[i].reportDraw(currentPlayer, to_report)\n","\n","                    if self.playVerbose:\n","                        print(\"Player %d draws %s.\\n\" % (currentPlayer, drawCard))\n","                    hands[currentPlayer].append(drawCard)\n","#-------------------------------------------------------------- APBD --------------------------------------------------------------#\n","                    \n","                    self.updateState(currentPlayer,discards,oppCard[currentPlayer])\n","                    \n","                    # 2021-01-16  -  Update player with current states\n","                    if isinstance(self.players[currentPlayer], MLPGinRummyPlayer):\n","                    # if type(self.players[currentPlayer]) == type(MLPGinRummyPlayer()):\n","                        self.players[currentPlayer].updateStates(self.states)\n","\n","                    discardCard = self.players[currentPlayer].getDiscard()\n","\n","                    # 2021-01-16  -  Track for both players instead of just player 0\n","                    # Track opponent pickup and discard after each discard \n","\n","                    # Set discarded card to 0 (in case discarded card was seen)\n","                    oppCard[1 - currentPlayer][discardCard.getId()] = 0\n","                    if drawFaceUp: # if opponent draws TopCard from discard\n","                        oppCard[1 - currentPlayer][drawCard.getId()] = 1\n","\n","                    if not discardCard in hands[currentPlayer] or discardCard == faceUpCard:\n","                        print(\"Player %d discards %s illegally and forfeits.\\n\" % (currentPlayer, discardCard))\n","                        return opponent;\n","                    hands[currentPlayer].remove(discardCard)\n","                    for i in range(2):\n","                        self.players[i].reportDiscard(currentPlayer, discardCard)                    \n","                    if self.playVerbose:\n","                        print(\"Player %d discards %s.\\n\" % (currentPlayer, discardCard))\n","                    discards.append(discardCard)\n","\n","                    if self.playVerbose:\n","                        unmeldedCards = hands[currentPlayer].copy()\n","                        bestMelds = GinRummyUtil.cardsToBestMeldSets(unmeldedCards)\n","                        if len(bestMelds) == 0:\n","                            print(\"Player %d has %s with %d deadwood.\\n\" % (currentPlayer, unmeldedCards, GinRummyUtil.getDeadwoodPoints3(unmeldedCards)))\n","                        else:\n","                            melds = bestMelds[0]\n","                            for meld in melds:\n","                                for card in meld:\n","                                    unmeldedCards.remove(card)\n","                            melds.extend(unmeldedCards)\n","                            print(\"Player %d has %s with %d deadwood.\\n\" % (currentPlayer, melds, GinRummyUtil.getDeadwoodPoints3(unmeldedCards)))\n","\n","#-------------------------------------------------------------- KNOCK --------------------------------------------------------------#\n","                    # CHECK FOR KNOCK\n","                    knockMelds = self.players[currentPlayer].getFinalMelds()\n","                    if knockMelds != None:\n","                        # print('Current Player:', currentPlayer)\n","                        # print(knockMelds)\n","                        # break\n","                        # 2021-01-16  -  Check if MLPGinRummyPlayer knocks\n","                        if isinstance(self.players[currentPlayer], MLPGinRummyPlayer):\n","                            knock = self.players[currentPlayer].knockAction()\n","                            if self.playVerbose:\n","                                print(knock)\n","                            if knock:\n","                                break\n","                        else:\n","                            break\n","                    \n","                turnsTaken += 1\n","                # currentPlayer = 1 if currentPlayer == 0 else 0\n","                # opponent = 1 if currentPlayer == 0 else 0\n","                if len(deck) > 2:\n","                    currentPlayer = 1 if currentPlayer == 0 else 0\n","                    opponent = 1 if currentPlayer == 0 else 0\n","\n","            # if knockMelds != None and len(deck) > 2:\n","            if knockMelds != None:\n","                # round didn't end due to non-knocking and 2 cards remaining in draw pile\n","                # check legality of knocking meld\n","                handBitstring = GinRummyUtil.cardsToBitstring(hands[currentPlayer])\n","                unmelded = handBitstring\n","                for meld in knockMelds:\n","                    meldBitstring = GinRummyUtil.cardsToBitstring(meld)\n","                    if (not meldBitstring in GinRummyUtil.getAllMeldBitstrings()) or ((meldBitstring & unmelded) != meldBitstring):\n","                        # non-meld or meld not in hand\n","                        # print(len(deck))\n","                        # print(meld)\n","                        # print(knockMelds)\n","                        # print(currentPlayer, hands[currentPlayer])\n","                        # print(1- currentPlayer, hands[1-currentPlayer])\n","                        # print(GinRummyUtil.getDeadwoodPoints1(knockMelds, hands[1-currentPlayer]))\n","                        print(\"Player %d melds %s illegally and forfeits.\\n\" % (currentPlayer, knockMelds))\n","                        return opponent\n","                    unmelded &= ~meldBitstring # remove successfully melded cards from\n","\n","                # compute knocking deadwood\n","                knockingDeadwood = GinRummyUtil.getDeadwoodPoints1(knockMelds, hands[currentPlayer])\n","                if knockingDeadwood > GinRummyUtil.MAX_DEADWOOD:\n","                    print(\"Player %d melds %s with greater than %d deadwood and forfeits.\\n\" % (currentPlayer, knockMelds, knockingDeadwood))\n","                    return opponent\n","\n","                meldsCopy = []\n","                for meld in knockMelds:\n","                    meldsCopy.append(meld.copy())\n","                for i in range(2):\n","                    self.players[i].reportFinalMelds(currentPlayer, meldsCopy)\n","                if self.playVerbose:\n","                    if knockingDeadwood > 0:\n","                        print(\"Player %d melds %s with %d deadwood from %s.\\n\" % (currentPlayer, knockMelds, knockingDeadwood, GinRummyUtil.bitstringToCards(unmelded)))\n","                    else:\n","                        print(\"Player %d goes gin with melds %s.\\n\" % (currentPlayer, knockMelds))\n","\n","                # get opponent meld\n","                opponentMelds = self.players[opponent].getFinalMelds();\n","                meldsCopy = []\n","                for meld in opponentMelds:\n","                    meldsCopy.append(meld.copy())\n","                for i in range(2):\n","                    self.players[i].reportFinalMelds(opponent, meldsCopy)\n","\n","                # check legality of opponent meld\n","                opponentHandBitstring = GinRummyUtil.cardsToBitstring(hands[opponent])\n","                opponentUnmelded = opponentHandBitstring\n","                for meld in opponentMelds:\n","                    meldBitstring = GinRummyUtil.cardsToBitstring(meld)\n","                    if (meldBitstring not in GinRummyUtil.getAllMeldBitstrings()) or ((meldBitstring & opponentUnmelded) != meldBitstring):\n","                        # non-meld or meld not in hand\n","                        print(\"Player %d melds %s illegally and forfeits.\\n\" % (opponent, opponentMelds))\n","                        return currentPlayer\n","                    opponentUnmelded &= ~meldBitstring # remove successfully melded cards from\n","\n","                if self.playVerbose:\n","                    print(\"Player %d melds %s.\\n\" % (opponent, opponentMelds))\n","\n","                # lay off on knocking meld (if not gin)\n","                unmeldedCards = GinRummyUtil.bitstringToCards(opponentUnmelded)\n","                if knockingDeadwood > 0:\n","                    # knocking player didn't go gin\n","                    cardWasLaidOff = False\n","                    while True:\n","                        # attempt to lay each card off\n","                        cardWasLaidOff = False\n","                        layOffCard = None\n","                        layOffMeld = None\n","                        for card in unmeldedCards:\n","                            for meld in knockMelds:\n","                                newMeld = meld.copy()\n","                                newMeld.append(card)\n","                                newMeldBitstring = GinRummyUtil.cardsToBitstring(newMeld)\n","                                if newMeldBitstring in GinRummyUtil.getAllMeldBitstrings():\n","                                    layOffCard = card\n","                                    layOffMeld = meld\n","                                    break\n","                            if layOffCard != None:\n","                                if self.playVerbose:\n","                                    print(\"Player %d lays off %s on %s.\\n\" % (opponent, layOffCard, layOffMeld))\n","                                for i in range(2):\n","                                    self.players[i].reportLayoff(opponent, layOffCard, layOffMeld.copy())\n","                                unmeldedCards.remove(layOffCard)\n","                                layOffMeld.append(layOffCard)\n","                                cardWasLaidOff = True\n","                                break\n","                        if not cardWasLaidOff:\n","                            break\n","\n","                opponentDeadwood = 0\n","                for card in unmeldedCards:\n","                    opponentDeadwood += GinRummyUtil.getDeadwoodPoints2(card)\n","                if self.playVerbose:\n","                    print(\"Player %d has %d deadwood with %s\\n\" % (opponent, opponentDeadwood, unmeldedCards))\n","                # compare deadwood and compute new scores\n","                if knockingDeadwood == 0:\n","                    # gin round win\n","                    scores[currentPlayer] += GinRummyUtil.GIN_BONUS + opponentDeadwood\n","                    if self.playVerbose:\n","                        print(\"Player %d scores the gin bonus of %d plus opponent deadwood %d for %d total points.\\n\" % \\\n","                        (currentPlayer, GinRummyUtil.GIN_BONUS, opponentDeadwood, GinRummyUtil.GIN_BONUS + opponentDeadwood))\n","\n","                elif knockingDeadwood < opponentDeadwood:\n","                    # non-gin round win:\n","                    scores[currentPlayer] += opponentDeadwood - knockingDeadwood;\n","                    if self.playVerbose:\n","                        print(\"Player %d scores the deadwood difference of %d.\\n\" % (currentPlayer, opponentDeadwood - knockingDeadwood))\n","\n","                else:\n","                    # undercut win for opponent\n","                    scores[opponent] += GinRummyUtil.UNDERCUT_BONUS + knockingDeadwood - opponentDeadwood;\n","                    if self.playVerbose:\n","                        print(\"Player %d undercuts and scores the undercut bonus of %d plus deadwood difference of %d for %d total points.\\n\" % \\\n","                        (opponent, GinRummyUtil.UNDERCUT_BONUS, knockingDeadwood - opponentDeadwood, GinRummyUtil.UNDERCUT_BONUS + knockingDeadwood - opponentDeadwood))\n","\n","                startingPlayer = 1 if startingPlayer == 0 else 0 # starting player alternates\n","\n","            # If the round ends due to a two card draw pile with no knocking, the round is cancelled.\n","            else:\n","                if self.playVerbose:\n","                    print(\"The draw pile was reduced to two cards without knocking, so the hand is cancelled.\")\n","\n","            # report final hands\n","            for i in range(2):\n","                for j in range(2):\n","                    self.players[i].reportFinalHand(j, hands[j].copy())\n","\n","            # score reporting\n","            if self.playVerbose:\n","                print(\"Player\\tScore\\n0\\t%d\\n1\\t%d\\n\" % (scores[0], scores[1]))\n","            for i in range(2):\n","                self.players[i].reportScores(scores.copy())\n","\n","        if self.playVerbose:\n","            print(\"Player %s wins.\\n\" % (0 if scores[0] > scores[1] else 1))\n","        return 0 if scores[0] >= GinRummyUtil.GOAL_SCORE else 1"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JIhyFRnjM_b-"},"source":["# Test Agents"]},{"cell_type":"markdown","metadata":{"id":"11qEEpVcXSun"},"source":["## Shared"]},{"cell_type":"code","metadata":{"id":"faqGzLQVWQZD","executionInfo":{"status":"ok","timestamp":1613418933436,"user_tz":300,"elapsed":4540,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}}},"source":["def testAgents(agent0,agent1,numGames,verbose):\n","    numP1Wins = 0\n","    game = GinRummyGame(agent0, agent1)\n","    # Multiple non-verbose games\n","    game.setPlayVerbose(verbose)\n","    for i in range(2):\n","        if isinstance(game.players[i], MLPGinRummyPlayer):\n","            print(game.players[i].model)\n","    for i in range(numGames):\n","        if i % 100 == 0:\n","            print(\"Game ... \", i)\n","        numP1Wins += game.play()\n","    print(\"Games Won: P0:%d, P1:%d.\\n\" % (numGames - numP1Wins, numP1Wins))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgmlCQKmVfj3","executionInfo":{"status":"ok","timestamp":1613418933437,"user_tz":300,"elapsed":4536,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}}},"source":["state = 'all'\r\n","action = 'all'"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzVO9_zLKE8z"},"source":["## test games"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXfISEHlSjHl","executionInfo":{"status":"ok","timestamp":1610935773593,"user_tz":300,"elapsed":192383,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"0030459e-fccc-41f4-8a2f-fbfae3341917"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device))\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:346, P1:1654.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9nuUfxzRh0f","executionInfo":{"status":"ok","timestamp":1610936301910,"user_tz":300,"elapsed":114855,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"092ec307-1c9c-40d8-85df-64f4ee0da7cf"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device))\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:267, P1:733.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzNXqvn5SbcZ","executionInfo":{"status":"ok","timestamp":1610936566487,"user_tz":300,"elapsed":229505,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"085a3077-5ec9-4363-8604-0f9ddfc1f15c"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device))\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:513, P1:1487.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwX-ofCLUT54","executionInfo":{"status":"ok","timestamp":1610937057528,"user_tz":300,"elapsed":228612,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"5733706c-1ea2-43a2-e5e7-f0418acd0c23"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device))\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:526, P1:1474.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFgrPqXZVPsg","executionInfo":{"status":"ok","timestamp":1610937341300,"user_tz":300,"elapsed":191032,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"ef1baa71-6c4a-48e9-aed8-f40340f31b71"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device))\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:358, P1:1642.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R9k-kfkiWVbH","executionInfo":{"status":"ok","timestamp":1610938395401,"user_tz":300,"elapsed":221679,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"3135dd4e-9248-4038-b9c2-2307c34ae8b0"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device))\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:542, P1:1458.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQoVb8WSaZ63","executionInfo":{"status":"ok","timestamp":1610938730892,"user_tz":300,"elapsed":223798,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"81899ebe-7617-47d2-fac1-fd4939f52250"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device))\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:535, P1:1465.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1EftJkGEE1dK","executionInfo":{"status":"ok","timestamp":1610936186565,"user_tz":300,"elapsed":399,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"80d92c31-ad14-430e-d43b-4b1ce9113e68"},"source":["numGames = 1\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device))\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Game ...  0\n","Games Won: P0:1, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kvykr4ZNvJZo"},"source":["## MLP Models vs. RandomAgent"]},{"cell_type":"markdown","metadata":{"id":"xjPYLr9oQ0SF"},"source":["### No DQN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBXnwRS8vJZs","executionInfo":{"status":"ok","timestamp":1611078170086,"user_tz":300,"elapsed":76139,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"36688875-ddbe-40b3-f551-01beea8b28b0"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","print(model_name)\r\n","agent1 = RandGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:2000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YapcvAtcvJZt","executionInfo":{"status":"ok","timestamp":1611078236140,"user_tz":300,"elapsed":65497,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"de2824f2-969f-4fc9-bf4a-43cc4fd6a3b3"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","print(model_name)\r\n","agent1 = RandGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_MLP_base_extra_knock_data_40K\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:2000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgdEDtNVvJZu","executionInfo":{"status":"ok","timestamp":1611078297494,"user_tz":300,"elapsed":126837,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"4634d00e-2e54-45bc-b105-d655d1481d17"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","print(model_name)\r\n","agent1 = RandGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_2hl_extra_knock_data_40K\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:2000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1ANIs_Lqlpw","executionInfo":{"status":"ok","timestamp":1611462833850,"user_tz":300,"elapsed":66836,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"6d836a0f-aa12-45b4-dd81-fbe630a2a328"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_80K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","print(model_name)\r\n","agent1 = RandGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_2hl_extra_knock_data_80K\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:2000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hBud_g_iQ5mn"},"source":["### DQN - Random Agent"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHfKDylOwDNM","executionInfo":{"status":"ok","timestamp":1611079422546,"user_tz":300,"elapsed":1096908,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"3c5a9883-eb89-4aff-81f6-54406153909c"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/TEST5/model_posttrain.pth', map_location=device)\r\n","mlp_layers=[520, 110]\r\n","# mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = RandGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=110, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=110, out_features=110, bias=True)\n","    (6): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:1996, P1:4.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t8siavYqRA6-"},"source":["### DQN - Selfplay"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SNnjtXbQsWr","executionInfo":{"status":"ok","timestamp":1612764809037,"user_tz":300,"elapsed":192219,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"792b4a9c-56f0-4ef5-9eea-3335a2eb1256"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/selfplay/TEST1/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = RandGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mK_BCGBJRGVh"},"source":["### DQN - SGRAgent"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5P7xKWLRJG4","executionInfo":{"status":"ok","timestamp":1613419268260,"user_tz":300,"elapsed":208714,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"43251525-30d3-40f6-f26a-bcb7f51a0f63"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST2/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = RandGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1000, P1:0.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zLTh_vClL43-"},"source":["## MLP Models vs. SimpleGinRummyAgent"]},{"cell_type":"markdown","metadata":{"id":"chfSSIbcRf1O"},"source":["### No DQN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0uRlIiYTPP6Y","executionInfo":{"status":"ok","timestamp":1611463310192,"user_tz":300,"elapsed":93797,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"cd10de95-55c6-43f1-bca4-f968bf949fbe"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:130, P1:870.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdoXXbBfTs9j","executionInfo":{"status":"ok","timestamp":1611463403416,"user_tz":300,"elapsed":187010,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"76dcbfe4-92f4-428e-8127-a453b8e8e9ac"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_MLP_base_extra_knock_data_40K\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:197, P1:803.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aL_OZ4BdHoe7","executionInfo":{"status":"ok","timestamp":1611463511694,"user_tz":300,"elapsed":295280,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"b6a57274-4a04-4629-b1ef-e4b1833bff85"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_2hl_extra_knock_data_40K\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:246, P1:754.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wICCyA6kqqPd","executionInfo":{"status":"ok","timestamp":1611463619397,"user_tz":300,"elapsed":402973,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"cb72a737-b1b2-4cc9-ca59-5e3b1d306fe6"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_80K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","all_states_all_actions_2hl_extra_knock_data_80K\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:273, P1:727.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yER8W1H6Tmrv"},"source":["### DQN - Random Agent (80K PT Model + Hardcoded Top layer weights)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kio3W9IwTmr7","executionInfo":{"status":"ok","timestamp":1613419981130,"user_tz":300,"elapsed":86846,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"19119b6a-6d10-4d62-de78-6e2aec7af4ad"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/TEST9/model_posttrain.pth', map_location=device)\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xD_LPqg2Tmr8"},"source":["### DQN - (Pure) Selfplay"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suScDBUITmr8","executionInfo":{"status":"ok","timestamp":1613420501932,"user_tz":300,"elapsed":86605,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"c9afdc0a-a4ce-48a1-8efd-8843e417b0db"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/selfplay/TEST2/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:3, P1:997.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yfapetWbXYeK"},"source":["### DQN - Selfplay after Random"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cG1L57fYjmp","executionInfo":{"status":"ok","timestamp":1613421066221,"user_tz":300,"elapsed":96705,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"c6414bff-e557-4c8b-aa5b-36d28ec353c4"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","checkpoint = torch.load('models/dqn/selfplay/TEST3/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:11, P1:989.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtTCq2R7XeUt","executionInfo":{"status":"ok","timestamp":1613421304107,"user_tz":300,"elapsed":78171,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"102e12c6-5cab-4b06-dd44-0c20ceee8bba"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","checkpoint = torch.load('models/dqn/selfplay/TEST4/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:1, P1:999.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6RteokMRTmr9"},"source":["### DQN - SGRAgent"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l593PSP2Tmr9","executionInfo":{"status":"ok","timestamp":1613421633828,"user_tz":300,"elapsed":92779,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"20db9704-8c0e-4aa9-9212-f0f6e64ff10d"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST2/model_posttrain.pth', map_location=device)\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:6, P1:994.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ek7y1eUesdB_"},"source":["### DQN - Selfplay after SGRAgent"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uE8qd2r-sdCE","executionInfo":{"status":"ok","timestamp":1613426440823,"user_tz":300,"elapsed":105633,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"d0cf57b4-362a-4dfd-8e33-726123f90bf9"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","checkpoint = torch.load('models/dqn/selfplay/TEST8/model_posttrain.pth', map_location=device)\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:22, P1:978.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U70Ryjd2aMuG"},"source":["## MLP Model vs. MLP Model"]},{"cell_type":"code","metadata":{"id":"2uj-HB_kaMuT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611075525720,"user_tz":300,"elapsed":290428,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"8bb26511-56d6-49e4-a14b-c5217d7e156d"},"source":["numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","# print(model_name)\r\n","agent1 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent1.loadModel(model)\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Game ...  1000\n","Game ...  1100\n","Game ...  1200\n","Game ...  1300\n","Game ...  1400\n","Game ...  1500\n","Game ...  1600\n","Game ...  1700\n","Game ...  1800\n","Game ...  1900\n","Games Won: P0:630, P1:1370.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGpzMSwEoSz3","executionInfo":{"status":"ok","timestamp":1611077173263,"user_tz":300,"elapsed":27154,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"df966f19-8edf-49ae-970b-1b5e641bbbcc"},"source":["numGames = 200\r\n","agent0 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_MLP_base_extra_knock_data_40K'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent0.loadModel(model)\r\n","# print(model_name)\r\n","agent1 = MLPGinRummyPlayer()\r\n","model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","model = torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)\r\n","agent1.loadModel(model)\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","Load Model\n","MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","MLP_2HL(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=520, bias=True)\n","  (l3): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")\n","Game ...  0\n","Game ...  100\n","Games Won: P0:80, P1:120.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jRDlFr6BrtD7"},"source":["## Test"]},{"cell_type":"markdown","metadata":{"id":"hm0ghfYvVKjZ"},"source":["### Single Game Verbose"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ax0VVg7Ya9ss","executionInfo":{"status":"ok","timestamp":1613421640195,"user_tz":300,"elapsed":2067,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"cfd0e069-26e4-4112-8826-61387ae5d527"},"source":["numGames = 1\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","checkpoint = torch.load('models/dqn/SGRAgent/TEST2/model_posttrain.pth', map_location=device)\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=True)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Player 0 is dealt [4H, 9H, 5H, 6S, AS, 2H, 7D, KH, QS, 7H].\n","\n","Player 1 is dealt [4S, 6C, 2C, AC, 5C, TS, 6H, TC, 9S, 4D].\n","\n","Player 1 starts.\n","\n","The initial face up card is 2S.\n","\n","Player 1 declines 2S.\n","\n","Update States\n","Draw new card: 0.19178025\n","Pickup from discard: 0.21570157\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 2S.\n","\n","Update States\n","Current Hand: [4H, 9H, 5H, 6S, AS, 2H, 7D, KH, QS, 7H, 2S]\n","Discard QS | D: QS | K: KH | 17\n","MAX:0.2130, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [4H, 9H, 5H, 6S, AS, 2H, 7D, KH, 7H, 2S] with 53 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9C.\n","\n","Player 1 discards TS.\n","\n","Player 1 has [4S, 6C, 2C, AC, 5C, 6H, TC, 9S, 4D, 9C] with 56 deadwood.\n","\n","Update States\n","Draw new card: 0.23447645\n","Pickup from discard: 0.23782119\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TS.\n","\n","Update States\n","Current Hand: [4H, 9H, 5H, 6S, AS, 2H, 7D, KH, 7H, 2S, TS]\n","Discard 9H | D: 9H | K: 9H | 27\n","MAX:0.2475, 0.0000\n","Discard Action\n","Player 0 discards 9H.\n","\n","Player 0 has [4H, 5H, 6S, AS, 2H, 7D, KH, 7H, 2S, TS] with 54 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 9H.\n","\n","Player 1 discards TC.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 6C, 2C, AC, 5C, 6H, 4D] with 28 deadwood.\n","\n","Update States\n","Draw new card: 0.21597537\n","Pickup from discard: 0.22181357\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TC.\n","\n","Update States\n","Current Hand: [4H, 5H, 6S, AS, 2H, 7D, KH, 7H, 2S, TS, TC]\n","Discard TC | D: KH | K: TS | 54\n","MAX:0.1586, 0.0000\n","Discard Action\n","Player 0 discards KH.\n","\n","Player 0 has [4H, 5H, 6S, AS, 2H, 7D, 7H, 2S, TS, TC] with 54 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5S.\n","\n","Player 1 discards 6C.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 6H, 4D, 5S] with 27 deadwood.\n","\n","Update States\n","Draw new card: 0.19635026\n","Pickup from discard: 0.22420259\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 6C.\n","\n","Update States\n","Current Hand: [4H, 5H, 6S, AS, 2H, 7D, 7H, 2S, TS, TC, 6C]\n","Discard TC | D: TC | K: TS | 54\n","MAX:0.2110, 0.0000\n","Discard Action\n","Player 0 discards TC.\n","\n","Player 0 has [4H, 5H, 6S, AS, 2H, 7D, 7H, 2S, TS, 6C] with 50 deadwood.\n","\n","Draw from deck\n","Player 1 draws 3D.\n","\n","Player 1 discards 6H.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 5S, 3D] with 24 deadwood.\n","\n","Update States\n","Draw new card: 0.15591727\n","Pickup from discard: 0.1927547\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 6H.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, TS, 6C]\n","Discard TS | D: TS | K: TS | 15\n","MAX:0.1843, 0.0000\n","Discard Action\n","Player 0 discards TS.\n","\n","Player 0 has [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 6C] with 24 deadwood.\n","\n","Draw from deck\n","Player 1 draws 3H.\n","\n","Player 1 discards 5S.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 3D, 3H] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.22109471\n","Pickup from discard: 0.23564899\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 5S.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 6C, 5S]\n","Discard 6C | D: 6C | K: 6C | 50\n","MAX:0.2920, 0.0000\n","Discard Action\n","Player 0 discards 6C.\n","\n","Player 0 has [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 5S] with 23 deadwood.\n","\n","Draw from deck\n","Player 1 draws JD.\n","\n","Player 1 discards JD.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 3D, 3H] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.24849562\n","Pickup from discard: 0.2374717\n","Draw from deck\n","Player 0 draws 8S.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 5S, 8S]\n","Discard 8S | D: 8S | K: 7D | 13\n","MAX:0.3001, 0.0000\n","Discard Action\n","Player 0 discards 8S.\n","\n","Player 0 has [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 5S] with 23 deadwood.\n","\n","Draw from deck\n","Player 1 draws 8C.\n","\n","Player 1 discards 8C.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 3D, 3H] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.2464057\n","Pickup from discard: 0.119752035\n","Draw from deck\n","Player 0 draws 8D.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H, 7H], 6S, AS, 2H, 7D, 2S, 5S, 8D]\n","Discard 7H | D: 7H | K: 8D | 25\n","MAX:0.2349, 0.0000\n","Discard Action\n","Player 0 discards 7H.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 8D] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7C.\n","\n","Player 1 discards 7C.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 5C, 4D, 3D, 3H] with 22 deadwood.\n","\n","Update States\n","Draw new card: 0.2441092\n","Pickup from discard: 0.24571918\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 7C.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 8D, 7C]\n","Discard 7C | D: 8D | K: 8D | 51\n","MAX:0.1282, 0.0000\n","Discard Action\n","Player 0 discards 8D.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 7C] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws AD.\n","\n","Player 1 discards 5C.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.24846092\n","Pickup from discard: 0.25041822\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 5C.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 7C, 5C]\n","Discard 7C | D: 7C | K: 7D | 51\n","MAX:0.2746, 0.0000\n","Discard Action\n","Player 0 discards 7C.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 5C] with 28 deadwood.\n","\n","Draw from deck\n","Player 1 draws KS.\n","\n","Player 1 discards KS.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.26035672\n","Pickup from discard: 0.2549223\n","Draw from deck\n","Player 0 draws JS.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 7D, 2S, 5S, 5C, JS]\n","Discard 7D | D: 7D | K: 7D | 38\n","MAX:0.2605, 0.0000\n","Discard Action\n","Player 0 discards 7D.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, JS] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws JH.\n","\n","Player 1 discards JH.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.2528556\n","Pickup from discard: 0.2601952\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws JH.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, JS, JH]\n","Discard JH | D: JS | K: 5C | 29\n","MAX:0.1543, 0.0000\n","Discard Action\n","Player 0 discards JS.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, JH] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws QC.\n","\n","Player 1 discards QC.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.24311474\n","Pickup from discard: 0.24599224\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws QC.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, JH, QC]\n","Discard JH | D: JH | K: JH | 29\n","MAX:0.2577, 0.0000\n","Discard Action\n","Player 0 discards JH.\n","\n","Player 0 has [[4H, 5H, 6H], 6S, AS, 2H, 2S, 5S, 5C, QC] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7S.\n","\n","Player 1 discards 7S.\n","\n","Player 1 has [[9S, 9H, 9C], 4S, 2C, AC, 4D, 3D, 3H, AD] with 18 deadwood.\n","\n","Update States\n","Draw new card: 0.25287387\n","Pickup from discard: 0.2456371\n","Draw from deck\n","Player 0 draws 2D.\n","\n","Update States\n","Current Hand: [[4H, 5H, 6H], [2S, 2H, 2D], 6S, AS, 5S, 5C, QC]\n","Discard QC | D: QC | K: QC | 56\n","MAX:0.2949, 0.0000\n","Discard Action\n","Player 0 discards QC.\n","\n","Player 0 has [[4H, 5H, 6H], [2S, 2H, 2D], 6S, AS, 5S, 5C] with 17 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9D.\n","\n","Player 1 discards 4S.\n","\n","Player 1 has [[9S, 9H, 9D, 9C], 2C, AC, 4D, 3D, 3H, AD] with 14 deadwood.\n","\n","Update States\n","Draw new card: 0.258333\n","Pickup from discard: 0.25973317\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 4S.\n","\n","Update States\n","Current Hand: [[4S, 5S, 6S], [4H, 5H, 6H], [2S, 2H, 2D], AS, 5C]\n","Discard 5C | D: 5C | K: 5C | 49\n","MAX:0.2192, 0.0000\n","Discard Action\n","Player 0 discards 5C.\n","\n","Player 0 has [[4S, 5S, 6S], [4H, 5H, 6H], [2S, 2H, 2D], AS] with 1 deadwood.\n","\n","False\n","Draw from deck\n","Player 1 draws 3S.\n","\n","Player 1 discards 4D.\n","\n","Player 1 has [[3S, 3H, 3D], [9S, 9H, 9D, 9C], 2C, AC, AD] with 4 deadwood.\n","\n","Player 1 melds [[3S, 3H, 3D], [9S, 9H, 9D, 9C]] with 4 deadwood from [AD, AC, 2C].\n","\n","Player 0 melds [[4S, 5S, 6S], [4H, 5H, 6H], [2S, 2H, 2D]].\n","\n","Player 0 has 1 deadwood with [AS]\n","\n","Player 0 undercuts and scores the undercut bonus of 25 plus deadwood difference of 3 for 28 total points.\n","\n","Player\tScore\n","0\t28\n","1\t0\n","\n","Player 0 is dealt [7C, 4D, 8H, 2C, 5D, TD, JS, 2D, 9S, 9D].\n","\n","Player 1 is dealt [5C, 4C, 5S, 7H, KC, 3S, AD, 8D, KD, 6S].\n","\n","Player 0 starts.\n","\n","The initial face up card is 2H.\n","\n","Update States\n","Draw new card: 0.2081592\n","Pickup from discard: 0.2117284\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 2H.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 8H, 5D, TD, JS, 9S, 9D]\n","Discard 8H | D: 8H | K: 8H | 26\n","MAX:0.2621, 0.0000\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, TD, JS, 9S, 9D] with 54 deadwood.\n","\n","Draw from deck\n","Player 1 draws AH.\n","\n","Player 1 discards KC.\n","\n","Player 1 has [5C, 4C, 5S, 7H, 3S, AD, 8D, KD, 6S, AH] with 50 deadwood.\n","\n","Update States\n","Draw new card: 0.23392132\n","Pickup from discard: 0.23656318\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws KC.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 5D, TD, JS, 9S, 9D, KC]\n","Discard TD | D: TD | K: JS | 41\n","MAX:0.1731, 0.0000\n","Discard Action\n","Player 0 discards TD.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, JS, 9S, 9D, KC] with 54 deadwood.\n","\n","Draw from deck\n","Player 1 draws TH.\n","\n","Player 1 discards KD.\n","\n","Player 1 has [5C, 4C, 5S, 7H, 3S, AD, 8D, 6S, AH, TH] with 50 deadwood.\n","\n","Update States\n","Draw new card: 0.21139659\n","Pickup from discard: 0.2096929\n","Draw from deck\n","Player 0 draws KS.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 5D, JS, 9S, 9D, KC, KS]\n","Discard TH | D: 9S | K: 7C | 28\n","MAX:0.1531, 0.0000\n","Discard Action\n","Player 0 discards 9S.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, JS, 9D, KC, KS] with 55 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4H.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [5C, 4C, 5S, 7H, 3S, AD, 8D, 6S, AH, 4H] with 44 deadwood.\n","\n","Update States\n","Draw new card: 0.20769706\n","Pickup from discard: 0.21099262\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TH.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 5D, JS, 9D, KC, KS, TH]\n","Discard TH | D: 9D | K: JS | 28\n","MAX:0.1897, 0.0000\n","Discard Action\n","Player 0 discards 9D.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, JS, KC, KS, TH] with 56 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7S.\n","\n","Player 1 discards 8D.\n","\n","Player 1 has [[5S, 6S, 7S], 5C, 4C, 7H, 3S, AD, AH, 4H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.21857391\n","Pickup from discard: 0.2150963\n","Draw from deck\n","Player 0 draws TC.\n","\n","Update States\n","Current Hand: [[2H, 2D, 2C], 7C, 4D, 5D, JS, KC, KS, TH, TC]\n","Discard TH | D: TH | K: JS | 28\n","MAX:0.2279, 0.0000\n","Discard Action\n","Player 0 discards TH.\n","\n","Player 0 has [[2H, 2D, 2C], 7C, 4D, 5D, JS, KC, KS, TC] with 56 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4S.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[5S, 6S, 7S], [4S, 4H, 4C], 5C, 3S, AD, AH] with 10 deadwood.\n","\n","Player 1 melds [[5S, 6S, 7S], [4S, 4H, 4C]] with 10 deadwood from [3S, AH, AD, 5C].\n","\n","Player 0 melds [[2H, 2D, 2C]].\n","\n","Player 0 lays off 4D on [4S, 4H, 4C].\n","\n","Player 0 has 52 deadwood with [JS, KS, 5D, 7C, TC, KC]\n","\n","Player 1 scores the deadwood difference of 42.\n","\n","Player\tScore\n","0\t28\n","1\t42\n","\n","Player 0 is dealt [3C, AH, 7C, 6H, 6D, 2H, 9C, JC, 2C, 4H].\n","\n","Player 1 is dealt [QH, 9H, TD, 2S, 4S, 4D, AD, 9D, 8S, 8H].\n","\n","Player 1 starts.\n","\n","The initial face up card is 3D.\n","\n","Player 1 declines 3D.\n","\n","Update States\n","Draw new card: 0.20878309\n","Pickup from discard: 0.21072072\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 3D.\n","\n","Update States\n","Current Hand: [3C, AH, 7C, 6H, 6D, 2H, 9C, JC, 2C, 4H, 3D]\n","Discard JC | D: JC | K: JC | 55\n","MAX:0.1714, 0.0000\n","Discard Action\n","Player 0 discards JC.\n","\n","Player 0 has [3C, AH, 7C, 6H, 6D, 2H, 9C, 2C, 4H, 3D] with 43 deadwood.\n","\n","Draw from deck\n","Player 1 draws TH.\n","\n","Player 1 discards QH.\n","\n","Player 1 has [[8H, 9H, TH], TD, 2S, 4S, 4D, AD, 9D, 8S] with 38 deadwood.\n","\n","Update States\n","Draw new card: 0.21904057\n","Pickup from discard: 0.21942674\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws QH.\n","\n","Update States\n","Current Hand: [3C, AH, 7C, 6H, 6D, 2H, 9C, 2C, 4H, 3D, QH]\n","Discard QH | D: 7C | K: 7C | 30\n","MAX:0.1710, 0.0000\n","Discard Action\n","Player 0 discards 7C.\n","\n","Player 0 has [3C, AH, 6H, 6D, 2H, 9C, 2C, 4H, 3D, QH] with 46 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7D.\n","\n","Player 1 discards TD.\n","\n","Player 1 has [[8H, 9H, TH], 2S, 4S, 4D, AD, 9D, 8S, 7D] with 35 deadwood.\n","\n","Update States\n","Draw new card: 0.22798033\n","Pickup from discard: 0.22098477\n","Draw from deck\n","Player 0 draws JH.\n","\n","Update States\n","Current Hand: [3C, AH, 6H, 6D, 2H, 9C, 2C, 4H, 3D, QH, JH]\n","Discard 9C | D: 9C | K: JH | 53\n","MAX:0.2343, 0.0000\n","Discard Action\n","Player 0 discards 9C.\n","\n","Player 0 has [3C, AH, 6H, 6D, 2H, 2C, 4H, 3D, QH, JH] with 47 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 9C.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 8S, 8H, 7D] with 34 deadwood.\n","\n","Update States\n","Draw new card: 0.207056\n","Pickup from discard: 0.21552747\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TH.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 6H, 6D, 2H, 2C, 4H, 3D]\n","Discard KD | D: 6H | K: QH | 44\n","MAX:0.1694, 0.0000\n","Discard Action\n","Player 0 discards 6H.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 6D, 2H, 2C, 4H, 3D] with 21 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7H.\n","\n","Player 1 discards 8H.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 8S, 7D, 7H] with 33 deadwood.\n","\n","Update States\n","Draw new card: 0.25151443\n","Pickup from discard: 0.24763985\n","Draw from deck\n","Player 0 draws TC.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 6D, 2H, 2C, 4H, 3D, TC]\n","Discard 6D | D: 6D | K: 6D | 37\n","MAX:0.2653, 0.0000\n","Discard Action\n","Player 0 discards 6D.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, TC] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws TS.\n","\n","Player 1 discards TS.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 8S, 7D, 7H] with 33 deadwood.\n","\n","Update States\n","Draw new card: 0.25013253\n","Pickup from discard: 0.2402273\n","Draw from deck\n","Player 0 draws QS.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, TC, QS]\n","Discard QS | D: QS | K: TC | 17\n","MAX:0.2593, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, TC] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws 8D.\n","\n","Player 1 discards 8S.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 7D, 7H, 8D] with 33 deadwood.\n","\n","Update States\n","Draw new card: 0.24472368\n","Pickup from discard: 0.23512243\n","Draw from deck\n","Player 0 draws AS.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, TC, AS]\n","Discard TC | D: TC | K: TC | 54\n","MAX:0.2046, 0.0000\n","Discard Action\n","Player 0 discards TC.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, AS] with 16 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5S.\n","\n","Player 1 discards 8D.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 7D, 7H, 5S] with 30 deadwood.\n","\n","Update States\n","Draw new card: 0.25990722\n","Pickup from discard: 0.25098306\n","Draw from deck\n","Player 0 draws JS.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, AS, JS]\n","Discard JS | D: JS | K: JS | 16\n","MAX:0.2946, 0.0000\n","Discard Action\n","Player 0 discards JS.\n","\n","Player 0 has [[TH, JH, QH], 3C, AH, 2H, 2C, 4H, 3D, AS] with 16 deadwood.\n","\n","Draw from deck\n","Player 1 draws KC.\n","\n","Player 1 discards KC.\n","\n","Player 1 has [[9H, 9D, 9C], 2S, 4S, 4D, AD, 7D, 7H, 5S] with 30 deadwood.\n","\n","Update States\n","Draw new card: 0.26878157\n","Pickup from discard: 0.25692803\n","Draw from deck\n","Player 0 draws 3S.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], [3S, 3D, 3C], AH, 2H, 2C, 4H, AS]\n","Discard 4H | D: 4H | K: 4H | 22\n","MAX:0.2727, 0.0000\n","Discard Action\n","Player 0 discards 4H.\n","\n","Player 0 has [[TH, JH, QH], [3S, 3D, 3C], AH, 2H, 2C, AS] with 6 deadwood.\n","\n","False\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 4H.\n","\n","Player 1 discards 7D.\n","\n","Player 1 has [[4S, 4H, 4D], [9H, 9D, 9C], 2S, AD, 7H, 5S] with 15 deadwood.\n","\n","Update States\n","Draw new card: 0.26836678\n","Pickup from discard: 0.255994\n","Draw from deck\n","Player 0 draws KS.\n","\n","Update States\n","Current Hand: [[TH, JH, QH], [3S, 3D, 3C], AH, 2H, 2C, AS, KS]\n","Discard KS | D: KS | K: KS | 18\n","MAX:0.2874, 0.0000\n","Discard Action\n","Player 0 discards KS.\n","\n","Player 0 has [[TH, JH, QH], [3S, 3D, 3C], AH, 2H, 2C, AS] with 6 deadwood.\n","\n","False\n","Draw from deck\n","Player 1 draws QD.\n","\n","Player 1 discards QD.\n","\n","Player 1 has [[4S, 4H, 4D], [9H, 9D, 9C], 2S, AD, 7H, 5S] with 15 deadwood.\n","\n","Update States\n","Draw new card: 0.26869798\n","Pickup from discard: 0.2572033\n","Draw from deck\n","Player 0 draws KH.\n","\n","Update States\n","Current Hand: [[TH, JH, QH, KH], [3S, 3D, 3C], AH, 2H, 2C, AS]\n","Discard TH | D: TH | K: AH | 28\n","MAX:0.2018, 0.0000\n","Discard Action\n","Player 0 discards TH.\n","\n","Player 0 has [[JH, QH, KH], [3S, 3D, 3C], AH, 2H, 2C, AS] with 6 deadwood.\n","\n","False\n","Draw from deck\n","Player 1 draws 9S.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[4S, 4H, 4D], [9S, 9H, 9D, 9C], 2S, AD, 5S] with 8 deadwood.\n","\n","Player 1 melds [[4S, 4H, 4D], [9S, 9H, 9D, 9C]] with 8 deadwood from [2S, 5S, AD].\n","\n","Player 0 melds [[JH, QH, KH], [3S, 3D, 3C]].\n","\n","Player 0 has 6 deadwood with [AS, AH, 2H, 2C]\n","\n","Player 0 undercuts and scores the undercut bonus of 25 plus deadwood difference of 2 for 27 total points.\n","\n","Player\tScore\n","0\t55\n","1\t42\n","\n","Player 0 is dealt [9D, 3D, 5D, 4H, 7C, QC, 8S, 5S, 8D, AD].\n","\n","Player 1 is dealt [2D, 3C, 3S, 9C, AC, KC, 3H, 4S, TC, KS].\n","\n","Player 0 starts.\n","\n","The initial face up card is 8C.\n","\n","Update States\n","Draw new card: 0.21009327\n","Pickup from discard: 0.21122344\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 8C.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 9D, 3D, 5D, 4H, 7C, QC, 5S, AD]\n","Discard TH | D: 9D | K: 7C | 28\n","MAX:0.1536, 0.0000\n","Discard Action\n","Player 0 discards 9D.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, 7C, QC, 5S, AD] with 35 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4C.\n","\n","Player 1 discards KC.\n","\n","Player 1 has [[3S, 3H, 3C], 2D, 9C, AC, 4S, TC, KS, 4C] with 40 deadwood.\n","\n","Update States\n","Draw new card: 0.24916296\n","Pickup from discard: 0.24170417\n","Draw from deck\n","Player 0 draws JH.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, 7C, QC, 5S, AD, JH]\n","Discard 7C | D: 7C | K: 7C | 51\n","MAX:0.2233, 0.0000\n","Discard Action\n","Player 0 discards 7C.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, QC, 5S, AD, JH] with 38 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5C.\n","\n","Player 1 discards TC.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, 9C, AC, 3H, 4S, KS] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.2329164\n","Pickup from discard: 0.2269174\n","Draw from deck\n","Player 0 draws 7D.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, QC, 5S, AD, JH, 7D]\n","Discard 7D | D: 7D | K: JH | 38\n","MAX:0.2097, 0.0000\n","Discard Action\n","Player 0 discards 7D.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, QC, 5S, AD, JH] with 38 deadwood.\n","\n","Draw from deck\n","Player 1 draws JS.\n","\n","Player 1 discards KS.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, 9C, AC, 3H, 4S, JS] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.23402613\n","Pickup from discard: 0.22692306\n","Draw from deck\n","Player 0 draws 6H.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, QC, 5S, AD, JH, 6H]\n","Discard QC | D: QC | K: JH | 56\n","MAX:0.2647, 0.0000\n","Discard Action\n","Player 0 discards QC.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, JH, 6H] with 34 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7S.\n","\n","Player 1 discards JS.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, 9C, AC, 3H, 4S, 7S] with 29 deadwood.\n","\n","Update States\n","Draw new card: 0.25101602\n","Pickup from discard: 0.2427342\n","Draw from deck\n","Player 0 draws 7H.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, JH, 6H, 7H]\n","Discard JH | D: JH | K: JH | 29\n","MAX:0.2772, 0.0000\n","Discard Action\n","Player 0 discards JH.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, 6H, 7H] with 31 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9H.\n","\n","Player 1 discards 9C.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 9H] with 29 deadwood.\n","\n","Update States\n","Draw new card: 0.26487398\n","Pickup from discard: 0.25391686\n","Draw from deck\n","Player 0 draws QD.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, 6H, 7H, QD]\n","Discard 7H | D: 7H | K: 7H | 25\n","MAX:0.2722, 0.0000\n","Discard Action\n","Player 0 discards 7H.\n","\n","Player 0 has [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, 6H, QD] with 34 deadwood.\n","\n","Draw from deck\n","Player 1 draws TD.\n","\n","Player 1 discards TD.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 9H] with 29 deadwood.\n","\n","Update States\n","Draw new card: 0.25365508\n","Pickup from discard: 0.25192294\n","Draw from deck\n","Player 0 draws 6C.\n","\n","Update States\n","Current Hand: [[8S, 8D, 8C], 3D, 5D, 4H, 5S, AD, 6H, QD, 6C]\n","Discard 8D | D: 8D | K: QD | 39\n","MAX:0.1794, 0.0000\n","Discard Action\n","Player 0 discards 8D.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, 8C, 6H, QD, 6C] with 56 deadwood.\n","\n","Draw from deck\n","Player 1 draws TH.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 9H] with 29 deadwood.\n","\n","Update States\n","Draw new card: 0.26286232\n","Pickup from discard: 0.22595087\n","Draw from deck\n","Player 0 draws 9S.\n","\n","Update States\n","Current Hand: [3D, 5D, 4H, 8S, 5S, AD, 8C, 6H, QD, 6C, 9S]\n","Discard 6H | D: 6H | K: 6C | 24\n","MAX:0.1866, 0.0000\n","Discard Action\n","Player 0 discards 6H.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, 8C, QD, 6C, 9S] with 59 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5H.\n","\n","Player 1 discards 9H.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 5H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.23144723\n","Pickup from discard: 0.13199279\n","Draw from deck\n","Player 0 draws 2C.\n","\n","Update States\n","Current Hand: [3D, 5D, 4H, 8S, 5S, AD, 8C, QD, 6C, 9S, 2C]\n","Discard 8C | D: 8C | K: 9S | 52\n","MAX:0.2325, 0.0000\n","Discard Action\n","Player 0 discards 8C.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 9S, 2C] with 53 deadwood.\n","\n","Draw from deck\n","Player 1 draws QS.\n","\n","Player 1 discards QS.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 5H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.23555\n","Pickup from discard: 0.23801099\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws QS.\n","\n","Update States\n","Current Hand: [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 9S, 2C, QS]\n","Discard QS | D: 9S | K: 9S | 17\n","MAX:0.1890, 0.0000\n","Discard Action\n","Player 0 discards 9S.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 2C, QS] with 54 deadwood.\n","\n","Draw from deck\n","Player 1 draws QH.\n","\n","Player 1 discards QH.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 5H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.22084098\n","Pickup from discard: 0.21852793\n","Draw from deck\n","Player 0 draws 2H.\n","\n","Update States\n","Current Hand: [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 2C, QS, 2H]\n","Discard QS | D: QS | K: 6C | 17\n","MAX:0.2520, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [3D, 5D, 4H, 8S, 5S, AD, QD, 6C, 2C, 2H] with 46 deadwood.\n","\n","Draw from deck\n","Player 1 draws JC.\n","\n","Player 1 discards JC.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 7S, 5H] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.25052187\n","Pickup from discard: 0.23954792\n","Draw from deck\n","Player 0 draws 4D.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], 4H, 8S, 5S, AD, QD, 6C, 2C, 2H]\n","Discard 8S | D: 8S | K: 6C | 13\n","MAX:0.2436, 0.0000\n","Discard Action\n","Player 0 discards 8S.\n","\n","Player 0 has [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6D.\n","\n","Player 1 discards 7S.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 5H, 6D] with 24 deadwood.\n","\n","Update States\n","Draw new card: 0.2523581\n","Pickup from discard: 0.24225847\n","Draw from deck\n","Player 0 draws JD.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H, JD]\n","Discard JD | D: JD | K: 6C | 42\n","MAX:0.2622, 0.0000\n","Discard Action\n","Player 0 discards JD.\n","\n","Player 0 has [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws KH.\n","\n","Player 1 discards KH.\n","\n","Player 1 has [[3C, 4C, 5C], 2D, 3S, AC, 3H, 4S, 5H, 6D] with 24 deadwood.\n","\n","Update States\n","Draw new card: 0.2656818\n","Pickup from discard: 0.2229946\n","Draw from deck\n","Player 0 draws 8H.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H, 8H]\n","Discard 8H | D: 8H | K: QD | 26\n","MAX:0.2536, 0.0000\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws 2S.\n","\n","Player 1 discards 6D.\n","\n","Player 1 has [[2S, 3S, 4S], [3C, 4C, 5C], 2D, AC, 3H, 5H] with 11 deadwood.\n","\n","Update States\n","Draw new card: 0.25027367\n","Pickup from discard: 0.24394903\n","Draw from deck\n","Player 0 draws AH.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], 4H, 5S, AD, QD, 6C, 2C, 2H, AH]\n","Discard QD | D: QD | K: QD | 43\n","MAX:0.2779, 0.0000\n","Discard Action\n","Player 0 discards QD.\n","\n","Player 0 has [[3D, 4D, 5D], 4H, 5S, AD, 6C, 2C, 2H, AH] with 21 deadwood.\n","\n","Draw from deck\n","Player 1 draws AS.\n","\n","Player 1 discards 5H.\n","\n","Player 1 has [[AS, 2S, 3S, 4S], [3C, 4C, 5C], 2D, AC, 3H] with 6 deadwood.\n","\n","Player 1 melds [[AS, 2S, 3S, 4S], [3C, 4C, 5C]] with 6 deadwood from [3H, 2D, AC].\n","\n","Player 0 melds [[3D, 4D, 5D]].\n","\n","Player 0 lays off 5S on [AS, 2S, 3S, 4S].\n","\n","Player 0 lays off 2C on [3C, 4C, 5C].\n","\n","Player 0 lays off 6C on [3C, 4C, 5C, 2C].\n","\n","Player 0 has 8 deadwood with [AH, 2H, 4H, AD]\n","\n","Player 1 scores the deadwood difference of 2.\n","\n","Player\tScore\n","0\t55\n","1\t44\n","\n","Player 0 is dealt [AS, 4C, 3S, KH, 6D, 2C, 5H, AH, 2S, QD].\n","\n","Player 1 is dealt [JS, 7H, JD, 2H, AC, 9H, 8S, JH, 5C, 4H].\n","\n","Player 1 starts.\n","\n","The initial face up card is 2D.\n","\n","Player 1 declines 2D.\n","\n","Update States\n","Draw new card: 0.17259115\n","Pickup from discard: 0.20116647\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 2D.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], 4C, KH, 6D, 2C, 5H, AH, QD, 2D]\n","Discard KH | D: KH | K: QD | 31\n","MAX:0.2434, 0.0000\n","Discard Action\n","Player 0 discards KH.\n","\n","Player 0 has [[AS, 2S, 3S], 4C, 6D, 2C, 5H, AH, QD, 2D] with 30 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5S.\n","\n","Player 1 discards 9H.\n","\n","Player 1 has [[JS, JH, JD], 7H, 2H, AC, 8S, 5C, 4H, 5S] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.25112793\n","Pickup from discard: 0.26998216\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 9H.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], 4C, 6D, 2C, 5H, AH, QD, 2D, 9H]\n","Discard 9H | D: QD | K: QD | 27\n","MAX:0.0429, 0.0000\n","Discard Action\n","Player 0 discards QD.\n","\n","Player 0 has [[AS, 2S, 3S], 4C, 6D, 2C, 5H, AH, 2D, 9H] with 29 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9C.\n","\n","Player 1 discards 9C.\n","\n","Player 1 has [[JS, JH, JD], 7H, 2H, AC, 8S, 5C, 4H, 5S] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.21277547\n","Pickup from discard: 0.21174602\n","Draw from deck\n","Player 0 draws 3C.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], [2C, 3C, 4C], 6D, 5H, AH, 2D, 9H]\n","Discard TD | D: 9H | K: 9H | 41\n","MAX:0.1992, 0.0000\n","Discard Action\n","Player 0 discards 9H.\n","\n","Player 0 has [[AS, 2S, 3S], [2C, 3C, 4C], 6D, 5H, AH, 2D] with 14 deadwood.\n","\n","Draw from deck\n","Player 1 draws 4S.\n","\n","Player 1 discards 8S.\n","\n","Player 1 has [[JS, JH, JD], 7H, 2H, AC, 5C, 4H, 5S, 4S] with 28 deadwood.\n","\n","Update States\n","Draw new card: 0.25412098\n","Pickup from discard: 0.2541765\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 8S.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], [2C, 3C, 4C], 6D, 5H, AH, 2D, 8S]\n","Discard 6D | D: 6D | K: 5H | 37\n","MAX:0.2513, 0.0000\n","Discard Action\n","Player 0 discards 6D.\n","\n","Player 0 has [[AS, 2S, 3S], [2C, 3C, 4C], 5H, AH, 2D, 8S] with 16 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9D.\n","\n","Player 1 discards 9D.\n","\n","Player 1 has [[JS, JH, JD], 7H, 2H, AC, 5C, 4H, 5S, 4S] with 28 deadwood.\n","\n","Update States\n","Draw new card: 0.25563738\n","Pickup from discard: 0.24818705\n","Draw from deck\n","Player 0 draws AD.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], [2C, 3C, 4C], 5H, AH, 2D, 8S, AD]\n","Discard 5H | D: 5H | K: 8S | 23\n","MAX:0.2912, 0.0000\n","Discard Action\n","Player 0 discards 5H.\n","\n","Player 0 has [[AS, 2S, 3S], [2C, 3C, 4C], AH, 2D, 8S, AD] with 12 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 5H.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[5S, 5H, 5C], [JS, JH, JD], 2H, AC, 4H, 4S] with 11 deadwood.\n","\n","Update States\n","Draw new card: 0.2588717\n","Pickup from discard: 0.25022733\n","Draw from deck\n","Player 0 draws 3D.\n","\n","Update States\n","Current Hand: [[AS, 2S, 3S], [AD, 2D, 3D], [2C, 3C, 4C], AH, 8S]\n","Discard 8S | D: 8S | K: 2S | 13\n","MAX:0.2447, 0.0000\n","Discard Action\n","Player 0 discards 8S.\n","\n","Player 0 has [[AS, 2S, 3S], [AD, 2D, 3D], [2C, 3C, 4C], AH] with 1 deadwood.\n","\n","False\n","Draw from deck\n","Player 1 draws 4D.\n","\n","Player 1 discards 2H.\n","\n","Player 1 has [[4S, 4H, 4D], [5S, 5H, 5C], [JS, JH, JD], AC] with 1 deadwood.\n","\n","Player 1 melds [[4S, 4H, 4D], [5S, 5H, 5C], [JS, JH, JD]] with 1 deadwood from [AC].\n","\n","Player 0 melds [[AS, 2S, 3S], [AD, 2D, 3D], [2C, 3C, 4C]].\n","\n","Player 0 has 1 deadwood with [AH]\n","\n","Player 0 undercuts and scores the undercut bonus of 25 plus deadwood difference of 0 for 25 total points.\n","\n","Player\tScore\n","0\t80\n","1\t44\n","\n","Player 0 is dealt [TD, 2C, 8H, 3C, JH, 7C, QS, 5S, KH, 6S].\n","\n","Player 1 is dealt [6D, 9D, 5H, QD, 3D, 8C, 4C, 3H, 3S, JD].\n","\n","Player 0 starts.\n","\n","The initial face up card is 8D.\n","\n","Update States\n","Draw new card: 0.19440046\n","Pickup from discard: 0.19278602\n","Player 0 declines 8D.\n","\n","Player 1 declines 8D.\n","\n","Draw from deck\n","Player 0 draws TC.\n","\n","Update States\n","Current Hand: [TD, 2C, 8H, 3C, JH, 7C, QS, 5S, KH, 6S, TC]\n","Discard 8H | D: 8H | K: 7C | 26\n","MAX:0.1976, 0.0000\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [TD, 2C, 3C, JH, 7C, QS, 5S, KH, 6S, TC] with 73 deadwood.\n","\n","Draw from deck\n","Player 1 draws TS.\n","\n","Player 1 discards JD.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 9D, 5H, QD, 8C, 4C, TS] with 52 deadwood.\n","\n","Update States\n","Draw new card: 0.19031166\n","Pickup from discard: 0.18991007\n","Draw from deck\n","Player 0 draws 4H.\n","\n","Update States\n","Current Hand: [TD, 2C, 3C, JH, 7C, QS, 5S, KH, 6S, TC, 4H]\n","Discard QS | D: QS | K: QS | 17\n","MAX:0.1931, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [TD, 2C, 3C, JH, 7C, 5S, KH, 6S, TC, 4H] with 67 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7H.\n","\n","Player 1 discards TS.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 9D, 5H, QD, 8C, 4C, 7H] with 49 deadwood.\n","\n","Update States\n","Draw new card: 0.20649223\n","Pickup from discard: 0.2042986\n","Draw from deck\n","Player 0 draws 7D.\n","\n","Update States\n","Current Hand: [TD, 2C, 3C, JH, 7C, 5S, KH, 6S, TC, 4H, 7D]\n","Discard TC | D: TC | K: 7C | 54\n","MAX:0.1831, 0.0000\n","Discard Action\n","Player 0 discards TC.\n","\n","Player 0 has [TD, 2C, 3C, JH, 7C, 5S, KH, 6S, 4H, 7D] with 64 deadwood.\n","\n","Draw from deck\n","Player 1 draws 2S.\n","\n","Player 1 discards QD.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 9D, 5H, 8C, 4C, 7H, 2S] with 41 deadwood.\n","\n","Update States\n","Draw new card: 0.20974505\n","Pickup from discard: 0.20826152\n","Draw from deck\n","Player 0 draws 7S.\n","\n","Update States\n","Current Hand: [[7S, 7D, 7C], TD, 2C, 3C, JH, 5S, KH, 6S, 4H]\n","Discard KH | D: KH | K: TD | 31\n","MAX:0.2505, 0.0000\n","Discard Action\n","Player 0 discards KH.\n","\n","Player 0 has [[7S, 7D, 7C], TD, 2C, 3C, JH, 5S, 6S, 4H] with 40 deadwood.\n","\n","Draw from deck\n","Player 1 draws 2D.\n","\n","Player 1 discards 9D.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 8C, 4C, 7H, 2S, 2D] with 34 deadwood.\n","\n","Update States\n","Draw new card: 0.23176359\n","Pickup from discard: 0.22537553\n","Draw from deck\n","Player 0 draws AC.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, JH, 5S, 6S, 4H]\n","Discard JH | D: JH | K: 4H | 29\n","MAX:0.2525, 0.0000\n","Discard Action\n","Player 0 discards JH.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9C.\n","\n","Player 1 discards 9C.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 8C, 4C, 7H, 2S, 2D] with 34 deadwood.\n","\n","Update States\n","Draw new card: 0.24725774\n","Pickup from discard: 0.2388761\n","Draw from deck\n","Player 0 draws KS.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H, KS]\n","Discard KS | D: KS | K: TD | 18\n","MAX:0.2818, 0.0000\n","Discard Action\n","Player 0 discards KS.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5C.\n","\n","Player 1 discards 8C.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 4C, 7H, 2S, 2D, 5C] with 31 deadwood.\n","\n","Update States\n","Draw new card: 0.2473259\n","Pickup from discard: 0.23944388\n","Draw from deck\n","Player 0 draws JC.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H, JC]\n","Discard JC | D: JC | K: JC | 55\n","MAX:0.2793, 0.0000\n","Discard Action\n","Player 0 discards JC.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws AD.\n","\n","Player 1 discards 7H.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 4C, 2S, 2D, 5C, AD] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.24457256\n","Pickup from discard: 0.24440259\n","Draw from deck\n","Player 0 draws 9S.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H, 9S]\n","Discard 9S | D: 9S | K: 9S | 14\n","MAX:0.2568, 0.0000\n","Discard Action\n","Player 0 discards 9S.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H] with 25 deadwood.\n","\n","Draw from deck\n","Player 1 draws QH.\n","\n","Player 1 discards QH.\n","\n","Player 1 has [[3S, 3H, 3D], 6D, 5H, 4C, 2S, 2D, 5C, AD] with 25 deadwood.\n","\n","Update States\n","Draw new card: 0.24742413\n","Pickup from discard: 0.23970284\n","Draw from deck\n","Player 0 draws AH.\n","\n","Update States\n","Current Hand: [[AC, 2C, 3C], [7S, 7D, 7C], TD, 5S, 6S, 4H, AH]\n","Discard TD | D: TD | K: TD | 41\n","MAX:0.2833, 0.0000\n","Discard Action\n","Player 0 discards TD.\n","\n","Player 0 has [[AC, 2C, 3C], [7S, 7D, 7C], 5S, 6S, 4H, AH] with 16 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6C.\n","\n","Player 1 discards 6D.\n","\n","Player 1 has [[4C, 5C, 6C], [3S, 3H, 3D], 5H, 2S, 2D, AD] with 10 deadwood.\n","\n","Player 1 melds [[4C, 5C, 6C], [3S, 3H, 3D]] with 10 deadwood from [2S, 5H, AD, 2D].\n","\n","Player 0 melds [[AC, 2C, 3C], [7S, 7D, 7C]].\n","\n","Player 0 has 16 deadwood with [5S, 6S, AH, 4H]\n","\n","Player 1 scores the deadwood difference of 6.\n","\n","Player\tScore\n","0\t80\n","1\t50\n","\n","Player 0 is dealt [4S, AS, 5H, JC, 2C, 9H, 9D, 7C, 4H, QS].\n","\n","Player 1 is dealt [AC, KS, 3S, 7S, 4D, JD, 7D, TS, QC, 4C].\n","\n","Player 1 starts.\n","\n","The initial face up card is 3C.\n","\n","Player 1 declines 3C.\n","\n","Update States\n","Draw new card: 0.21048538\n","Pickup from discard: 0.2099461\n","Player 0 declines 3C.\n","\n","Draw from deck\n","Player 1 draws 5S.\n","\n","Player 1 discards QC.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, JD, 7D, TS, 4C, 5S] with 61 deadwood.\n","\n","Update States\n","Draw new card: 0.20814455\n","Pickup from discard: 0.20772186\n","Draw from deck\n","Player 0 draws QH.\n","\n","Update States\n","Current Hand: [4S, AS, 5H, JC, 2C, 9H, 9D, 7C, 4H, QS, QH]\n","Discard JC | D: JC | K: QS | 55\n","MAX:0.2269, 0.0000\n","Discard Action\n","Player 0 discards JC.\n","\n","Player 0 has [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QS, QH] with 61 deadwood.\n","\n","Draw from deck\n","Player 1 draws JH.\n","\n","Player 1 discards JH.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, JD, 7D, TS, 4C, 5S] with 61 deadwood.\n","\n","Update States\n","Draw new card: 0.20161411\n","Pickup from discard: 0.20398493\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws JH.\n","\n","Update States\n","Current Hand: [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QS, QH, JH]\n","Discard QS | D: QS | K: QS | 17\n","MAX:0.2413, 0.0000\n","Discard Action\n","Player 0 discards QS.\n","\n","Player 0 has [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QH, JH] with 61 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5D.\n","\n","Player 1 discards TS.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, JD, 7D, 4C, 5S, 5D] with 56 deadwood.\n","\n","Update States\n","Draw new card: 0.2398133\n","Pickup from discard: 0.23350981\n","Draw from deck\n","Player 0 draws 8D.\n","\n","Update States\n","Current Hand: [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QH, JH, 8D]\n","Discard 8D | D: 8D | K: 7C | 39\n","MAX:0.2250, 0.0000\n","Discard Action\n","Player 0 discards 8D.\n","\n","Player 0 has [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QH, JH] with 61 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6H.\n","\n","Player 1 discards JD.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, 7D, 4C, 5S, 5D, 6H] with 52 deadwood.\n","\n","Update States\n","Draw new card: 0.235021\n","Pickup from discard: 0.23214418\n","Draw from deck\n","Player 0 draws JS.\n","\n","Update States\n","Current Hand: [4S, AS, 5H, 2C, 9H, 9D, 7C, 4H, QH, JH, JS]\n","Discard 9D | D: 9D | K: JS | 40\n","MAX:0.1749, 0.0000\n","Discard Action\n","Player 0 discards 9D.\n","\n","Player 0 has [4S, AS, 5H, 2C, 9H, 7C, 4H, QH, JH, JS] with 62 deadwood.\n","\n","Draw from deck\n","Player 1 draws TH.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [AC, KS, 3S, 7S, 4D, 7D, 4C, 5S, 5D, 6H] with 52 deadwood.\n","\n","Update States\n","Draw new card: 0.20487773\n","Pickup from discard: 0.21193998\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TH.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 7C, 4H, JS]\n","Discard JS | D: JS | K: 7C | 16\n","MAX:0.2895, 0.0000\n","Discard Action\n","Player 0 discards JS.\n","\n","Player 0 has [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 7C, 4H] with 23 deadwood.\n","\n","Draw from deck\n","Player 1 draws 5C.\n","\n","Player 1 discards KS.\n","\n","Player 1 has [[5S, 5D, 5C], AC, 3S, 7S, 4D, 7D, 4C, 6H] with 32 deadwood.\n","\n","Update States\n","Draw new card: 0.26757225\n","Pickup from discard: 0.25636718\n","Draw from deck\n","Player 0 draws 2S.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 7C, 4H, 2S]\n","Discard 7C | D: 7C | K: 7C | 51\n","MAX:0.2671, 0.0000\n","Discard Action\n","Player 0 discards 7C.\n","\n","Player 0 has [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S] with 18 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 7C.\n","\n","Player 1 discards 6H.\n","\n","Player 1 has [[5S, 5D, 5C], [7S, 7D, 7C], AC, 3S, 4D, 4C] with 12 deadwood.\n","\n","Update States\n","Draw new card: 0.25941792\n","Pickup from discard: 0.24880427\n","Draw from deck\n","Player 0 draws KC.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S, KC]\n","Discard KC | D: KC | K: KC | 57\n","MAX:0.2364, 0.0000\n","Discard Action\n","Player 0 discards KC.\n","\n","Player 0 has [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S] with 18 deadwood.\n","\n","Draw from deck\n","Player 1 draws TC.\n","\n","Player 1 discards TC.\n","\n","Player 1 has [[5S, 5D, 5C], [7S, 7D, 7C], AC, 3S, 4D, 4C] with 12 deadwood.\n","\n","Update States\n","Draw new card: 0.25852424\n","Pickup from discard: 0.254448\n","Draw from deck\n","Player 0 draws 9S.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S, 9S]\n","Discard 9S | D: 9S | K: 9S | 14\n","MAX:0.2234, 0.0000\n","Discard Action\n","Player 0 discards 9S.\n","\n","Player 0 has [[9H, TH, JH, QH], 4S, AS, 5H, 2C, 4H, 2S] with 18 deadwood.\n","\n","Draw from deck\n","Player 1 draws 6D.\n","\n","Player 1 discards 6D.\n","\n","Player 1 has [[5S, 5D, 5C], [7S, 7D, 7C], AC, 3S, 4D, 4C] with 12 deadwood.\n","\n","Update States\n","Draw new card: 0.26014832\n","Pickup from discard: 0.2536934\n","Draw from deck\n","Player 0 draws KH.\n","\n","Update States\n","Current Hand: [[9H, TH, JH, QH, KH], 4S, AS, 5H, 2C, 4H, 2S]\n","Discard 5H | D: 5H | K: 5H | 23\n","MAX:0.2828, 0.0000\n","Discard Action\n","Player 0 discards 5H.\n","\n","Player 0 has [[9H, TH, JH, QH, KH], 4S, AS, 2C, 4H, 2S] with 13 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 5H.\n","\n","Player 1 discards 4D.\n","\n","Player 1 has [[5S, 5H, 5D, 5C], [7S, 7D, 7C], AC, 3S, 4C] with 8 deadwood.\n","\n","Player 1 melds [[5S, 5H, 5D, 5C], [7S, 7D, 7C]] with 8 deadwood from [3S, AC, 4C].\n","\n","Player 0 melds [[9H, TH, JH, QH, KH]].\n","\n","Player 0 has 13 deadwood with [AS, 2S, 4S, 4H, 2C]\n","\n","Player 1 scores the deadwood difference of 5.\n","\n","Player\tScore\n","0\t80\n","1\t55\n","\n","Player 0 is dealt [KD, TS, 5D, 8S, JH, 2H, 9C, 4D, QD, 3D].\n","\n","Player 1 is dealt [5S, 7S, TH, 7H, 4S, 6H, AS, 2D, AH, 9H].\n","\n","Player 0 starts.\n","\n","The initial face up card is KH.\n","\n","Update States\n","Draw new card: 0.210971\n","Pickup from discard: 0.20767614\n","Player 0 declines KH.\n","\n","Player 1 declines KH.\n","\n","Draw from deck\n","Player 0 draws 8H.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], KD, TS, 8S, JH, 2H, 9C, QD, 8H]\n","Discard Pickup | D: KD | K: JH | 3\n","MAX:0.1815, 0.0000\n","Discard Action\n","Player 0 discards KD.\n","\n","Player 0 has [[3D, 4D, 5D], TS, 8S, JH, 2H, 9C, QD, 8H] with 57 deadwood.\n","\n","Draw from deck\n","Player 1 draws 9S.\n","\n","Player 1 discards TH.\n","\n","Player 1 has [5S, 7S, 7H, 4S, 6H, AS, 2D, AH, 9H, 9S] with 51 deadwood.\n","\n","Update States\n","Draw new card: 0.21197264\n","Pickup from discard: 0.2129256\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws TH.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], TS, 8S, JH, 2H, 9C, QD, 8H, TH]\n","Discard 9C | D: 9C | K: 9C | 53\n","MAX:0.2377, 0.0000\n","Discard Action\n","Player 0 discards 9C.\n","\n","Player 0 has [[3D, 4D, 5D], TS, 8S, JH, 2H, QD, 8H, TH] with 58 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 9C.\n","\n","Player 1 discards 7S.\n","\n","Player 1 has [[9S, 9H, 9C], 5S, 7H, 4S, 6H, AS, 2D, AH] with 26 deadwood.\n","\n","Update States\n","Draw new card: 0.22360437\n","Pickup from discard: 0.2152475\n","Draw from deck\n","Player 0 draws 7D.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], TS, 8S, JH, 2H, QD, 8H, TH, 7D]\n","Discard 8S | D: 8S | K: TH | 13\n","MAX:0.1410, 0.0000\n","Discard Action\n","Player 0 discards 8S.\n","\n","Player 0 has [[3D, 4D, 5D], TS, JH, 2H, QD, 8H, TH, 7D] with 57 deadwood.\n","\n","Draw from deck\n","Player 1 draws 8C.\n","\n","Player 1 discards 8C.\n","\n","Player 1 has [[9S, 9H, 9C], 5S, 7H, 4S, 6H, AS, 2D, AH] with 26 deadwood.\n","\n","Update States\n","Draw new card: 0.23031096\n","Pickup from discard: 0.2172583\n","Draw from deck\n","Player 0 draws 2S.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], TS, JH, 2H, QD, 8H, TH, 7D, 2S]\n","Discard TH | D: TH | K: QD | 28\n","MAX:0.2036, 0.0000\n","Discard Action\n","Player 0 discards TH.\n","\n","Player 0 has [[3D, 4D, 5D], TS, JH, 2H, QD, 8H, 7D, 2S] with 49 deadwood.\n","\n","Draw from deck\n","Player 1 draws QC.\n","\n","Player 1 discards QC.\n","\n","Player 1 has [[9S, 9H, 9C], 5S, 7H, 4S, 6H, AS, 2D, AH] with 26 deadwood.\n","\n","Update States\n","Draw new card: 0.23176602\n","Pickup from discard: 0.22189823\n","Draw from deck\n","Player 0 draws 5H.\n","\n","Update States\n","Current Hand: [[3D, 4D, 5D], TS, JH, 2H, QD, 8H, 7D, 2S, 5H]\n","Discard 8H | D: 8H | K: JH | 26\n","MAX:0.2125, 0.0000\n","Discard Action\n","Player 0 discards 8H.\n","\n","Player 0 has [[3D, 4D, 5D], TS, JH, 2H, QD, 7D, 2S, 5H] with 46 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws 8H.\n","\n","Player 1 discards 5S.\n","\n","Player 1 has [[6H, 7H, 8H], [9S, 9H, 9C], 4S, AS, 2D, AH] with 8 deadwood.\n","\n","Player 1 melds [[6H, 7H, 8H], [9S, 9H, 9C]] with 8 deadwood from [AS, 4S, AH, 2D].\n","\n","Player 0 melds [[3D, 4D, 5D]].\n","\n","Player 0 lays off 5H on [6H, 7H, 8H].\n","\n","Player 0 has 41 deadwood with [2S, TS, 2H, JH, 7D, QD]\n","\n","Player 1 scores the deadwood difference of 33.\n","\n","Player\tScore\n","0\t80\n","1\t88\n","\n","Player 0 is dealt [6H, TD, 3D, 9C, AS, 2C, KH, JC, 2H, QH].\n","\n","Player 1 is dealt [QD, 9D, JD, KD, 3S, 6D, TC, 5D, AD, 4H].\n","\n","Player 1 starts.\n","\n","The initial face up card is 8C.\n","\n","Player 1 declines 8C.\n","\n","Update States\n","Draw new card: 0.19998352\n","Pickup from discard: 0.20046969\n","drawFaceUp (Pickup discarded card)\n","Player 0 draws 8C.\n","\n","Update States\n","Current Hand: [6H, TD, 3D, 9C, AS, 2C, KH, JC, 2H, QH, 8C]\n","Discard Pickup | D: TD | K: TD | 3\n","MAX:0.1637, 0.0000\n","Discard Action\n","Player 0 discards TD.\n","\n","Player 0 has [6H, 3D, 9C, AS, 2C, KH, JC, 2H, QH, 8C] with 61 deadwood.\n","\n","drawFaceUp (Pickup discarded card)\n","Player 1 draws TD.\n","\n","Player 1 discards TC.\n","\n","Player 1 has [[9D, TD, JD, QD, KD], 3S, 6D, 5D, AD, 4H] with 19 deadwood.\n","\n","Update States\n","Draw new card: 0.21080936\n","Pickup from discard: 0.21001954\n","Draw from deck\n","Player 0 draws 6S.\n","\n","Update States\n","Current Hand: [6H, 3D, 9C, AS, 2C, KH, JC, 2H, QH, 8C, 6S]\n","Discard QH | D: QH | K: JC | 30\n","MAX:0.1923, 0.0000\n","Discard Action\n","Player 0 discards QH.\n","\n","Player 0 has [6H, 3D, 9C, AS, 2C, KH, JC, 2H, 8C, 6S] with 57 deadwood.\n","\n","Draw from deck\n","Player 1 draws 7D.\n","\n","Player 1 discards 4H.\n","\n","Player 1 has [[5D, 6D, 7D], [9D, TD, JD, QD, KD], 3S, AD] with 4 deadwood.\n","\n","Player 1 melds [[5D, 6D, 7D], [9D, TD, JD, QD, KD]] with 4 deadwood from [3S, AD].\n","\n","Player 0 melds [].\n","\n","Player 0 has 57 deadwood with [AS, 6S, 2H, 6H, KH, 3D, 2C, 8C, 9C, JC]\n","\n","Player 1 scores the deadwood difference of 53.\n","\n","Player\tScore\n","0\t80\n","1\t141\n","\n","Player 1 wins.\n","\n","Games Won: P0:0, P1:1.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qN33bkHlsWJh"},"source":["### Debugging"]},{"cell_type":"code","metadata":{"id":"vKQFUWa_pZrw"},"source":["a = GinRummyGame(agent0, agent1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"803xEEVGpcsv"},"source":["a.players"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DfbG3pgtuEy4"},"source":["numGames = 1000\r\n","agent0 = RandGinRummyPlayer()\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1dDypQcrsTlD"},"source":["### QNet"]},{"cell_type":"code","metadata":{"id":"Nl3wKveu9QIf"},"source":["numGames = 1\r\n","numGames = 2000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/TEST5/model_posttrain.pth', map_location=device)\r\n","mlp_layers=[520, 110]\r\n","# mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Afo_73eKMcpD"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/TEST9/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iqNHQ87hPdGo"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/TEST10/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZlMZQcFQiWD"},"source":["numGames = 100\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/TEST9/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","agent0.loadModel(qnet)\r\n","\r\n","agent1 = MLPGinRummyPlayer()\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/TEST10/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","agent1.loadModel(qnet)\r\n","\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NldHrWfOSTiR","executionInfo":{"status":"ok","timestamp":1612766041963,"user_tz":300,"elapsed":75109,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"14cb3b0b-6dad-4a07-99b8-eca50873c89b"},"source":["numGames = 1000\r\n","agent0 = MLPGinRummyPlayer()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","# model_name = 'all_states_all_actions_2hl_extra_knock_data_40K'\r\n","checkpoint = torch.load('models/dqn/selfplay/TEST2/model_posttrain.pth', map_location=device)\r\n","# mlp_layers=[520, 110]\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)\r\n","qnet.load_state_dict(checkpoint['dqn_q_estimator'])\r\n","\r\n","agent0.loadModel(qnet)\r\n","# print(model_name)\r\n","agent1 = SimpleGinRummyPlayer()\r\n","states, actions = [], []\r\n","# testAgents(agent0,agent1,numGames,verbose=True)\r\n","testAgents(agent0,agent1,numGames,verbose=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n","EstimatorNetwork(\n","  (fc_layers): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=260, out_features=520, bias=True)\n","    (2): Sigmoid()\n","    (3): Linear(in_features=520, out_features=520, bias=True)\n","    (4): Sigmoid()\n","    (5): Linear(in_features=520, out_features=110, bias=True)\n","    (6): Sigmoid()\n","    (7): Linear(in_features=110, out_features=110, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n","Game ...  0\n","Game ...  100\n","Game ...  200\n","Game ...  300\n","Game ...  400\n","Game ...  500\n","Game ...  600\n","Game ...  700\n","Game ...  800\n","Game ...  900\n","Games Won: P0:2, P1:998.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_TzQ2YoZly8b"},"source":["# Loading Agent Model Testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2wcepCrXrTt","executionInfo":{"status":"ok","timestamp":1610900268153,"user_tz":300,"elapsed":2776,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"fe734124-ad9b-47ae-fa7f-80c03bd9e707"},"source":["state = 'all'\r\n","action = 'all'\r\n","model_name = 'all_states_all_actions'\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state,action,model_name), map_location=device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MLP_base(\n","  (l1): Linear(in_features=260, out_features=520, bias=True)\n","  (l2): Linear(in_features=520, out_features=110, bias=True)\n","  (act_fnc): Sigmoid()\n","  (sfx): Softmax(dim=1)\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"cgMMeYPxgxz_"},"source":["state_s = 'apbd'\r\n","action_a = 'knock'\r\n","data_pth = '{}/data/{}/{}'.format(pth,state_s,action_a)\r\n","states = np.load('{}/s_2k.npy'.format(data_pth))\r\n","actions = np.load('{}/a_2k.npy'.format(data_pth))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UQXiRL0ZmWKs"},"source":["## Agent"]},{"cell_type":"code","metadata":{"id":"_eb_TcqLgm49"},"source":["agent = MLPGinRummyPlayer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGDoHYG9gri9","executionInfo":{"status":"ok","timestamp":1610900272191,"user_tz":300,"elapsed":333,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"87e78c01-ac9d-4d93-f651-dfa9aac09d84"},"source":["state_s = 'all'\r\n","action_a = 'all'\r\n","agent.loadModel(torch.load('{}/models/{}/{}/{}/model.pt'.format(pth,state_s,action_a,model_name), map_location=device))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CfeRVbDygt_m"},"source":["# input = np.expand_dims(states[0],axis=0)\r\n","# prob = agent.model(torch.from_numpy(input).type(torch.FloatTensor))\r\n","# action = prob.detach().numpy().reshape(-1)\r\n","# action[6:58]*np.zeros(52)\r\n","# # agent.model(np.expand_dims(,axis=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQ-N7W2O1BQg"},"source":["deck = Deck.getShuffle(random.randrange(10 ** 8))\r\n","hands = []\r\n","hands.extend([[], []])\r\n","hands[0] = []\r\n","hands[1] = []\r\n","for i in range(2 * GinRummyGame.HAND_SIZE):\r\n","    hands[i % 2] += [deck.pop()]\r\n","agent.startGame(0, 0, hands[0]);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IpdrZO2RlqjT","executionInfo":{"status":"ok","timestamp":1610900288796,"user_tz":300,"elapsed":269,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"a089ab29-b86f-4390-da40-a06f00f18e9b"},"source":["agent.updateStates(states[-1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Update States\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6AC2ZNehjDa","executionInfo":{"status":"ok","timestamp":1610901186207,"user_tz":300,"elapsed":347,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"2331f861-22b0-4d95-f576-2264e4bcf037"},"source":["c = Deck.strCardMap['AC']\r\n","agent.willDrawFaceUpCard(c)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Pickup from discard: 5.1510585e-10\n","Draw new card: 8.215045e-09\n","Draw Action\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k2969RH51HyG","executionInfo":{"status":"ok","timestamp":1610900291113,"user_tz":300,"elapsed":737,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"af5fa872-2ae9-4c7a-e069-f25c1f97e55e"},"source":["agent.playerNum"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103},"id":"ysY_xRb_lx0u","executionInfo":{"status":"ok","timestamp":1610900323625,"user_tz":300,"elapsed":316,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"ba53b30d-9993-45fa-9a16-44c22cb4783e"},"source":["i = 11\r\n","agent.updateStates(states[i])\r\n","agent.reportDraw(0, c)\r\n","agent.getDiscard()\r\n","all_classes[np.argmax(actions[i])]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Update States\n","6D 89\n","MAX:0.19825728237628937, 0.7989177107810974\n","Knock Action\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'6D'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6v532Z5EJF1E","executionInfo":{"status":"ok","timestamp":1610900429479,"user_tz":300,"elapsed":329,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"a4cee751-1e0f-4707-a489-7fda490cbb0e"},"source":["agent.model(torch.from_numpy(np.expand_dims(agent.state, axis=0)).type(torch.FloatTensor).to(device))\r\n","# state = np.expand_dims(self.state, axis=0)\r\n","# action = self.model(torch.from_numpy(state).type(torch.FloatTensor))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.5613e-08, 1.5413e-08, 5.1511e-10, 8.2150e-09, 2.9999e-08, 1.2821e-09,\n","         5.5631e-09, 2.5155e-08, 2.7546e-06, 4.5472e-07, 1.0434e-03, 8.9934e-17,\n","         3.4545e-15, 7.6638e-20, 1.2097e-23, 9.0395e-21, 3.3336e-16, 1.2249e-17,\n","         1.4306e-13, 1.5554e-08, 5.1269e-08, 1.0969e-08, 7.8594e-07, 7.9670e-12,\n","         4.4021e-18, 5.8035e-19, 3.2541e-18, 1.2281e-18, 1.5415e-15, 2.9808e-19,\n","         8.6931e-15, 8.5212e-14, 1.4021e-08, 1.0776e-08, 1.0269e-08, 2.9233e-09,\n","         6.7081e-11, 1.9826e-01, 8.6911e-15, 1.6958e-20, 6.8392e-18, 3.8210e-16,\n","         1.5054e-19, 4.5664e-16, 3.2462e-10, 1.5062e-07, 2.1884e-08, 1.1281e-08,\n","         1.1448e-04, 5.9201e-12, 1.1257e-13, 1.4764e-16, 3.0289e-24, 8.3574e-19,\n","         7.6238e-17, 3.5383e-14, 8.8625e-20, 1.4193e-20, 2.3093e-07, 1.5752e-07,\n","         4.3524e-05, 1.8425e-06, 1.4934e-03, 3.1863e-11, 4.4363e-08, 1.9563e-07,\n","         4.9013e-06, 1.5853e-08, 1.0693e-06, 1.3684e-08, 8.0732e-07, 1.6183e-08,\n","         2.2061e-05, 9.4124e-08, 4.5300e-10, 2.2975e-09, 1.6456e-13, 1.1721e-06,\n","         1.2828e-06, 2.7124e-07, 2.2376e-08, 1.5255e-08, 4.0729e-08, 1.1123e-08,\n","         7.2174e-08, 2.9650e-06, 1.6772e-06, 7.7064e-05, 4.1690e-17, 7.9892e-01,\n","         1.0043e-14, 1.5928e-07, 1.2464e-06, 1.6597e-08, 3.0182e-08, 1.3622e-06,\n","         8.1668e-07, 2.5266e-06, 1.7661e-07, 3.7193e-08, 2.2941e-07, 6.6019e-07,\n","         2.0783e-13, 2.1818e-06, 1.7139e-08, 1.1502e-08, 1.9091e-08, 1.4139e-07,\n","         5.2852e-08, 1.9630e-08]], grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"LSGRQrlB8NUn"},"source":["## QNet"]},{"cell_type":"code","metadata":{"id":"Vm47cXB90CI6"},"source":["class EstimatorNetwork(nn.Module):\r\n","    ''' The function approximation network for Estimator\r\n","        It is just a series of sigmoid layers. All in/out are torch.tensor\r\n","        (OLD) It is just a series of tanh layers. All in/out are torch.tensor\r\n","    '''\r\n","\r\n","    def __init__(self, mlp_layers=None, batch_norm=False):\r\n","        ''' Initialize the Q network\r\n","        Args:\r\n","            action_num (int): number of legal actions\r\n","            state_shape (list): shape of state tensor\r\n","            mlp_layers (list): output size of each fc layer\r\n","        '''\r\n","        super(EstimatorNetwork, self).__init__()\r\n","\r\n","        self.action_num = 110\r\n","        self.state_shape = 260\r\n","        self.mlp_layers = mlp_layers\r\n","        self.batch_norm = batch_norm\r\n","\r\n","        # build the Q network\r\n","        layer_dims = [np.prod(self.state_shape)] + self.mlp_layers\r\n","        fc = [nn.Flatten()]\r\n","        if batch_norm:\r\n","            fc.append(nn.BatchNorm1d(layer_dims[0]))\r\n","        for i in range(len(layer_dims)-1):\r\n","            fc.append(nn.Linear(layer_dims[i], layer_dims[i+1], bias=True))\r\n","            fc.append(nn.Sigmoid())\r\n","        fc.append(nn.Linear(layer_dims[-1], self.action_num, bias=True))\r\n","        fc.append(nn.Softmax(dim=1))\r\n","        self.fc_layers = nn.Sequential(*fc)\r\n","\r\n","    def forward(self, s):\r\n","        ''' Predict action values\r\n","        Args:\r\n","            s  (Tensor): (batch, state_shape)\r\n","        '''\r\n","        return self.fc_layers(s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIudaaMe0X1_"},"source":["state_shape = 260\r\n","action_num = 110\r\n","mlp_layers=[520, 520, 110]\r\n","batch_norm = False\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","qnet = EstimatorNetwork(mlp_layers, batch_norm)\r\n","qnet = qnet.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xo3rbpxH42Gz"},"source":["checkpoint = torch.load('models/dqn/TEST4/model_posttrain.pth', map_location=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgHKA0AZ6jfJ","executionInfo":{"status":"ok","timestamp":1611031143413,"user_tz":300,"elapsed":270,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"17a0cc15-f99e-4eb5-c8f9-8ad797add92c"},"source":["qnet.load_state_dict(checkpoint['dqn_q_estimator'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRTEjXPl8eQA","executionInfo":{"status":"ok","timestamp":1611031394344,"user_tz":300,"elapsed":235,"user":{"displayName":"Calvin Tan","photoUrl":"","userId":"12200632467998545940"}},"outputId":"584a43b2-ff52-4260-d3f1-a2c2caf2361b"},"source":["qnet(torch.from_numpy(np.expand_dims(states[-1], axis=0)).type(torch.FloatTensor).to(device))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[7.2249e-09, 2.2420e-10, 9.7314e-16, 4.7728e-15, 1.2340e-20, 6.8497e-10,\n","         5.7679e-02, 3.3210e-02, 1.1054e-01, 2.0988e-02, 1.7701e-02, 6.7780e-03,\n","         1.2067e-02, 4.0160e-03, 2.8021e-04, 3.1774e-03, 5.9243e-03, 1.0486e-02,\n","         3.3039e-03, 2.7109e-02, 3.3363e-02, 4.7771e-02, 1.8946e-02, 2.7230e-02,\n","         9.2067e-03, 3.6598e-03, 2.2502e-03, 9.3831e-03, 7.2180e-03, 2.3893e-03,\n","         2.6061e-03, 6.0732e-03, 2.8625e-02, 4.8642e-02, 3.8667e-02, 3.7032e-02,\n","         1.3078e-02, 9.2480e-02, 9.3268e-04, 1.0151e-03, 4.8095e-03, 1.0041e-03,\n","         5.6105e-03, 2.7269e-03, 3.4772e-03, 3.9008e-02, 4.8259e-02, 3.4264e-02,\n","         4.3172e-02, 2.0446e-02, 1.8986e-02, 2.4711e-03, 7.2034e-03, 1.0481e-03,\n","         1.0171e-02, 4.2704e-03, 6.3416e-04, 8.6092e-03, 4.0611e-10, 3.4673e-10,\n","         1.6277e-10, 1.9494e-10, 3.1402e-10, 1.9318e-10, 2.3830e-10, 1.1181e-10,\n","         1.1989e-10, 1.7327e-10, 2.8693e-10, 8.1085e-11, 1.4320e-10, 9.0052e-11,\n","         2.9499e-10, 5.1579e-10, 4.1876e-10, 1.9062e-10, 9.0127e-11, 4.0147e-10,\n","         1.6223e-10, 9.0625e-11, 1.6091e-10, 1.4370e-10, 1.7994e-10, 1.3156e-10,\n","         6.4692e-10, 1.4115e-10, 1.7668e-10, 1.5604e-10, 1.7981e-10, 3.0449e-10,\n","         2.3876e-10, 4.4373e-10, 2.7965e-10, 8.9287e-11, 2.3358e-10, 2.2818e-10,\n","         1.5378e-10, 5.6208e-11, 1.0548e-10, 1.5618e-10, 2.6403e-10, 1.7098e-10,\n","         3.5305e-10, 2.2007e-10, 1.3393e-10, 4.6836e-10, 4.1738e-10, 2.1173e-10,\n","         3.6913e-10, 1.5075e-10]], grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":27}]}]}