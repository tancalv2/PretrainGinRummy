{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testAgents_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ssj566eQMxKZ",
        "qfjPoV0kM1NH",
        "o1K0a747bja2",
        "WswUyFq7MzBj",
        "Bh93Ni3UszBL",
        "u-hik2PLM6C2",
        "11qEEpVcXSun",
        "TUoy-A6cBlkH",
        "1gKilTmVjLg-",
        "2QpYtl1sjLhQ",
        "sN9p6lpjjLhI",
        "LxXywCoKjLhL",
        "APcGxXD0jLhP",
        "vLdilK_tjLhO",
        "7jGS7wLa4bX0",
        "8axG9YHv4bYN",
        "Y1-rBbew4bYG",
        "53sUQPHc4bYI",
        "HusFzuo04bYM",
        "leyXsZsX4bYL",
        "0eLOp_Gz-pDZ",
        "Y6pa581e-pDs",
        "yRtJWR2v-pDn",
        "TPw6P7X4-pDp",
        "wLlWPw9c-pDs",
        "Sxjep7l2-pDr",
        "EGjNvegP-waN",
        "KeRoI7e9-waQ",
        "T1CLcH07-waN",
        "hi5ccbHC-waO",
        "EIq4dPEE-waP",
        "Tojla7Ln-waP",
        "sYsCw-B6V-3B",
        "QUYnTbcLV-3Q",
        "xu_f-zYbV-3H",
        "UcYjYx_7V-3J",
        "Mma4HR8cV-3O",
        "4yiI4UBgV-3L",
        "x_KgHvEyZ6c7",
        "SPk9CheMdxWF",
        "6i8jIgy3Z6c7",
        "MKjskB2AZ6c8",
        "CAosuwC3cSni",
        "UjoMoEHEb-Fc",
        "lizD8Akdu4HT",
        "EQlG1x9Bu4Hr",
        "AjaIOs-vu4Hg",
        "UYMkzY03u4Hj",
        "fX9NCTPsu4Ho",
        "LKHExLfgu4Hn",
        "Sg4cLKYAdKuN",
        "Df4AAC1vdISG",
        "jIAWaWK-dISQ",
        "xZyzEKiydISJ",
        "wtUslzBGdISK",
        "nlZFUdh5dISO",
        "IvwAvIWwdISO",
        "CN6jHDX8dmtx",
        "OS729IDjdmt6",
        "nGIH-5Ymdmt1",
        "rCgbKjWBdmt3",
        "i6rt7HU5dmt6",
        "K-8SiYnydmt5",
        "zd10xR0FdpXl",
        "i4GMpOGsdpXq",
        "ue75G8KedpXm",
        "cF2TogaudpXm",
        "5HpaqJGidpXp",
        "N-V9LmmVdpXo",
        "-NQcsIVJdsKS",
        "OUDAbH-3dsKZ",
        "vMyCKYAedsKU",
        "hbCTIt0WdsKV",
        "Lw7LR36adsKY",
        "iwCBx15-dsKY",
        "EYfcSEBPdu4k",
        "ZcL_DgaNdu4o",
        "zEGaOO-5du4l",
        "8sjsla8Bdu4m",
        "IDh-L11Xdu4n",
        "fs3cRRYldu4n",
        "Ia1PRiONFseZ",
        "yGTOO_j_Fser",
        "5QfgYfspFse0",
        "l-DhtUjgFses",
        "GltUq_onFseu",
        "CeU534pxFsez",
        "dsFNdt58Fsey",
        "eC0X7IVEF8oP",
        "Ubd-MnXkF8pE",
        "twWy_D8wF8oV",
        "_NnLa05_F8oi",
        "f8d5RebwF8pD",
        "wwnYDexnF8o_",
        "T3cW_MEqGBWp",
        "-rnOjM2KGBW-",
        "KNqqT0qdGBW5",
        "P_x95SEXGBW6",
        "q5CGpiJkGBW9",
        "oZHUaYnNGBW9",
        "lTlctAsxUHys",
        "Hoq2Oxui_QTF",
        "YqkF9ixG_QTX",
        "F650TVBz_QTS",
        "cDQ7vZu4_QTT",
        "i_lPivrH_QTW",
        "bjwJwgEW_QTV",
        "5LkPMQvnVNz1",
        "6eYiF5zlVNz8",
        "6FxWLRw8VNz2",
        "OzXvyysOVNz3",
        "syFOnf-pVNz7",
        "1YdJeBR6VNz5",
        "9_35xcCHVWMO",
        "-MQcSzB_VWMT",
        "ap6ffROvVWMP",
        "nNHVUaNYVWMQ",
        "s1J1CctdVWMS",
        "Erx-_883VWMS",
        "DL5uNyJFVYp_",
        "36sLMnaiVYqC",
        "UwT6-M-VVYp_",
        "AvwQhKx2VYqA",
        "a0Ut9uG2VYqC",
        "GYCDI2mAVYqB",
        "tMXoADH3VbT0",
        "KjbmJupwVbT5",
        "p0M4r7USVbT1",
        "7Be-dhfnVbT2",
        "dMmy95g3VbT4",
        "teHcYVTuVbT4"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RubzqOlEW1H2",
        "outputId": "81846cb9-7268-4746-b76f-39b2082099df"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssj566eQMxKZ"
      },
      "source": [
        "# Gin Rummy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPCni-gdFFeE"
      },
      "source": [
        "pth = '/content/drive/MyDrive/Colab Notebooks/Thesis'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Hs2guSyLy_"
      },
      "source": [
        "all_classes = ['SP0','SP1','Draw','Pickup','DH','GIN',\n",
        "               'AS', '2S', '3S', '4S', '5S', '6S', '7S', '8S', '9S', 'TS', 'JS', 'QS', 'KS',\n",
        "               'AH', '2H', '3H', '4H', '5H', '6H', '7H', '8H', '9H', 'TH', 'JH', 'QH', 'KH',\n",
        "               'AD', '2D', '3D', '4D', '5D', '6D', '7D', '8D', '9D', 'TD', 'JD', 'QD', 'KD',\n",
        "               'AC', '2C', '3C', '4C', '5C', '6C', '7C', '8C', '9C', 'TC', 'JC', 'QC', 'KC',\n",
        "               'AS', '2S', '3S', '4S', '5S', '6S', '7S', '8S', '9S', 'TS', 'JS', 'QS', 'KS',\n",
        "               'AH', '2H', '3H', '4H', '5H', '6H', '7H', '8H', '9H', 'TH', 'JH', 'QH', 'KH',\n",
        "               'AD', '2D', '3D', '4D', '5D', '6D', '7D', '8D', '9D', 'TD', 'JD', 'QD', 'KD',\n",
        "               'AC', '2C', '3C', '4C', '5C', '6C', '7C', '8C', '9C', 'TC', 'JC', 'QC', 'KC']\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfjPoV0kM1NH"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZZ3FbZfWmdn",
        "outputId": "5f8935f6-8811-4812-e744-ec605c362e84"
      },
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# The following code was originally written by Todd Neller in Java.\n",
        "# It was translated into Python by Anthony Hein.\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# A class for modeling a game of Gin Rummy\n",
        "# @author Todd W. Neller\n",
        "# @version 1.0\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# Copyright (C) 2020 Todd Neller\n",
        "#\n",
        "# This program is free software; you can redistribute it and/or\n",
        "# modify it under the terms of the GNU General Public License\n",
        "# as published by the Free Software Foundation; either version 2\n",
        "# of the License, or (at your option) any later version.\n",
        "#\n",
        "# This program is distributed in the hope that it will be useful,\n",
        "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "# GNU General Public License for more details.\n",
        "#\n",
        "# Information about the GNU General Public License is available online at:\n",
        "#   http://www.gnu.org/licenses/\n",
        "# To receive a copy of the GNU General Public License, write to the Free\n",
        "# Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n",
        "# 02111-1307, USA.\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "\n",
        "%cd /content/drive/My Drive/Colab Notebooks/Thesis/GinRummy\n",
        "\n",
        "from Deck import Deck\n",
        "from GinRummyUtil import GinRummyUtil\n",
        "from SimpleGinRummyPlayer import SimpleGinRummyPlayer\n",
        "\n",
        "%cd /content/drive/My Drive/Colab Notebooks/Thesis/SupervisedLearning\n",
        "\n",
        "from models import *\n",
        "\n",
        "%cd /content/drive/My Drive/Colab Notebooks/Thesis\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "# TRACKING\n",
        "# Plane (5x52)      Feature\n",
        "# 0\t currHand       the cards in current player's hand\n",
        "# 1\t topCard        the top card of the discard pile\n",
        "# 2\t deadCard       the dead cards: cards in discard pile (excluding the top card)\n",
        "# 3\t oppCard        opponent known cards: cards picked up from discard pile, but not discarded\n",
        "# 4\t unknownCard    the unknown cards: cards in stockpile or in opponent hand (but not known)\n",
        "\n",
        "# Action ID         Action\n",
        "# 0\t                score_player_0_action\n",
        "# 1\t                score_player_1_action\n",
        "# 2\t                draw_card_action\n",
        "# 3\t                pick_up_discard_action\n",
        "# 4\t                declare_dead_hand_action\n",
        "# 5\t                gin_action\n",
        "# 6 - 57\t        discard_action\n",
        "# 58 - 109\t        knock_action\n",
        "\n",
        "# Knock_bin\n",
        "# Action ID         Action\n",
        "# 0\t                No Knock\n",
        "# 1\t                Knock\n",
        "\n",
        "def one_hot(cards):\n",
        "    ret = np.zeros(52)\n",
        "    for card in cards:\n",
        "        ret[card.getId()] = 1\n",
        "    return ret\n",
        "\n",
        "def un_one_hot(arr):\n",
        "    rankNames = [\"A\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"T\", \"J\", \"Q\", \"K\"]\n",
        "    suitNames = ['S', 'H', 'D', 'C']\n",
        "    ret = []\n",
        "    for i in range(len(arr)):\n",
        "        if arr[i] != 0:\n",
        "            ret.append(rankNames[i%13] + suitNames[i//13])\n",
        "    return ret\n",
        "\n",
        "#-------------------------------------------------------------------------------"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Thesis/GinRummy\n",
            "/content/drive/My Drive/Colab Notebooks/Thesis/SupervisedLearning\n",
            "/content/drive/My Drive/Colab Notebooks/Thesis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1K0a747bja2"
      },
      "source": [
        "## MLPGinRummyPlayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxJaArOfbmUM"
      },
      "source": [
        "# -------------------------------------------------------------------------------\n",
        "#  MLPGinRummyPlayer\n",
        "#\n",
        "#  This estimation will be calculated using a Multilayer Percepton trained on the\n",
        "#  SimpleGinRummyPlayer written\n",
        "#  by Calvin Tan.\n",
        "#\n",
        "#  @author Calvin Tan\n",
        "#  @version 1.0\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# The following code was originally written by Todd Neller in Java.\n",
        "# It was translated into Python by May Jiang.\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# Copyright (C) 2020 Todd Neller\n",
        "# This program is free software; you can redistribute it and/or\n",
        "# modify it under the terms of the GNU General Public License\n",
        "# as published by the Free Software Foundation; either version 2\n",
        "# of the License, or (at your option) any later version.\n",
        "# This program is distributed in the hope that it will be useful,\n",
        "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "# GNU General Public License for more details.\n",
        "# Information about the GNU General Public License is available online at:\n",
        "#   http://www.gnu.org/licenses/\n",
        "# To receive a copy of the GNU General Public License, write to the Free\n",
        "# Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n",
        "# 02111-1307, USA.\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "from typing import List, TypeVar\n",
        "from random import randint\n",
        "from GinRummyUtil import GinRummyUtil\n",
        "from GinRummyPlayer import GinRummyPlayer\n",
        "\n",
        "# Import MLP Models\n",
        "# from SupervisedLearning.models import *\n",
        "\n",
        "Card = TypeVar('Card')\n",
        "\n",
        "class MLPGinRummyPlayer(GinRummyPlayer):\n",
        "\n",
        "    def loadModel(self, model_pt):\n",
        "        print('Load Model')\n",
        "        self.model = model_pt\n",
        "\n",
        "    def setVerbose(self, verbose):\n",
        "        self.playVerbose = verbose\n",
        "\n",
        "    def updateStates(self, states):\n",
        "        if self.playVerbose:\n",
        "            print('Update States')\n",
        "        self.state = states\n",
        "\n",
        "    def knockAction(self) -> bool:\n",
        "        return self.knock\n",
        "\n",
        "    # Inform player of 0-based player number (0/1), starting player number (0/1), and dealt cards\n",
        "    def startGame(self, playerNum: int, startingPlayerNum: int, cards: List[Card]) -> None:\n",
        "        self.playerNum = playerNum\n",
        "        self.startingPlayerNum = startingPlayerNum\n",
        "        self.cards = list(cards)\n",
        "        self.opponentKnocked = False\n",
        "        self.drawDiscardBitstrings = [] # long[], or List[int]\n",
        "        self.faceUpCard = None\n",
        "        self.faceUpCardBool = False\n",
        "        self.drawnCard = None\n",
        "        self.state = None\n",
        "        self.knock = False\n",
        "        self.playVerbose = False\n",
        "\n",
        "    # Return whether or not player will draw the given face-up card on the draw pile.\n",
        "    def willDrawFaceUpCard(self, card: Card) -> bool:\n",
        "        self.faceUpCard = card\n",
        "        # BPBD, either draw(2)->False or pickup(3)->True\n",
        "        state = np.expand_dims(self.state, axis=0)\n",
        "        state = torch.from_numpy(state).type(torch.FloatTensor).to(device)\n",
        "        action = self.model(state)\n",
        "        action = action.detach().numpy().reshape(-1)\n",
        "        if self.playVerbose:\n",
        "            print('Draw new card:', action[2])\n",
        "            print('Pickup from discard:', action[3])\n",
        "        if action[3] > action[2]:\n",
        "            # print('Pickup Discard Action')\n",
        "            self.faceUpCardBool = True\n",
        "            return True\n",
        "        # print('Draw from Deck Action')\n",
        "        self.faceUpCardBool = False\n",
        "        return False\n",
        "\n",
        "    # Report that the given player has drawn a given card and, if known, what the card is.\n",
        "    # If the card is unknown because it is drawn from the face-down draw pile, the drawnCard is null.\n",
        "    # Note that a player that returns false for willDrawFaceUpCard will learn of their face-down draw from this method.\n",
        "    def reportDraw(self, playerNum: int, drawnCard: Card) -> None:\n",
        "        # Ignore other player draws.  Add to cards if playerNum is this player.\n",
        "        if playerNum == self.playerNum:\n",
        "            self.cards.append(drawnCard)\n",
        "            self.drawnCard = drawnCard\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def getDiscard(self) -> Card:\n",
        "    #     # Discard a random card (not just drawn face up) leaving minimal deadwood points.\n",
        "    #     minDeadwood = float('inf')\n",
        "    #     candidateCards = []\n",
        "    #     for card in self.cards:\n",
        "    #         # Cannot draw and discard face up card.\n",
        "    #         if card == self.drawnCard and self.drawnCard == self.faceUpCard:\n",
        "    #         # if card == self.drawnCard and self.faceUpCard:\n",
        "    #             continue\n",
        "    #         # Disallow repeat of draw and discard.\n",
        "    #         drawDiscard = [self.drawnCard, card]\n",
        "    #         if GinRummyUtil.cardsToBitstring(drawDiscard) in self.drawDiscardBitstrings:\n",
        "    #             continue\n",
        "\n",
        "    #         remainingCards = list(self.cards)\n",
        "    #         remainingCards.remove(card)\n",
        "    #         bestMeldSets = GinRummyUtil.cardsToBestMeldSets(remainingCards)\n",
        "    #         deadwood = GinRummyUtil.getDeadwoodPoints3(remainingCards) if len(bestMeldSets) == 0 \\\n",
        "    #             else GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], remainingCards)\n",
        "    #         if deadwood <= minDeadwood:\n",
        "    #             if deadwood < minDeadwood:\n",
        "    #                 minDeadwood = deadwood\n",
        "    #                 candidateCards.clear()\n",
        "    #             candidateCards.append(card)\n",
        "    #     # Prevent future repeat of draw, discard pair.\n",
        "    #     discard = candidateCards[randint(0, len(candidateCards)-1)]\n",
        "    #     drawDiscard = [self.drawnCard, discard]\n",
        "    #     self.drawDiscardBitstrings.append(GinRummyUtil.cardsToBitstring(drawDiscard))\n",
        "    #     return discard\n",
        "\n",
        "    # Get the player's discarded card.  If you took the top card from the discard pile,\n",
        "    # you must discard a different card.\n",
        "    # If this is not a card in the player's possession, the player forfeits the game.\n",
        "    # @return the player's chosen card for discarding\n",
        "    def getDiscard(self) -> Card:\n",
        "        # APBD, either either discard or knock...\n",
        "        # determine the allowable actions (which cards can be discarded/knocked on)\n",
        "        currHand = np.array(self.state[0:52])\n",
        "        knockCards = np.array(self.state[0:52])\n",
        "        # if self.playVerbose:\n",
        "        #     print('Current Hand:', un_one_hot(currHand))\n",
        "        # disallow discarding PickUp FaceUp/Discarded Card\n",
        "        if self.faceUpCardBool:\n",
        "        # if self.drawnCard == self.faceUpCard:\n",
        "            currHand[self.drawnCard.getId()] = 0\n",
        "            knockCards[self.drawnCard.getId()] = 0\n",
        "        \n",
        "        # prune illegal knock actions\n",
        "        cardIndex = np.where(knockCards == 1)[0]\n",
        "        for c in cardIndex:\n",
        "            remainingCards = list(self.cards)\n",
        "            remainingCards.remove(Deck.getCard(c))\n",
        "            bestMeldSets = GinRummyUtil.cardsToBestMeldSets(remainingCards)\n",
        "            deadwood = GinRummyUtil.getDeadwoodPoints3(remainingCards) if len(bestMeldSets) == 0 \\\n",
        "                else GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], remainingCards)\n",
        "            if deadwood > 10:\n",
        "                knockCards[c] = 0\n",
        "\n",
        "        state = np.expand_dims(self.state, axis=0)\n",
        "        state = torch.from_numpy(state).type(torch.FloatTensor).to(device)\n",
        "        action = self.model(state)\n",
        "        action = action.detach().numpy().reshape(-1)\n",
        "\n",
        "        discardMax = max(currHand * action[6:58])\n",
        "        # knockMax = max(currHand * action[58:110])\n",
        "        knockMax = max(knockCards * action[58:110])\n",
        "\n",
        "        if self.playVerbose:\n",
        "            unmeldedCards = self.cards.copy()\n",
        "            bestMelds = GinRummyUtil.cardsToBestMeldSets(unmeldedCards)\n",
        "            if len(bestMelds) > 0:\n",
        "                melds = bestMelds[0]\n",
        "                for meld in melds:\n",
        "                    for card in meld:\n",
        "                        unmeldedCards.remove(card)\n",
        "                melds.extend(unmeldedCards)\n",
        "            else:\n",
        "                melds = unmeldedCards\n",
        "            print('Current Hand:', melds)\n",
        "            if np.argmax(action) > 58:\n",
        "                # print('Knock', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(currHand * action[58:])), '|', np.argmax(action))\n",
        "                print('Knock', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(knockCards * action[58:])), '|', np.argmax(action))\n",
        "            else:\n",
        "                # print('Discard', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(currHand * action[58:])), '|', np.argmax(action))\n",
        "                print('Discard', all_classes[np.argmax(action)], '| D:', Deck.getCard(np.argmax(currHand * action[6:58])), '| K:', Deck.getCard(np.argmax(knockCards * action[58:])), '|', np.argmax(action))\n",
        "            print('MAX:{:.4f}, {:.4f}'.format(discardMax, knockMax))\n",
        "\n",
        "        if discardMax > knockMax or int(sum(knockCards) == 0):\n",
        "            if self.playVerbose:\n",
        "                print('Discard Action')\n",
        "            self.knock = False\n",
        "            return Deck.getCard(np.argmax(currHand * action[6:58]))\n",
        "        else:\n",
        "            if self.playVerbose:\n",
        "                print('Knock Action')\n",
        "            self.knock = True\n",
        "            # return Deck.getCard(np.argmax(currHand * action[58:]))\n",
        "            return Deck.getCard(np.argmax(knockCards * action[58:]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Report that the given player has discarded a given card.\n",
        "    def reportDiscard(self, playerNum: int, discardedCard: Card) -> None:\n",
        "        # Ignore other player discards.  Remove from cards if playerNum is this player.\n",
        "        if playerNum == self.playerNum:\n",
        "            self.cards.remove(discardedCard)\n",
        "\n",
        "    # At the end of each turn, this method is called and the player that cannot (or will not) end the round will return a null value.\n",
        "    # However, the first player to \"knock\" (that is, end the round), and then their opponent, will return an ArrayList of ArrayLists of melded cards.\n",
        "    # All other cards are counted as \"deadwood\", unless they can be laid off (added to) the knocking player's melds.\n",
        "    # When final melds have been reported for the other player, a player should return their final melds for the round.\n",
        "    # @return null if continuing play and opponent hasn't melded, or an ArrayList of ArrayLists of melded cards.\n",
        "    def getFinalMelds(self) -> List[List[Card]]:\n",
        "        # Check if deadwood of maximal meld is low enough to go out.\n",
        "        bestMeldSets = GinRummyUtil.cardsToBestMeldSets(self.cards) # List[List[List[Card]]]\n",
        "        if not self.opponentKnocked and (len(bestMeldSets) == 0 or \\\n",
        "            GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], self.cards) > \\\n",
        "            GinRummyUtil.MAX_DEADWOOD):\n",
        "            return None\n",
        "        if len(bestMeldSets) == 0:\n",
        "            return []\n",
        "        return bestMeldSets[randint(0, len(bestMeldSets)-1)]\n",
        "\n",
        "    # When an player has ended play and formed melds, the melds (and deadwood) are reported to both players.\n",
        "    def reportFinalMelds(self, playerNum: int, melds: List[List[Card]]) -> None:\n",
        "        # Melds ignored by simple player, but could affect which melds to make for complex player.\n",
        "        if playerNum != self.playerNum:\n",
        "            self.opponentKnocked = True\n",
        "\n",
        "    # Report current player scores, indexed by 0-based player number.\n",
        "    def reportScores(self, scores: List[int]) -> None:\n",
        "        # Ignored by simple player, but could affect strategy of more complex player.\n",
        "        return\n",
        "\n",
        "    # Report layoff actions.\n",
        "    def reportLayoff(self, playerNum: int, layoffCard: Card, opponentMeld: List[Card]) -> None:\n",
        "        # Ignored by simple player, but could affect strategy of more complex player.\n",
        "        return\n",
        "\n",
        "    # Report the final hands of players.\n",
        "    def reportFinalHand(self, playerNum: int, hand: List[Card]) -> None:\n",
        "        # Ignored by simple player, but could affect strategy of more complex player.\n",
        "        return"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WswUyFq7MzBj"
      },
      "source": [
        "### Estimator Network & load checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVSCfSTL9KAL"
      },
      "source": [
        "class EstimatorNetwork(nn.Module):\n",
        "    ''' The function approximation network for Estimator\n",
        "        It is just a series of sigmoid layers. All in/out are torch.tensor\n",
        "        (OLD) It is just a series of tanh layers. All in/out are torch.tensor\n",
        "    '''\n",
        "\n",
        "    def __init__(self, mlp_layers=None, batch_norm=False, knock_layer=False, top_layer=True):\n",
        "        ''' Initialize the Q network\n",
        "        Args:\n",
        "            action_num (int): number of legal actions\n",
        "            state_shape (list): shape of state tensor\n",
        "            mlp_layers (list): output size of each fc layer\n",
        "        '''\n",
        "        super(EstimatorNetwork, self).__init__()\n",
        "\n",
        "        self.action_num = 110\n",
        "        self.state_shape = 260\n",
        "        self.mlp_layers = mlp_layers\n",
        "        self.batch_norm = batch_norm\n",
        "        self.knock_layer = knock_layer\n",
        "        self.top_layer = top_layer\n",
        "\n",
        "        # build the Q network\n",
        "        layer_dims = [np.prod(self.state_shape)] + self.mlp_layers\n",
        "        fc = [nn.Flatten()]\n",
        "        if batch_norm:\n",
        "            fc.append(nn.BatchNorm1d(layer_dims[0]))\n",
        "        for i in range(len(layer_dims)-1):\n",
        "            fc.append(nn.Linear(layer_dims[i], layer_dims[i+1], bias=True))\n",
        "            fc.append(nn.Sigmoid())\n",
        "        # add top layer onto Q-network\n",
        "        if self.top_layer:\n",
        "            fc.append(nn.Linear(layer_dims[-1], self.action_num, bias=True))\n",
        "            fc.append(nn.Softmax(dim=1))\n",
        "        else:\n",
        "            # remove last sigmoid layer and append softmax layer\n",
        "            fc.pop()\n",
        "            fc.append(nn.Softmax(dim=1))\n",
        "\n",
        "        # add knock layer to be an additional layer, which will manually be set identity\n",
        "        # with bias on the knock actions (58-110)\n",
        "        # required to be frozen!!!\n",
        "        if self.knock_layer:\n",
        "            fc.append(nn.Linear(self.action_num, self.action_num, bias=True))\n",
        "            fc.append(nn.Softmax(dim=1))\n",
        "        self.fc_layers = nn.Sequential(*fc)\n",
        "        \n",
        "    def forward(self, s):\n",
        "        ''' Predict action values\n",
        "        Args:\n",
        "            s  (Tensor): (batch, state_shape)\n",
        "        '''\n",
        "        return self.fc_layers(s)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUFsqPpeD1xq"
      },
      "source": [
        "def load_checkpoint(checkpoint):\n",
        "    pretrained_dict = {}\n",
        "    if knock_layer:\n",
        "        pretrained_dict = checkpoint\n",
        "    else:\n",
        "        model_dict = checkpoint\n",
        "        # check if there is batch norm layer\n",
        "        if batch_norm:\n",
        "            b_layer = 1 \n",
        "            pretrained_dict['fc_layers.1.weight'] = model_dict['fc_layers.1.weight']\n",
        "            pretrained_dict['fc_layers.1.bias'] = model_dict['fc_layers.1.bias']\n",
        "            pretrained_dict['fc_layers.1.running_mean'] = model_dict['fc_layers.1.running_mean']\n",
        "            pretrained_dict['fc_layers.1.running_var'] = model_dict['fc_layers.1.running_var']\n",
        "            pretrained_dict['fc_layers.1.num_batches_tracked'] = model_dict['fc_layers.1.num_batches_tracked']\n",
        "        else:\n",
        "            b_layer = 0\n",
        "        curr_layer = 1 + b_layer\n",
        "        for i in range(len(mlp_layers)):\n",
        "            pretrained_dict['fc_layers.{}.weight'.format(curr_layer)] = model_dict['fc_layers.{}.weight'.format(curr_layer)]\n",
        "            pretrained_dict['fc_layers.{}.bias'.format(curr_layer)] = model_dict['fc_layers.{}.bias'.format(curr_layer)]\n",
        "            curr_layer += 2\n",
        "        if top_layer:\n",
        "            pretrained_dict['fc_layers.{}.weight'.format(curr_layer)] = model_dict['fc_layers.{}.weight'.format(curr_layer)]\n",
        "            pretrained_dict['fc_layers.{}.bias'.format(curr_layer)] = model_dict['fc_layers.{}.bias'.format(curr_layer)]\n",
        "    return pretrained_dict"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh93Ni3UszBL"
      },
      "source": [
        "## RandGinRummyPlayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNu79KMoszBN"
      },
      "source": [
        "# -------------------------------------------------------------------------------\n",
        "#  RandGinRummyPlayer\n",
        "#\n",
        "#  This estimation will be calculated using a Multilayer Percepton trained on the\n",
        "#  SimpleGinRummyPlayer written\n",
        "#  by Calvin Tan.\n",
        "#\n",
        "#  @author Calvin Tan\n",
        "#  @version 1.0\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# The following code was originally written by Todd Neller in Java.\n",
        "# It was translated into Python by May Jiang.\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# Copyright (C) 2020 Todd Neller\n",
        "# This program is free software; you can redistribute it and/or\n",
        "# modify it under the terms of the GNU General Public License\n",
        "# as published by the Free Software Foundation; either version 2\n",
        "# of the License, or (at your option) any later version.\n",
        "# This program is distributed in the hope that it will be useful,\n",
        "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "# GNU General Public License for more details.\n",
        "# Information about the GNU General Public License is available online at:\n",
        "#   http://www.gnu.org/licenses/\n",
        "# To receive a copy of the GNU General Public License, write to the Free\n",
        "# Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n",
        "# 02111-1307, USA.\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "from typing import List, TypeVar\n",
        "from random import randint\n",
        "from GinRummyUtil import GinRummyUtil\n",
        "from GinRummyPlayer import GinRummyPlayer\n",
        "import random\n",
        "\n",
        "# Import MLP Models\n",
        "# from SupervisedLearning.models import *\n",
        "\n",
        "Card = TypeVar('Card')\n",
        "\n",
        "class RandGinRummyPlayer(GinRummyPlayer):\n",
        "\n",
        "    # Inform player of 0-based player number (0/1), starting player number (0/1), and dealt cards\n",
        "    def startGame(self, playerNum: int, startingPlayerNum: int, cards: List[Card]) -> None:\n",
        "        self.playerNum = playerNum\n",
        "        self.startingPlayerNum = startingPlayerNum\n",
        "        self.cards = list(cards)\n",
        "        self.opponentKnocked = False\n",
        "        self.drawDiscardBitstrings = [] # long[], or List[int]\n",
        "        self.faceUpCard = None\n",
        "        self.drawnCard = None\n",
        "        self.state = None\n",
        "\n",
        "    def willDrawFaceUpCard(self, card: Card) -> bool:\n",
        "        # Return random choice\n",
        "        self.faceUpCard = card\n",
        "        newCards = list(self.cards)\n",
        "        newCards.append(card)\n",
        "        choice = random.randint(0, 1)\n",
        "        if choice == 0:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "    # Report that the given player has drawn a given card and, if known, what the card is.\n",
        "    # If the card is unknown because it is drawn from the face-down draw pile, the drawnCard is null.\n",
        "    # Note that a player that returns false for willDrawFaceUpCard will learn of their face-down draw from this method.\n",
        "    def reportDraw(self, playerNum: int, drawnCard: Card) -> None:\n",
        "        # Ignore other player draws.  Add to cards if playerNum is this player.\n",
        "        if playerNum == self.playerNum:\n",
        "            self.cards.append(drawnCard)\n",
        "            self.drawnCard = drawnCard\n",
        "\n",
        "    # Get the player's discarded card.  If you took the top card from the discard pile,\n",
        "    # you must discard a different card.\n",
        "    # If this is not a card in the player's possession, the player forfeits the game.\n",
        "    # @return the player's chosen card for discarding\n",
        "    def getDiscard(self) -> Card:\n",
        "\n",
        "        choice = random.randint(0, len(self.cards)-1)\n",
        "        discCard = self.cards[choice]\n",
        "        while discCard == self.faceUpCard:\n",
        "            choice = random.randint(0, len(self.cards)-1)\n",
        "            discCard = self.cards[choice]\n",
        "        return discCard\n",
        "\n",
        "\n",
        "    # Report that the given player has discarded a given card.\n",
        "    def reportDiscard(self, playerNum: int, discardedCard: Card) -> None:\n",
        "        # Ignore other player discards.  Remove from cards if playerNum is this player.\n",
        "        if playerNum == self.playerNum:\n",
        "            self.cards.remove(discardedCard)\n",
        "\n",
        "    # At the end of each turn, this method is called and the player that cannot (or will not) end the round will return a null value.\n",
        "    # However, the first player to \"knock\" (that is, end the round), and then their opponent, will return an ArrayList of ArrayLists of melded cards.\n",
        "    # All other cards are counted as \"deadwood\", unless they can be laid off (added to) the knocking player's melds.\n",
        "    # When final melds have been reported for the other player, a player should return their final melds for the round.\n",
        "    # @return null if continuing play and opponent hasn't melded, or an ArrayList of ArrayLists of melded cards.\n",
        "    def getFinalMelds(self) -> List[List[Card]]:\n",
        "        # Check if deadwood of maximal meld is low enough to go out.\n",
        "        bestMeldSets = GinRummyUtil.cardsToBestMeldSets(self.cards) # List[List[List[Card]]]\n",
        "        if not self.opponentKnocked and (len(bestMeldSets) == 0 or \\\n",
        "            GinRummyUtil.getDeadwoodPoints1(bestMeldSets[0], self.cards) > \\\n",
        "            GinRummyUtil.MAX_DEADWOOD):\n",
        "            return None\n",
        "        if len(bestMeldSets) == 0:\n",
        "            return []\n",
        "        return bestMeldSets[randint(0, len(bestMeldSets)-1)]\n",
        "\n",
        "    # When an player has ended play and formed melds, the melds (and deadwood) are reported to both players.\n",
        "    def reportFinalMelds(self, playerNum: int, melds: List[List[Card]]) -> None:\n",
        "        # Melds ignored by simple player, but could affect which melds to make for complex player.\n",
        "        if playerNum != self.playerNum:\n",
        "            self.opponentKnocked = True\n",
        "\n",
        "    # Report current player scores, indexed by 0-based player number.\n",
        "    def reportScores(self, scores: List[int]) -> None:\n",
        "        # Ignored by simple player, but could affect strategy of more complex player.\n",
        "        return\n",
        "\n",
        "    # Report layoff actions.\n",
        "    def reportLayoff(self, playerNum: int, layoffCard: Card, opponentMeld: List[Card]) -> None:\n",
        "        # Ignored by simple player, but could affect strategy of more complex player.\n",
        "        return\n",
        "\n",
        "    # Report the final hands of players.\n",
        "    def reportFinalHand(self, playerNum: int, hand: List[Card]) -> None:\n",
        "        # Ignored by simple player, but could affect strategy of more complex player.\n",
        "        return"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-hik2PLM6C2"
      },
      "source": [
        "## Game Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDVKIcsgWJwe"
      },
      "source": [
        "class GinRummyGame:\n",
        "\n",
        "    # Hand size (before and after turn). After draw and before discard there is one extra card.\n",
        "    HAND_SIZE = 10;\n",
        "\n",
        "    # Whether or not to print information during game play\n",
        "    playVerbose = False;\n",
        "\n",
        "    # Two Gin Rummy players numbered according to their array index.\n",
        "    players = [];\n",
        "\n",
        "    # Set whether or not there is to be printed output during gameplay.\n",
        "    def setPlayVerbose(self, playVerbose):\n",
        "        self.playVerbose = playVerbose\n",
        "    \n",
        "    #-------------------------------- updateState --------------------------------#\n",
        "    # 2020-12-20: Define a method to append states\n",
        "    # 2021-01-16: modified append state to work for either player (0 or 1)\n",
        "    def updateState(self, currentPlayer, discards, oppCard):\n",
        "        currHand = one_hot(self.players[currentPlayer].cards)\n",
        "        topCard = np.zeros(52)\n",
        "        if len(discards) > 0:\n",
        "            topCard[discards[-1].getId()] = 1\n",
        "        deadCard = np.zeros(52)\n",
        "        for d in range(len(discards) - 1):\n",
        "            deadCard[discards[d].getId()] = 1\n",
        "        unknownCard = np.ones(52) - currHand - topCard - deadCard - oppCard\n",
        "        self.states = np.array([currHand, topCard, deadCard, oppCard, unknownCard]).flatten()\n",
        "    #------------------------------------------------------------------------------#\n",
        "\n",
        "    # Create a self with two given players\n",
        "    def __init__(self, player0, player1):\n",
        "        self.players = []\n",
        "        self.players.extend([player0, player1])\n",
        "\n",
        "    # Play a game of Gin Rummy and return the winning player number 0 or 1.\n",
        "    # @return the winning player number 0 or 1\n",
        "\n",
        "    def play(self):\n",
        "        scores = [0, 0]\n",
        "        hands = []\n",
        "        hands.extend([[], []])\n",
        "        startingPlayer = random.randrange(2);\n",
        "\n",
        "        # while game not over\n",
        "        while scores[0] < GinRummyUtil.GOAL_SCORE and scores[1] < GinRummyUtil.GOAL_SCORE:\n",
        "            \n",
        "            num_turns = 0\n",
        "            currentPlayer = startingPlayer\n",
        "            opponent = (1 if currentPlayer == 0 else 0)\n",
        "            \n",
        "            # get shuffled deck and deal cards\n",
        "            deck = Deck.getShuffle(random.randrange(10 ** 8))\n",
        "            hands[0] = []\n",
        "            hands[1] = []\n",
        "            for i in range(2 * self.HAND_SIZE):\n",
        "                hands[i % 2] += [deck.pop()]\n",
        "            for i in range(2):\n",
        "                self.players[i].startGame(i, startingPlayer, hands[i]);\n",
        "                if self.playVerbose:\n",
        "                    print(\"Player %d is dealt %s.\\n\" % (i, hands[i]))\n",
        "            if self.playVerbose:\n",
        "                print(\"Player %d starts.\\n\" % (startingPlayer))\n",
        "            discards = []\n",
        "            discards.append(deck.pop())\n",
        "            if self.playVerbose:\n",
        "                print(\"The initial face up card is %s.\\n\" % (discards[len(discards) - 1]))\n",
        "            firstFaceUpCard = discards[len(discards) - 1]\n",
        "            turnsTaken = 0\n",
        "            knockMelds = None\n",
        "\n",
        "            # 11/25 - Initial state, prior to any cards\n",
        "            # 1/16 - Initialize oppCard to be two dimensional to track both players as opponents\n",
        "            oppCard = []\n",
        "            oppCard.extend([np.zeros(52), np.zeros(52)])\n",
        "\n",
        "            for i in range(2):\n",
        "                if isinstance(self.players[i], MLPGinRummyPlayer):\n",
        "                    self.players[i].setVerbose(self.playVerbose)\n",
        "\n",
        "            # while the deck has more than two cards remaining, play round\n",
        "            while len(deck) > 2:\n",
        "                if num_turns > 300:\n",
        "                    print(\"Max Turns exceeded, restart\")\n",
        "                    break\n",
        "                else:\n",
        "                    num_turns += 1\n",
        "#-------------------------------------------------------------- BPBD --------------------------------------------------------------#\n",
        "                drawFaceUp = False\n",
        "                faceUpCard = discards[len(discards) - 1]\n",
        "\n",
        "                # offer draw face-up iff not 3rd turn with first face up card (decline automatically in that case)\n",
        "                if not (turnsTaken == 2 and faceUpCard == firstFaceUpCard):\n",
        "\n",
        "                    #------------------------------------ DRAW ------------------------------------#\n",
        "                    # 2020-12-01  -  Track states BEFORE the player PICKUP BEFORE player DISCARDS (track_bpbd)\n",
        "                    # 2021-01-16  -  Track for both players instead of just player 0\n",
        "                    # Action      -  PickUp from Discard(FaceUp) or Deck (Unknown)\n",
        "                    # State       -  BPBD -> APBD\n",
        "\n",
        "                    self.updateState(currentPlayer,discards,oppCard[currentPlayer])\n",
        "\n",
        "                    #------------------------------------------------------------------------------#\n",
        "\n",
        "                    # 2021-01-16  -  Update player with current states\n",
        "                    if isinstance(self.players[currentPlayer], MLPGinRummyPlayer):\n",
        "                        self.players[currentPlayer].updateStates(self.states)\n",
        "\n",
        "                    # both players declined and 1st player must draw face down\n",
        "                    drawFaceUp = self.players[currentPlayer].willDrawFaceUpCard(faceUpCard)\n",
        "                    \n",
        "                    if self.playVerbose and not drawFaceUp and faceUpCard == firstFaceUpCard and turnsTaken < 2:\n",
        "                        print(\"Player %d declines %s.\\n\" % (currentPlayer, firstFaceUpCard))\n",
        "\n",
        "                if not (not drawFaceUp and turnsTaken < 2 and faceUpCard == firstFaceUpCard):\n",
        "\n",
        "                    # continue with turn if not initial declined option\n",
        "                    if self.playVerbose:\n",
        "                        if drawFaceUp:\n",
        "                            print('drawFaceUp (Pickup discarded card)')\n",
        "                        else:\n",
        "                            print('Draw from deck')\n",
        "                    drawCard = discards.pop() if drawFaceUp else deck.pop()\n",
        "                    for i in range(2):\n",
        "                        to_report = drawCard if i == currentPlayer or drawFaceUp else None\n",
        "                        self.players[i].reportDraw(currentPlayer, to_report)\n",
        "\n",
        "                    if self.playVerbose:\n",
        "                        print(\"Player %d draws %s.\\n\" % (currentPlayer, drawCard))\n",
        "                    hands[currentPlayer].append(drawCard)\n",
        "#-------------------------------------------------------------- APBD --------------------------------------------------------------#\n",
        "                    \n",
        "                    self.updateState(currentPlayer,discards,oppCard[currentPlayer])\n",
        "                    \n",
        "                    # 2021-01-16  -  Update player with current states\n",
        "                    if isinstance(self.players[currentPlayer], MLPGinRummyPlayer):\n",
        "                    # if type(self.players[currentPlayer]) == type(MLPGinRummyPlayer()):\n",
        "                        self.players[currentPlayer].updateStates(self.states)\n",
        "\n",
        "                    discardCard = self.players[currentPlayer].getDiscard()\n",
        "\n",
        "                    # 2021-01-16  -  Track for both players instead of just player 0\n",
        "                    # Track opponent pickup and discard after each discard \n",
        "\n",
        "                    # Set discarded card to 0 (in case discarded card was seen)\n",
        "                    oppCard[1 - currentPlayer][discardCard.getId()] = 0\n",
        "                    if drawFaceUp: # if opponent draws TopCard from discard\n",
        "                        oppCard[1 - currentPlayer][drawCard.getId()] = 1\n",
        "\n",
        "                    if not discardCard in hands[currentPlayer] or discardCard == faceUpCard:\n",
        "                        print(\"Player %d discards %s illegally and forfeits.\\n\" % (currentPlayer, discardCard))\n",
        "                        return opponent;\n",
        "                    hands[currentPlayer].remove(discardCard)\n",
        "                    for i in range(2):\n",
        "                        self.players[i].reportDiscard(currentPlayer, discardCard)                    \n",
        "                    if self.playVerbose:\n",
        "                        print(\"Player %d discards %s.\\n\" % (currentPlayer, discardCard))\n",
        "                    discards.append(discardCard)\n",
        "\n",
        "                    if self.playVerbose:\n",
        "                        unmeldedCards = hands[currentPlayer].copy()\n",
        "                        bestMelds = GinRummyUtil.cardsToBestMeldSets(unmeldedCards)\n",
        "                        if len(bestMelds) == 0:\n",
        "                            print(\"Player %d has %s with %d deadwood.\\n\" % (currentPlayer, unmeldedCards, GinRummyUtil.getDeadwoodPoints3(unmeldedCards)))\n",
        "                        else:\n",
        "                            melds = bestMelds[0]\n",
        "                            for meld in melds:\n",
        "                                for card in meld:\n",
        "                                    unmeldedCards.remove(card)\n",
        "                            melds.extend(unmeldedCards)\n",
        "                            print(\"Player %d has %s with %d deadwood.\\n\" % (currentPlayer, melds, GinRummyUtil.getDeadwoodPoints3(unmeldedCards)))\n",
        "\n",
        "#-------------------------------------------------------------- KNOCK --------------------------------------------------------------#\n",
        "                    # CHECK FOR KNOCK\n",
        "                    knockMelds = self.players[currentPlayer].getFinalMelds()\n",
        "                    if knockMelds != None:\n",
        "                        # print('Current Player:', currentPlayer)\n",
        "                        # print(knockMelds)\n",
        "                        # break\n",
        "                        # 2021-01-16  -  Check if MLPGinRummyPlayer knocks\n",
        "                        if isinstance(self.players[currentPlayer], MLPGinRummyPlayer):\n",
        "                            knock = self.players[currentPlayer].knockAction()\n",
        "                            if self.playVerbose:\n",
        "                                print(knock)\n",
        "                            if knock:\n",
        "                                break\n",
        "                        else:\n",
        "                            break\n",
        "                    \n",
        "                turnsTaken += 1\n",
        "                # currentPlayer = 1 if currentPlayer == 0 else 0\n",
        "                # opponent = 1 if currentPlayer == 0 else 0\n",
        "                if len(deck) > 2:\n",
        "                    currentPlayer = 1 if currentPlayer == 0 else 0\n",
        "                    opponent = 1 if currentPlayer == 0 else 0\n",
        "\n",
        "            # if knockMelds != None and len(deck) > 2:\n",
        "            if knockMelds != None:\n",
        "                # round didn't end due to non-knocking and 2 cards remaining in draw pile\n",
        "                # check legality of knocking meld\n",
        "                handBitstring = GinRummyUtil.cardsToBitstring(hands[currentPlayer])\n",
        "                unmelded = handBitstring\n",
        "                for meld in knockMelds:\n",
        "                    meldBitstring = GinRummyUtil.cardsToBitstring(meld)\n",
        "                    if (not meldBitstring in GinRummyUtil.getAllMeldBitstrings()) or ((meldBitstring & unmelded) != meldBitstring):\n",
        "                        # non-meld or meld not in hand\n",
        "                        # print(len(deck))\n",
        "                        # print(meld)\n",
        "                        # print(knockMelds)\n",
        "                        # print(currentPlayer, hands[currentPlayer])\n",
        "                        # print(1- currentPlayer, hands[1-currentPlayer])\n",
        "                        # print(GinRummyUtil.getDeadwoodPoints1(knockMelds, hands[1-currentPlayer]))\n",
        "                        print(\"Player %d melds %s illegally and forfeits.\\n\" % (currentPlayer, knockMelds))\n",
        "                        return opponent\n",
        "                    unmelded &= ~meldBitstring # remove successfully melded cards from\n",
        "\n",
        "                # compute knocking deadwood\n",
        "                knockingDeadwood = GinRummyUtil.getDeadwoodPoints1(knockMelds, hands[currentPlayer])\n",
        "                if knockingDeadwood > GinRummyUtil.MAX_DEADWOOD:\n",
        "                    print(\"Player %d melds %s with greater than %d deadwood and forfeits.\\n\" % (currentPlayer, knockMelds, knockingDeadwood))\n",
        "                    return opponent\n",
        "\n",
        "                meldsCopy = []\n",
        "                for meld in knockMelds:\n",
        "                    meldsCopy.append(meld.copy())\n",
        "                for i in range(2):\n",
        "                    self.players[i].reportFinalMelds(currentPlayer, meldsCopy)\n",
        "                if self.playVerbose:\n",
        "                    if knockingDeadwood > 0:\n",
        "                        print(\"Player %d melds %s with %d deadwood from %s.\\n\" % (currentPlayer, knockMelds, knockingDeadwood, GinRummyUtil.bitstringToCards(unmelded)))\n",
        "                    else:\n",
        "                        print(\"Player %d goes gin with melds %s.\\n\" % (currentPlayer, knockMelds))\n",
        "\n",
        "                # get opponent meld\n",
        "                opponentMelds = self.players[opponent].getFinalMelds();\n",
        "                meldsCopy = []\n",
        "                for meld in opponentMelds:\n",
        "                    meldsCopy.append(meld.copy())\n",
        "                for i in range(2):\n",
        "                    self.players[i].reportFinalMelds(opponent, meldsCopy)\n",
        "\n",
        "                # check legality of opponent meld\n",
        "                opponentHandBitstring = GinRummyUtil.cardsToBitstring(hands[opponent])\n",
        "                opponentUnmelded = opponentHandBitstring\n",
        "                for meld in opponentMelds:\n",
        "                    meldBitstring = GinRummyUtil.cardsToBitstring(meld)\n",
        "                    if (meldBitstring not in GinRummyUtil.getAllMeldBitstrings()) or ((meldBitstring & opponentUnmelded) != meldBitstring):\n",
        "                        # non-meld or meld not in hand\n",
        "                        print(\"Player %d melds %s illegally and forfeits.\\n\" % (opponent, opponentMelds))\n",
        "                        return currentPlayer\n",
        "                    opponentUnmelded &= ~meldBitstring # remove successfully melded cards from\n",
        "\n",
        "                if self.playVerbose:\n",
        "                    print(\"Player %d melds %s.\\n\" % (opponent, opponentMelds))\n",
        "\n",
        "                # lay off on knocking meld (if not gin)\n",
        "                unmeldedCards = GinRummyUtil.bitstringToCards(opponentUnmelded)\n",
        "                if knockingDeadwood > 0:\n",
        "                    # knocking player didn't go gin\n",
        "                    cardWasLaidOff = False\n",
        "                    while True:\n",
        "                        # attempt to lay each card off\n",
        "                        cardWasLaidOff = False\n",
        "                        layOffCard = None\n",
        "                        layOffMeld = None\n",
        "                        for card in unmeldedCards:\n",
        "                            for meld in knockMelds:\n",
        "                                newMeld = meld.copy()\n",
        "                                newMeld.append(card)\n",
        "                                newMeldBitstring = GinRummyUtil.cardsToBitstring(newMeld)\n",
        "                                if newMeldBitstring in GinRummyUtil.getAllMeldBitstrings():\n",
        "                                    layOffCard = card\n",
        "                                    layOffMeld = meld\n",
        "                                    break\n",
        "                            if layOffCard != None:\n",
        "                                if self.playVerbose:\n",
        "                                    print(\"Player %d lays off %s on %s.\\n\" % (opponent, layOffCard, layOffMeld))\n",
        "                                for i in range(2):\n",
        "                                    self.players[i].reportLayoff(opponent, layOffCard, layOffMeld.copy())\n",
        "                                unmeldedCards.remove(layOffCard)\n",
        "                                layOffMeld.append(layOffCard)\n",
        "                                cardWasLaidOff = True\n",
        "                                break\n",
        "                        if not cardWasLaidOff:\n",
        "                            break\n",
        "\n",
        "                opponentDeadwood = 0\n",
        "                for card in unmeldedCards:\n",
        "                    opponentDeadwood += GinRummyUtil.getDeadwoodPoints2(card)\n",
        "                if self.playVerbose:\n",
        "                    print(\"Player %d has %d deadwood with %s\\n\" % (opponent, opponentDeadwood, unmeldedCards))\n",
        "                # compare deadwood and compute new scores\n",
        "                if knockingDeadwood == 0:\n",
        "                    # gin round win\n",
        "                    scores[currentPlayer] += GinRummyUtil.GIN_BONUS + opponentDeadwood\n",
        "                    if self.playVerbose:\n",
        "                        print(\"Player %d scores the gin bonus of %d plus opponent deadwood %d for %d total points.\\n\" % \\\n",
        "                        (currentPlayer, GinRummyUtil.GIN_BONUS, opponentDeadwood, GinRummyUtil.GIN_BONUS + opponentDeadwood))\n",
        "\n",
        "                elif knockingDeadwood < opponentDeadwood:\n",
        "                    # non-gin round win:\n",
        "                    scores[currentPlayer] += opponentDeadwood - knockingDeadwood;\n",
        "                    if self.playVerbose:\n",
        "                        print(\"Player %d scores the deadwood difference of %d.\\n\" % (currentPlayer, opponentDeadwood - knockingDeadwood))\n",
        "\n",
        "                else:\n",
        "                    # undercut win for opponent\n",
        "                    scores[opponent] += GinRummyUtil.UNDERCUT_BONUS + knockingDeadwood - opponentDeadwood;\n",
        "                    if self.playVerbose:\n",
        "                        print(\"Player %d undercuts and scores the undercut bonus of %d plus deadwood difference of %d for %d total points.\\n\" % \\\n",
        "                        (opponent, GinRummyUtil.UNDERCUT_BONUS, knockingDeadwood - opponentDeadwood, GinRummyUtil.UNDERCUT_BONUS + knockingDeadwood - opponentDeadwood))\n",
        "\n",
        "                startingPlayer = 1 if startingPlayer == 0 else 0 # starting player alternates\n",
        "\n",
        "            # If the round ends due to a two card draw pile with no knocking, the round is cancelled.\n",
        "            else:\n",
        "                if self.playVerbose:\n",
        "                    print(\"The draw pile was reduced to two cards without knocking, so the hand is cancelled.\")\n",
        "\n",
        "            # report final hands\n",
        "            for i in range(2):\n",
        "                for j in range(2):\n",
        "                    self.players[i].reportFinalHand(j, hands[j].copy())\n",
        "\n",
        "            # score reporting\n",
        "            if self.playVerbose:\n",
        "                print(\"Player\\tScore\\n0\\t%d\\n1\\t%d\\n\" % (scores[0], scores[1]))\n",
        "            for i in range(2):\n",
        "                self.players[i].reportScores(scores.copy())\n",
        "\n",
        "        if self.playVerbose:\n",
        "            print(\"Player %s wins.\\n\" % (0 if scores[0] > scores[1] else 1))\n",
        "        return 0 if scores[0] >= GinRummyUtil.GOAL_SCORE else 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11qEEpVcXSun"
      },
      "source": [
        "## Shared"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faqGzLQVWQZD"
      },
      "source": [
        "def testAgents(agent0,agent1,numGames,verbose):\n",
        "    numP1Wins = 0\n",
        "    game = GinRummyGame(agent0, agent1)\n",
        "    # Multiple non-verbose games\n",
        "    game.setPlayVerbose(verbose)\n",
        "    # for i in range(2):\n",
        "    #     if isinstance(game.players[i], MLPGinRummyPlayer):\n",
        "    #         print(game.players[i].model)\n",
        "    for i in range(numGames):\n",
        "        if i % 250 == 0:\n",
        "        # if i % 100 == 0:\n",
        "            print(\"Game ... \", i)\n",
        "        # set random seed to make testing consistent\n",
        "        random.seed(i)\n",
        "        numP1Wins += game.play()\n",
        "    print(\"Games Won: P0:%d, P1:%d.\\n\" % (numGames - numP1Wins, numP1Wins))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgmlCQKmVfj3"
      },
      "source": [
        "state = 'all'\n",
        "action = 'all'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUoy-A6cBlkH"
      },
      "source": [
        "# Test Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gKilTmVjLg-"
      },
      "source": [
        "## DQN - baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne8dAH3YjLhJ"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: 0\n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/baseline'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QpYtl1sjLhQ"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9s5cCYajLhQ"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN9p6lpjjLhI"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVt747XwjLhK",
        "outputId": "486bcc8b-7801-4101-c06d-6a627b19d5e6"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxXywCoKjLhL"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbQnIiIPjLhM",
        "outputId": "594fac18-b496-49d5-f95f-780ee9e2de51"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkJkKtQjjLhM",
        "outputId": "5aea4d15-d6d2-46fd-bce2-30720851a015"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_VeMUKcOLOP",
        "outputId": "f33fd832-cbd2-42de-ec55-293a1b05d29e"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOp3BYRAjLhN",
        "outputId": "afd8d40a-425c-421f-9c18-d2c8628cd21d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV7osmhsON8U",
        "outputId": "5a0464c1-9168-42c5-8969-d89581dee773"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4YwzOByjLhO",
        "outputId": "c3e3ed03-f035-41f4-a98f-21d9bf09389b"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mNaZVdHjLhN",
        "outputId": "cd47fd3c-41cc-4c6b-aa9b-b0eb72b29e5d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APcGxXD0jLhP"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynZ9bSHBjLhP",
        "outputId": "4e056aa1-8c6c-48ac-e535-3b63556a9991"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjmGIOKNjLhP"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLdilK_tjLhO"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRMUMOm0jLhO"
      },
      "source": [
        "# numGames = 1000\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# agent0 = MLPGinRummyPlayer()\n",
        "# checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "# qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "# qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "# agent0.loadModel(qnet)\n",
        "# agent2 = MLPGinRummyPlayer()\n",
        "# checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "# qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "# qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "# agent2.loadModel(qnet)\n",
        "# testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jGS7wLa4bX0"
      },
      "source": [
        "## DQN - baseline 1HL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny3apipd4bYF"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: 138/74/137/80\n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 110]\n",
        "model = 'models/dqn/final/baseline_1HL'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8axG9YHv4bYN"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3m_YBzt4bYO",
        "outputId": "d8ec7f9a-bb03-468f-8d20-d3d02c00b917"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1-rBbew4bYG"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5wSF8CB4bYG",
        "outputId": "1b431d41-fa4b-480c-b589-1d7840f7ccc1"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:138, P1:862.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53sUQPHc4bYI"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvNP6wW34bYI",
        "outputId": "e3134bac-0558-4784-8506-eb4cfddc2a49"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:74, P1:926.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyQQRv5wOoB6",
        "outputId": "af6a925d-c55a-43d1-d45d-e682a1c3ef00"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:73, P1:927.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oACCV5TT4bYJ",
        "outputId": "9e9c518e-dacf-4969-c133-3150c8425192"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:137, P1:863.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjnlOxFl4bYK",
        "outputId": "917fc567-1d08-4672-f79c-a3530844947c"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:135, P1:865.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZr5XpG6Osvd",
        "outputId": "b82a36da-f056-4514-8437-a671a7d531d8"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:141, P1:859.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfgTtiLk4bYK",
        "outputId": "34302de9-2d30-425d-ad6b-c63ebe403443"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:138, P1:862.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIllYH494bYJ",
        "outputId": "68d8e41b-28b0-4e5c-b90f-bd8b11f1dd65"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:80, P1:920.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HusFzuo04bYM"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_UuwOPP4bYM",
        "outputId": "17c53c76-d22a-4a47-e6bf-e67435024c4e"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:321, P1:679.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2UeGIc54bYN",
        "outputId": "932096f9-461f-4b55-d301-f2514b7df1c2"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Player 0 melds [[9D, TD, JD, QD, KD], [4S, 4D, 4C]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:159, P1:841.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leyXsZsX4bYL"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jehEJSX94bYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b91c4b-d92c-444a-a7b7-65c3269a7da1"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[2S, 2H, 2D, 2C], [5S, 5H, 5D]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:280, P1:720.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eLOp_Gz-pDZ"
      },
      "source": [
        "## DQN - baseline 2HL_40k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta_MBHxT-pDn"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: 280/160/220/167\n",
        "# Wins2: 282/282\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/baseline_2HL_40k'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6pa581e-pDs"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHUnC0XV-pDt",
        "outputId": "94223ffa-9a31-4cfc-cd18-70f247445cc9"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRtJWR2v-pDn"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jx4Bw---pDo",
        "outputId": "b5744fcf-4fae-4df7-fcbc-a92536c68fdd"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:280, P1:720.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPw6P7X4-pDp"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC8eGYXl-pDp",
        "outputId": "217a73e1-36e7-4dbf-f154-10783e68e8ad"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:161, P1:839.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHlS9rYOO307",
        "outputId": "09dbd1ac-9a93-4c7d-847e-7d321362cce7"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:181, P1:819.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzdvGCI3-pDq",
        "outputId": "fb4a12d0-6991-49fd-f531-9dde657a86f1"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:220, P1:780.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aG7Xqyq-pDq",
        "outputId": "d4ba9886-6315-41a4-fe1a-a40b60f3ea54"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:282, P1:718.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZABbqk2O7PW",
        "outputId": "b0f0d2dd-d92a-46d6-d8d7-9588cf9c689b"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:282, P1:718.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFPvMiCX-pDr",
        "outputId": "d09bd4dd-45a9-4eee-a417-a6d5685bdae4"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:282, P1:718.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMvQfQum-pDq",
        "outputId": "1aa27653-7601-46f2-8efb-55393cda966d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:167, P1:833.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLlWPw9c-pDs"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuG9w12--pDs",
        "outputId": "c68d2baa-5e1b-41f6-9c2b-b5c2a87dbc45"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_40K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:539, P1:461.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKyj2qSg-pDs",
        "outputId": "8cdee38a-a298-44ea-820d-1f0a5d5cc3b6"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_40K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[2S, 3S, 4S], [8D, 9D, TD, JD, QD]] illegally and forfeits.\n",
            "\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[4S, 4H, 4D], [7S, 7H, 7D, 7C]] illegally and forfeits.\n",
            "\n",
            "Games Won: P0:332, P1:668.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxjep7l2-pDr"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xySFe0U-pDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78eab42-f093-4d06-ea21-7a19e1702749"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[2S, 3S, 4S], [8D, 9D, TD, JD, QD]] illegally and forfeits.\n",
            "\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[4S, 4H, 4D], [7S, 7H, 7D, 7C]] illegally and forfeits.\n",
            "\n",
            "Games Won: P0:332, P1:668.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGjNvegP-waN"
      },
      "source": [
        "## DQN - baseline 2HL_80k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8kiEwQ6-waN"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/baseline_2HL_80k'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeRoI7e9-waQ"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jeD0Fe0-waQ",
        "outputId": "317233a9-aa7a-4e18-b382-a2143702a65e"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1CLcH07-waN"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE2jkdyE-waO",
        "outputId": "9ad13d30-c738-4f46-d31f-ecf491706d17"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi5ccbHC-waO"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RuASDvT-waO",
        "outputId": "3ed69304-3f22-434e-ec7b-3ba4d7172d4a"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:205, P1:795.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPccY7IQO-_h",
        "outputId": "dfce9f8c-5f77-4b4b-af0c-7182a044d487"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:195, P1:805.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAeDv52A-waO",
        "outputId": "b16834bb-2a32-4e50-8107-917246e98ea5"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:308, P1:692.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sWo_vqx-waP",
        "outputId": "e795ed04-a512-4a8b-f1bc-601169d8f99e"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlgek2S8PAoj",
        "outputId": "a5560ab0-1add-4c33-f709-c7dfdc0e5419"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:273, P1:727.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvjUmyPT-waP",
        "outputId": "257cfcc9-776c-4993-e87d-9671cfcc4269"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:323, P1:677.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WU7ZkPs-waO",
        "outputId": "d1a3a8bd-1c0c-41de-da9f-34ccb0d68d2d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:194, P1:806.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIq4dPEE-waP"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C5KbtD_-waQ",
        "outputId": "1393406d-e249-44cf-ea38-4e6ac85b853b"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:492, P1:508.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7umSemoI-waQ",
        "outputId": "4efbdac7-7f8d-42a0-ef86-19839faef601"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[7S, 8S, 9S, TS], [3S, 3D, 3C]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:350, P1:650.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tojla7Ln-waP"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U_NvIfn-waP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a85f9c9-74d9-46f4-99a4-508a2ed90bbd"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[7S, 8S, 9S, TS], [3S, 3D, 3C]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:350, P1:650.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYsCw-B6V-3B"
      },
      "source": [
        "## DQN - Frozen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB0TbSBYV-3G"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/frozen'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUYnTbcLV-3Q"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GyzKEGmV-3Q",
        "outputId": "85e3a937-14c8-4080-e413-bf80cc4ca755"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu_f-zYbV-3H"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bAy-xJKV-3I",
        "outputId": "dbb7b67c-eb02-4655-d262-592fd092751b"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcYjYx_7V-3J"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiK3WKxVV-3J",
        "outputId": "370fea89-2b70-4249-9ace-655c913768a4"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:238, P1:762.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0OTVajzPHUi",
        "outputId": "6a93de5b-8610-4c99-8826-59f7033a02ea"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:261, P1:739.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE1GwgnyV-3K",
        "outputId": "8d2efcc5-d774-46d8-f1ad-747bbc3c97f1"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:242, P1:758.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lciv0AnYV-3L",
        "outputId": "abe4376c-4a9e-4334-f959-2dfe57b31288"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:312, P1:688.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA1bW_AjPKnf",
        "outputId": "8a3104e3-c2f0-4253-8fb5-4b969ec9b6b0"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:290, P1:710.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOS0hHPHV-3L",
        "outputId": "a2ec912d-b7f4-474b-8348-3128be2129ab"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDp04Ka0V-3K",
        "outputId": "f5843a1e-a261-456e-91e3-0beb61346999"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:231, P1:769.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mma4HR8cV-3O"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKBSgRfMV-3P",
        "outputId": "2a4bb64c-1eb6-4105-84a7-64e4599f87a9"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:492, P1:508.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvWm-9ISV-3P",
        "outputId": "4ecab8a5-c365-4408-f501-13e4bfafe6a7"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:408, P1:592.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yiI4UBgV-3L"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qfvvMjeV-3M",
        "outputId": "af80c00f-f1fd-4d33-b273-4f12e1839a76"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:408, P1:592.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_KgHvEyZ6c7"
      },
      "source": [
        "## DQN - Random Top Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMgyqPD7Z6c7"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = True\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/random'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPk9CheMdxWF"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PlxmtDRdxWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35e966b-5abf-4834-b42f-5852a05998d4"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:990, P1:10.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i8jIgy3Z6c7"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx-Qulj7Z6c7",
        "outputId": "bedbb03c-82e6-40a7-8dc6-58420bc5d86f"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKjskB2AZ6c8"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhay3dmqZ6c8",
        "outputId": "e521e3b6-b45a-4a3a-ec66-7864f89ca197"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZPue6LEZ6c8",
        "outputId": "e58d67ba-9f67-4e26-9e26-0d56a985d3a4"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcXeqkKBZ6c9",
        "outputId": "27b937da-1c41-4a20-93d4-63db7fe2268b"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO8iyZM3Z6c9",
        "outputId": "72ccd02e-aeaf-4846-84a1-99a808d111b8"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzmWiiO9Z6c9",
        "outputId": "c89b156d-4913-4f43-879f-ba8ebd40d3db"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAosuwC3cSni"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8ecek5NckFm",
        "outputId": "2cc075a5-bed8-4b53-8fa2-f1118bde88f7"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Player 0 melds [[AS, AD, AC], [7S, 7H, 7D, 7C]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZOrcwLUdZCr",
        "outputId": "0a21a036-496d-426a-cb1e-bcbba66f730a"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjoMoEHEb-Fc"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhNDrg1ncDDG"
      },
      "source": [
        "# numGames = 1000\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# agent0 = MLPGinRummyPlayer()\n",
        "# checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "# qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "# qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "# agent0.loadModel(qnet)\n",
        "# agent2 = MLPGinRummyPlayer()\n",
        "# checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "# qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "# qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "# agent2.loadModel(qnet)\n",
        "# testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lizD8Akdu4HT"
      },
      "source": [
        "## DQN - Copy Top Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orHmVz28u4Hf"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = True\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/copy'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQlG1x9Bu4Hr"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4VSUs5lu4Hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56e0288-b20f-4e74-ad93-1196c25e3c52"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:997, P1:3.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjaIOs-vu4Hg"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I4NwA6ru4Hh",
        "outputId": "7a4aa434-9802-4b06-82bc-d18ccbde70ed"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:63, P1:937.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYMkzY03u4Hj"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2blG91OIu4Hk",
        "outputId": "3c1cca03-2b8d-4624-aca3-033b76915f55"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUlM3Wrgu4Hk",
        "outputId": "938e9afd-71a3-4014-c181-1a140fcaccf4"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:63, P1:937.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwxH-vG_u4Hm",
        "outputId": "2a42aa34-2800-4425-bd56-e72567496f91"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:63, P1:937.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwrhIDEiu4Hn",
        "outputId": "042402eb-c206-4bae-e84d-5b163d0b3a11"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:63, P1:937.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tirNjYWgu4Hl",
        "outputId": "b9239b46-9e06-4093-92b4-4cf45b8ceeb6"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9NCTPsu4Ho"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUbsk9H2u4Hp",
        "outputId": "25b8c0cf-755c-47f1-ee4a-d6cc5fd86a56"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:176, P1:824.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGzfaVcMu4Hq",
        "outputId": "ba6b77b1-d341-4e80-996a-1c4dbd9d5524"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKHExLfgu4Hn"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yNiDuyCu4Ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5830420a-36cd-40e4-dc86-bf584d70bff8"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1, P1:999.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg4cLKYAdKuN"
      },
      "source": [
        "# Test Agents - Rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df4AAC1vdISG"
      },
      "source": [
        "## DQN - v2\n",
        "\n",
        "Gin/Knock/Other = 1/0.4/-0.01 per DW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYKppLrPdISI"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/rewards/v2'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIAWaWK-dISQ"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlUb9LLadISQ",
        "outputId": "921bdc31-fbec-4a0c-a42b-52c585588ecc"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZyzEKiydISJ"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwgC-vlmdISJ",
        "outputId": "8f958ead-42fe-4184-c2ca-36e784937ed8"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtUslzBGdISK"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EoBP4OHdISK",
        "outputId": "a7eb2559-40f5-4e80-a884-e8a2a9bd2917"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:237, P1:763.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRYIPF9uPbLI",
        "outputId": "2bebe8be-0bf6-4a61-cb82-688841694202"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:267, P1:733.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPb2Mjs7dISL",
        "outputId": "359003e0-bd93-4a6d-a7f6-a94130879b6b"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:303, P1:697.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P84SqKKAdISM",
        "outputId": "463aa4f2-d356-43f5-85a4-2411fa961f01"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:312, P1:688.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVBKEbMwPffd",
        "outputId": "4c0f8d60-6c88-414a-d7a4-1c89e3145189"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:290, P1:710.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMdJlH23dISN",
        "outputId": "d2e0abec-fbdd-4675-986d-be26db26be06"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2eqi5XFdISM",
        "outputId": "f598f298-5d00-4ecd-81e1-128faf176285"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:243, P1:757.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlZFUdh5dISO"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvDqUAn5dISP",
        "outputId": "7f5b8d0b-6000-47f5-8820-37044c2be069"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:492, P1:508.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTrANa0zdISP",
        "outputId": "49e04d43-95f9-4acb-dd81-51011587c301"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:408, P1:592.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvwAvIWwdISO"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BuQI9-adISO",
        "outputId": "cb13e7a9-baa1-43ec-bce6-71970d8c9b41"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:408, P1:592.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN6jHDX8dmtx"
      },
      "source": [
        "## DQN - v3\n",
        "\n",
        "Gin/Knock/Other = 1/1/-0.01 per DW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k6h4UZydmt0"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/rewards/v3'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS729IDjdmt6"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVem-Ao7dmt7",
        "outputId": "fe53808b-aba1-468b-ffd1-ca23ace314b9"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGIH-5Ymdmt1"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASLZXFredmt2",
        "outputId": "abca52ca-c106-4f46-c4fd-7ff61a4ef39a"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCgbKjWBdmt3"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45p_Szjsdmt3",
        "outputId": "f64c4b6f-b99e-42cc-cb04-e5ba9a04f46f"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:279, P1:721.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_9ZuHfMPnS2",
        "outputId": "44171f8c-4d4c-47dc-9fbf-f396fa493a7e"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:250, P1:750.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFwesVavdmt3",
        "outputId": "df1ed86f-c146-4e43-9a36-12c0abf2c805"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:247, P1:753.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFuQQDjRdmt4",
        "outputId": "ab7400c0-de4b-43bd-9c72-56f233ca57c7"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:312, P1:688.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaLH97t-PnS3",
        "outputId": "95c4cefd-d854-482b-c21c-51fabc5c4a03"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:290, P1:710.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytasuEJqdmt4",
        "outputId": "66b9aba7-13b6-4900-d38f-51175cd5be5d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:303, P1:697.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQQpOsXXdmt4",
        "outputId": "71d1e004-81aa-4f09-aeca-0b6f432f9240"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:257, P1:743.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6rt7HU5dmt6"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sq5KlZKdmt6",
        "outputId": "4b2ce2e7-1a97-48d9-c369-751d4300ba73"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:492, P1:508.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5N9zoerdmt6",
        "outputId": "a178cc30-8317-4c47-b64e-f1ed8f7c8800"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:438, P1:562.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-8SiYnydmt5"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMDvK2oedmt5",
        "outputId": "a7e588ea-3471-402c-f724-36925f5d57c4"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:438, P1:562.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd10xR0FdpXl"
      },
      "source": [
        "## DQN - v4\n",
        "\n",
        "Gin/Knock/Other = 1/10/-0.01 per DW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqq2oiEzdpXm"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/rewards/v4'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4GMpOGsdpXq"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C41neszXdpXq",
        "outputId": "293c82b7-4ce9-4d90-e1b0-1ab3eb45cc7d"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue75G8KedpXm"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgRc-0zNdpXm",
        "outputId": "a56d763c-1f46-458b-cee9-a5bc850ac5e1"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF2TogaudpXm"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP8pp9n2dpXn",
        "outputId": "56433d33-85fa-41a4-e604-72f08e26a5cc"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:289, P1:711.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ALdMiBTPr0u",
        "outputId": "8f860837-c6be-492c-e0a3-91bb1059dd8e"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:280, P1:720.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBWZgtEmdpXn",
        "outputId": "6622ba97-9d51-4304-ae71-09dea946c7c8"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:272, P1:728.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWhjkWiEdpXn",
        "outputId": "3fcbd87b-f3df-4a22-d6ec-82875d6c68cb"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:312, P1:688.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf4sMi39Pr0v",
        "outputId": "4f2c6b37-159c-472c-edc3-99408801d36f"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:289, P1:711.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v02xelQhdpXn",
        "outputId": "fff7e4fa-f77e-482c-c7df-f4523d989b3f"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:289, P1:711.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr_qe821dpXn",
        "outputId": "c8b9d146-fcce-4cc6-9d2e-0c4e35403bb6"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:118, P1:882.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HpaqJGidpXp"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eEYiQ25dpXp",
        "outputId": "1a1b2074-a98c-4ff9-acc4-1c1cf065bff3"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:492, P1:508.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di5C4syHdpXq",
        "outputId": "d7911dd6-05e6-44e9-a316-f21afcc8d97b"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[2S, 2D, 2C], [4S, 4D, 4C]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 0 melds [[AS, 2S, 3S, 4S, 5S], [4H, 4D, 4C]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:260, P1:740.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-V9LmmVdpXo"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDn-Y9bLdpXp",
        "outputId": "9a05c5f9-8fae-4384-de12-9afa50c0fcef"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[2S, 2D, 2C], [4S, 4D, 4C]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 0 melds [[AS, 2S, 3S, 4S, 5S], [4H, 4D, 4C]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:260, P1:740.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NQcsIVJdsKS"
      },
      "source": [
        "## DQN - v5\n",
        "\n",
        "Gin/Knock/Other = 0/10/-0.01 per DW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXSy9Is-dsKU"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/rewards/v5'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUDAbH-3dsKZ"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct30HTavdsKa",
        "outputId": "65f74ecd-8042-43ed-f31c-495d6ade3666"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMyCKYAedsKU"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTpcNhaSdsKV",
        "outputId": "c04a1c4b-0e7f-4891-ae79-ec9a015781c4"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbCTIt0WdsKV"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9vZSjEDdsKV",
        "outputId": "de450e9e-4291-41ec-f58e-4dd0bc41d4af"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:289, P1:711.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgFg37iwPwnk",
        "outputId": "51130d5d-b424-4e8c-bb40-bf5e75e012b4"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:271, P1:729.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMTNNGXHdsKW",
        "outputId": "bb980fd4-a358-4a43-8475-1fb8b81c2387"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:312, P1:688.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns0lPxR4dsKX",
        "outputId": "a3f167da-ccc2-4518-d243-eb5e4be17803"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:312, P1:688.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU0tTSZ8Pwnl",
        "outputId": "d22ba693-e89e-4820-aae0-3745607dc6c3"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:289, P1:711.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U4HGclJdsKX",
        "outputId": "1f0c7f82-9f0e-45d9-ce5a-b1c4a45596b4"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:289, P1:711.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1Sb6g3cdsKW",
        "outputId": "8742091f-05af-4b26-ee79-f2aa809fb594"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:113, P1:887.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw7LR36adsKY"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tkVSni5dsKZ",
        "outputId": "f5d3e8c6-c041-4755-a607-30be08224af8"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:492, P1:508.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80HitAAIdsKZ",
        "outputId": "0ed2cebf-1754-4655-b3da-feb10ca6b07f"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Player 0 melds [[4S, 4D, 4C], [6S, 6H, 6D]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:241, P1:759.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwCBx15-dsKY"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8qcfPaqdsKY",
        "outputId": "9099b436-deb3-46d4-e8c9-7d2e1c5192e2"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Player 0 melds [[4S, 4D, 4C], [6S, 6H, 6D]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:241, P1:759.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYfcSEBPdu4k"
      },
      "source": [
        "## DQN - v7\n",
        "\n",
        "Gin/Knock/Other = 0/10/0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5ayQkIodu4l"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/rewards/v7'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcL_DgaNdu4o"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeY_rLICdu4o",
        "outputId": "660c829e-96f4-4fb3-ec93-f48648efa38c"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEGaOO-5du4l"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5C0mZ-Adu4l",
        "outputId": "ebee017a-9b2c-437e-8da9-2b1624e8f9cb"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:304, P1:696.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sjsla8Bdu4m"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhDLBWskdu4m",
        "outputId": "e5749492-4422-48b4-9c77-3f4b8790821a"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:289, P1:711.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX0P75ZwP0yE",
        "outputId": "49545c47-3117-4e8a-dd5e-68857141c1d1"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:257, P1:743.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2KON4Rsdu4m",
        "outputId": "0ddf5ca8-2134-42d7-b947-54238635a90f"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:312, P1:688.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElJ2vNr4du4m",
        "outputId": "99941960-786d-44b8-9812-6897ae92794d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:312, P1:688.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_Le-S74P0yE",
        "outputId": "05a48b56-6bd2-4502-b515-44025d3cb02e"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:289, P1:711.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sh_BP7Jdu4m",
        "outputId": "bf5becfb-7acf-48ae-b91f-f619f4a920a4"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:289, P1:711.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QGtqhEEdu4m",
        "outputId": "6fa9bcd6-4d66-49c2-cf6c-27746a4df273"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:131, P1:869.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDh-L11Xdu4n"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckZTVIvLdu4n",
        "outputId": "a7a96c7f-6167-4b39-9e08-2b8f03309517"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:492, P1:508.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P4AZoYsdu4n",
        "outputId": "7fff9307-4015-4312-d96b-acd979985d1e"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[3S, 3H, 3D, 3C], [QS, QH, QC]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:278, P1:722.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs3cRRYldu4n"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIEGT9wGdu4n",
        "outputId": "8b984e95-2847-49cb-98d1-0e2b772719df"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[3S, 3H, 3D, 3C], [QS, QH, QC]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:278, P1:722.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia1PRiONFseZ"
      },
      "source": [
        "# Test Agents - Psuedo Identity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGTOO_j_Fser"
      },
      "source": [
        "## all_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuY4X5qZFses"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = True\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/pseudo/all_data'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QfgYfspFse0"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgqcxRvnFse0",
        "outputId": "26be4c0c-d27f-47dc-a5bb-bec7ba611a44"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-DhtUjgFses"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a6b2tVdFset",
        "outputId": "c239cb37-dbff-43bc-c376-509e5af9483d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GltUq_onFseu"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA-andDwFsev",
        "outputId": "e83c7cd8-c6d8-4281-ff66-ac4401109d3e"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxiF6xSwFsev",
        "outputId": "23c5b068-95f1-4256-f845-09da721591c5"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1, P1:999.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-V-M8OyFsew",
        "outputId": "0e413c77-fa17-4cbf-cb1b-4df5b4a0e234"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_L0NwUVFsex",
        "outputId": "eeb5ad85-da12-47f0-f7d6-87c2e9798e48"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk-WEDFcFsew",
        "outputId": "6b741827-4ff2-4aab-fbd0-94c48f81534a"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeU534pxFsez"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "funxNwiQFsez",
        "outputId": "1a5c6bb3-fa93-41fa-e86d-116d946c4d6b"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:1, P1:999.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwNnQD5jFsez",
        "outputId": "a94a5ca3-f8c2-4875-d668-dec6d3887945"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsFNdt58Fsey"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPl6Xdy6Fsey",
        "outputId": "af12fba1-8312-4e1e-a83f-b53426c28651"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:10, P1:990.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC0X7IVEF8oP"
      },
      "source": [
        "## 10pct_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff6WiFYtF8oU"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = True\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/pseudo/10pct_data'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubd-MnXkF8pE"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRlVvda7F8pF",
        "outputId": "ec068fdc-3f14-440e-9b84-ebc79046bf06"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:976, P1:24.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twWy_D8wF8oV"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40Ql21RLF8oh",
        "outputId": "451a4f94-d12d-49c5-eb66-75ee02962d66"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NnLa05_F8oi"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-CC0DBvF8oj",
        "outputId": "fd52c38f-580f-409e-c48c-c24497381d3d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mskSLiOyP-92",
        "outputId": "ba86ee07-d607-4e24-eb5e-903632b4b8ae"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynywSAqPF8ok",
        "outputId": "71c3b6f4-075c-4fa5-da1f-91508a598df5"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLg3UdWfF8o6",
        "outputId": "b7d4d0c9-c121-4b9e-9e94-29f27e61ec49"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36JvOswVP-93",
        "outputId": "3a67f9ef-ffe3-40f4-cea6-736b4a960d69"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLwv8E2fF8o-",
        "outputId": "358fdf51-0c2a-43aa-b3be-924a8457d26d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT8tRG2FF8ok",
        "outputId": "4dd0368d-af3d-418f-80ac-65fb1523ef5f"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8d5RebwF8pD"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GNeWp1mF8pD",
        "outputId": "b55419e0-22e1-4edb-f3f4-aa109c057971"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:1, P1:999.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgqLBkpwF8pE",
        "outputId": "56f4b254-dde5-4530-b99a-34b2cc3a19cc"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwnYDexnF8o_"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDVWrCYzF8pA"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3cW_MEqGBWp"
      },
      "source": [
        "## 5K_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1gRZow1GBW4"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = True\n",
        "knock_layer = False\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/pseudo/5K_data'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rnOjM2KGBW-"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDgQbb7bGBW-",
        "outputId": "a8c9c329-d0dc-467b-a22c-26144f1a9e16"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:865, P1:135.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNqqT0qdGBW5"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFFOCj2mGBW6",
        "outputId": "bd5dba77-c387-40f2-bf9a-f9bab11c1760"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_x95SEXGBW6"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-pPHnTtGBW7",
        "outputId": "5efe2110-4189-4976-dca2-df127963d831"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VVtik0lGBW7",
        "outputId": "dbc4d62e-b95b-4673-8204-dfe7f061db41"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjmiJKihGBW8",
        "outputId": "245a09e1-c58e-4441-c532-6ce75d2a3582"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWyYJnj2GBW8",
        "outputId": "1b4ed44c-e698-4d58-dd1c-b58afc038b9c"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57d8VF8bGBW7",
        "outputId": "0f60d880-2b60-4d7c-f1fc-865075270d7c"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5CGpiJkGBW9"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMi70ewSGBW9",
        "outputId": "9534e40b-a27c-4694-da57-0f274df038b4"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCYcA0rDGBW-",
        "outputId": "f663101a-242c-4352-b44e-801eb718dd49"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 0 melds [[4H, 5H, 6H], [2H, 2D, 2C]] illegally and forfeits.\n",
            "\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 0 melds [[8H, 9H, TH, JH], [4S, 4H, 4D]] illegally and forfeits.\n",
            "\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:0, P1:1000.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZHUaYnNGBW9"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl7YIKj0GBW9"
      },
      "source": [
        "# numGames = 1000\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# agent0 = MLPGinRummyPlayer()\n",
        "# checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "# qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "# qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "# agent0.loadModel(qnet)\n",
        "# agent2 = MLPGinRummyPlayer()\n",
        "# checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "# qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "# qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "# agent2.loadModel(qnet)\n",
        "# testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTlctAsxUHys"
      },
      "source": [
        "# Test Agents - Knock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hoq2Oxui_QTF"
      },
      "source": [
        "## knock_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stifk-y9_QTS"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = True\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/knock/knock_1'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqkF9ixG_QTX"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwg-ryM1_QTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00cc4d7-a5b8-4c42-f230-1c8a8d3f90de"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F650TVBz_QTS"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsRYvByz_QTT",
        "outputId": "3fe3f3a1-cf2d-4757-c138-98a3a82a9638"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:335, P1:665.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDQ7vZu4_QTT"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F0DhiX__QTU",
        "outputId": "02fc9d66-b3fd-48e4-db7d-b53aa408dc4c"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:343, P1:657.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXZ1yf64QHz0",
        "outputId": "a6015571-9509-4957-a7db-f6d5df05db1d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:358, P1:642.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou-eAHIT_QTU",
        "outputId": "d4c8722a-f896-4b44-a00a-33a769f19879"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:343, P1:657.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZnrY1ke_QTV",
        "outputId": "ac013d67-5696-4f70-a07c-fa9b32a6e37c"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:337, P1:663.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBIkwfxyQHz1",
        "outputId": "113d4106-f1e8-47b8-9887-17a16364042d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:335, P1:665.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LSMFeHN_QTV",
        "outputId": "9b280abd-78c4-48e8-86f9-21a566aa4b63"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:335, P1:665.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkswZkKu_QTU",
        "outputId": "59f6adf7-128b-4500-c81f-2ead49257d09"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:371, P1:629.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_lPivrH_QTW"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiQ3vjYC_QTW",
        "outputId": "005400be-7cd9-4bc7-dc9a-02a79ce39210"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:529, P1:471.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTW3LbMe_QTX",
        "outputId": "a718525e-498c-494a-8055-201880e4866d"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Max Turns exceeded, restart\n",
            "Games Won: P0:551, P1:449.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjwJwgEW_QTV"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdN3AuRs_QTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07353a9-a59e-439a-96ad-5a7a355248d3"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:521, P1:479.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV9_F8mkvOnv",
        "outputId": "65e2b856-fb49-4e55-a43e-07ae89f715fa"
      },
      "source": [
        "numGames = 5000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Game ...  1000\n",
            "Game ...  1250\n",
            "Game ...  1500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  1750\n",
            "Game ...  2000\n",
            "Game ...  2250\n",
            "Game ...  2500\n",
            "Game ...  2750\n",
            "Game ...  3000\n",
            "Game ...  3250\n",
            "Game ...  3500\n",
            "Game ...  3750\n",
            "Max Turns exceeded, restart\n",
            "Game ...  4000\n",
            "Game ...  4250\n",
            "Game ...  4500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  4750\n",
            "Games Won: P0:2699, P1:2301.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LkPMQvnVNz1"
      },
      "source": [
        "## knock_pt002"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZTWVWbUVNz1"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = True\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/knock/knock_pt002'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eYiF5zlVNz8"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESGihH9SVNz8",
        "outputId": "b1540167-fa5c-4ac9-cdfc-35dcb2b8dd2f"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FxWLRw8VNz2"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJBGMFP6VNz2",
        "outputId": "c63ef2e7-ea85-4169-f358-302bbf41bab6"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:309, P1:691.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzXvyysOVNz3"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QCb4zgaVNz3",
        "outputId": "e88f5ef1-e892-464c-f3e9-af7969b3cfe1"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:238, P1:762.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW06V1j3QM0c",
        "outputId": "127a02d3-40b5-44b0-ec0a-abf6b642bea1"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:273, P1:727.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvUldZblVNz3",
        "outputId": "02b8527e-04f9-4ad6-c646-a610d025be29"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:270, P1:730.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC0xsMtdVNz5",
        "outputId": "eb2b3053-5ee8-471a-e8b9-eb4670eacc06"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:280, P1:720.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyFON4CiQM0d",
        "outputId": "48ff9f55-b8f6-4727-d62c-539c67f4ba0c"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:293, P1:707.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM2vB4gWVNz5",
        "outputId": "23623584-8995-4a50-8a06-a4deb225ffba"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:274, P1:726.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1zYk_mdVNz4",
        "outputId": "354ba650-9f94-4a55-a233-79727a0be05f"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:233, P1:767.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syFOnf-pVNz7"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdCeG4kRVNz7",
        "outputId": "c49c7d99-6a3d-458a-d51f-3114803708d1"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:496, P1:504.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPQW3siKVNz8",
        "outputId": "a3328bf5-5487-4ed7-cf03-d9d3eadfc128"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:447, P1:553.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YdJeBR6VNz5"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nacabWOLVNz6",
        "outputId": "a1e3eded-65a2-4cbd-a1d0-398df8bb291b"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Max Turns exceeded, restart\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:450, P1:550.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_35xcCHVWMO"
      },
      "source": [
        "## knock_pt02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDQXRYoUVWMP"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = True\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/knock/knock_pt02'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MQcSzB_VWMT"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv6OwXjdVWMT",
        "outputId": "2461a855-e011-4f8a-c477-6a4e5ba7717e"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap6ffROvVWMP"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORl5PkZ-VWMP",
        "outputId": "8ed7efd4-5209-4360-f220-ca6e7f66f508"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:309, P1:691.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNHVUaNYVWMQ"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLGjZrSkVWMQ",
        "outputId": "4ea27cce-d52f-4f47-b08f-0e3d776109a7"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:285, P1:715.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e6BUphwQRD2",
        "outputId": "0b38afc5-38b3-46b5-f2dd-0af6ade35894"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:275, P1:725.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V3esH9aVWMQ",
        "outputId": "e84b945f-5e13-4e01-b430-0582b5f1f53b"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:247, P1:753.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ6LsFR_VWMR",
        "outputId": "c1f1de84-5beb-45ff-9a7f-af24d0f2e3dd"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:306, P1:694.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2htNTIVJQRD4",
        "outputId": "b94af5fd-6294-4b59-a5ba-1f55159b7f50"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:301, P1:699.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBZQ06RoVWMR",
        "outputId": "bb268344-767e-4a5d-f5f0-c51a18807d20"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:293, P1:707.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEptKdSHVWMQ",
        "outputId": "90404165-3b58-43df-8a71-b172cfb25b9e"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:278, P1:722.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1J1CctdVWMS"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhmHTxCsVWMT",
        "outputId": "ae12d86a-3caa-4b38-a7aa-104f2fa8711e"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:494, P1:506.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFUMs3xoVWMT",
        "outputId": "0aef15a6-d4ea-4ff8-d156-ea718a6bb402"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:427, P1:573.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erx-_883VWMS"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZB9WPhyVWMS",
        "outputId": "33f24e56-593e-4718-847a-db9b82f2144b"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Max Turns exceeded, restart\n",
            "Player 1 melds [[4S, 5S, 6S, 7S], [3D, 4D, 5D]] illegally and forfeits.\n",
            "\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:429, P1:571.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL5uNyJFVYp_"
      },
      "source": [
        "## knock_pt2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37dG-_tUVYp_"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = True\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/knock/knock_pt2'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36sLMnaiVYqC"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX-B5epcVYqD",
        "outputId": "82f31581-4800-4ae4-bbcb-9ac114c004dc"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwT6-M-VVYp_"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeuzgruCVYp_",
        "outputId": "8596bb79-d585-40ab-8f3d-fa3052fdbaa7"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:310, P1:690.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvwQhKx2VYqA"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNzJxySiVYqA",
        "outputId": "b86437bb-19d6-49ce-e117-4d105efbb4ce"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:276, P1:724.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpaQvkL8QVGB",
        "outputId": "fb4c21cc-2281-4986-f93b-d926973ea4e9"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:281, P1:719.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaVDVcHkVYqA",
        "outputId": "57671cae-37bf-49ef-ea42-55a5f5150b19"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:315, P1:685.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtePE6_2VYqB",
        "outputId": "a85f6653-99f4-430b-fde5-e0290f6d8728"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:310, P1:690.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VwrPG7JQVGC",
        "outputId": "8f287d5a-2dfb-4bcf-e369-3d095b98ab51"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:294, P1:706.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDY4o0xgVYqB",
        "outputId": "2292b7f7-e60c-4100-972e-ee1354d79f9d"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:305, P1:695.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4xOVd6gVYqA",
        "outputId": "328f1c43-aaac-42be-c8ce-898687c20a12"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:301, P1:699.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0Ut9uG2VYqC"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWidwKmHVYqC",
        "outputId": "2f0545ef-c4d2-4ea8-8d2c-e72b49ec79ab"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:508, P1:492.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpnJ9Ni_VYqC",
        "outputId": "2859f40b-217b-4e8d-e97c-a5e1c64548d5"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:469, P1:531.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYCDI2mAVYqB"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeGJBpFYVYqB",
        "outputId": "0bc12f68-14d1-41f1-b3b5-588d4a9b126e"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:443, P1:557.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMXoADH3VbT0"
      },
      "source": [
        "## knock_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcBtZpJrVbT1"
      },
      "source": [
        "# Wins: pre/rand/sgr/post\n",
        "# Wins2: rand_k/sgr_k\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "batch_norm = False\n",
        "top_layer = False\n",
        "knock_layer = True\n",
        "mlp_layers = [520, 520, 110]\n",
        "model = 'models/dqn/final/knock/knock_2'\n",
        "# Wins: \n",
        "# Wins2:\n",
        "\n",
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "agent1 = SimpleGinRummyPlayer()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjbmJupwVbT5"
      },
      "source": [
        "### vs Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_j_5u1FVbT5",
        "outputId": "05dd1389-f07c-42a1-9af8-f86ffb135fb8"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = RandGinRummyPlayer()\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:1000, P1:0.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0M4r7USVbT1"
      },
      "source": [
        "### Pre Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OZ_erYjVbT2",
        "outputId": "7fa48445-9a6f-4b22-9c70-1f92c018e648"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:334, P1:666.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Be-dhfnVbT2"
      },
      "source": [
        "### Post DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE6afEu6VbT2",
        "outputId": "ca3008d1-b9bd-4d30-ef6a-899b6195b7cc"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:339, P1:661.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR967TWPQZgB",
        "outputId": "0de21a65-36f2-47d2-c665-e5d7b02110de"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:336, P1:664.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjIdHtoeVbT2",
        "outputId": "284ad207-848f-4c21-cc78-51a3712032dc"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:322, P1:678.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nreXEhQ0VbT3",
        "outputId": "dd02866e-a74d-48b0-8b5e-a8961cc8fad2"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_rand_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:334, P1:666.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK8nvKqRQZgC",
        "outputId": "05ba7666-f893-446c-e2d1-f67ac0048047"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_self_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:334, P1:666.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPzp5PiLVbT3",
        "outputId": "714b07c0-96d8-4002-860b-236c252b5d5e"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_sgr_knock.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:334, P1:666.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lzJDu3WVbT3",
        "outputId": "433969bf-e623-46f1-d8e3-c947e1da38b0"
      },
      "source": [
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "testAgents(agent0,agent1,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:219, P1:781.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMmy95g3VbT4"
      },
      "source": [
        "### vs Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqRl6mj8VbT4",
        "outputId": "e1f00324-864f-4c2d-98df-701f4ed88d8d"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Max Turns exceeded, restart\n",
            "Game ...  500\n",
            "Max Turns exceeded, restart\n",
            "Game ...  750\n",
            "Games Won: P0:528, P1:472.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk9P9nXGVbT4",
        "outputId": "b344913b-28d4-44c0-b33a-fac5c7bb7c4c"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('models/all/all/all_states_all_actions_2hl_extra_knock_data_80K/model.pt', map_location=device)\n",
        "agent2.loadModel(checkpoint)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:391, P1:609.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teHcYVTuVbT4"
      },
      "source": [
        "### Post vs. Pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRt9hEF9VbT4",
        "outputId": "95710b19-4e6e-4632-d71f-e0d63f70b385"
      },
      "source": [
        "numGames = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "agent0 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_posttrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent0.loadModel(qnet)\n",
        "agent2 = MLPGinRummyPlayer()\n",
        "checkpoint = torch.load('{}/model_pretrain.pth'.format(model), map_location=device)\n",
        "qnet = EstimatorNetwork(mlp_layers, batch_norm, knock_layer, top_layer).to(device)\n",
        "qnet.load_state_dict(load_checkpoint(checkpoint['dqn_q_estimator']))\n",
        "agent2.loadModel(qnet)\n",
        "testAgents(agent0,agent2,numGames,verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Model\n",
            "Load Model\n",
            "Game ...  0\n",
            "Game ...  250\n",
            "Game ...  500\n",
            "Game ...  750\n",
            "Games Won: P0:342, P1:658.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}